<!DOCTYPE html>
<html lang="zh_CN">
<head>
  <meta charset="UTF-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ScriptModule — PyTorch main documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html">
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css">
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css">
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css">
  <link rel="stylesheet" href="../_static/katex-math.css" type="text/css">
  <link rel="stylesheet" href="../_static/sphinx-dropdown.css" type="text/css">
  <link rel="stylesheet" href="../_static/panels-bootstrap.min.css" type="text/css">
  <link rel="stylesheet" href="../_static/css/jit.css" type="text/css">
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css">
    <link rel="index" title="Index" href="../genindex.html">
    <link rel="search" title="Search" href="../search.html">
    <link rel="next" title="ScriptFunction" href="torch.jit.ScriptFunction.html">
    <link rel="prev" title="torch.jit.wait" href="torch.jit.wait.html">

<!--
  Search engines should not index the main version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head><body class="pytorch-body"><div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">学习</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class="dropdown-title">开始使用</span>
                  <p>在本地运行 PyTorch 或快速开始使用支持的云平台之一</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">教程</span><p></p>
                  <p>PyTorch 教程中的新功能</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">学习基础知识</span><p></p>
                  <p>熟悉 PyTorch 的概念和模块</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch 食谱</span><p></p>
                  <p>精简版、可直接部署的 PyTorch 代码示例</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">PyTorch 入门 - YouTube 系列教程</span><p></p>
                  <p>使用我们引人入胜的 YouTube 教程系列掌握 PyTorch 基础知识</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">生态系统</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">工具</span><p></p>
                  <p>了解 PyTorch 生态系统中的工具和框架</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">社区</span>
                  <p>加入 PyTorch 开发者社区，贡献、学习并获得问题解答</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">论坛</span>
                  <p>讨论 PyTorch 代码、问题、安装、研究的地方</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">开发者资源</span>
                  <p>查找资源并获得问题解答</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">2024 年度贡献者奖项</span><p></p>
                  <p>本届 PyTorch 会议揭晓获奖者</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">边缘</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">关于 PyTorch Edge</span><p></p>
                  <p>为边缘设备构建创新且注重隐私的 AI 体验</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span><p></p>
                  <p>涵盖移动和边缘设备端到端推理能力的解决方案</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch 文档</span><p></p>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">文档</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span><p></p>
                  <p>探索文档以获取如何使用 PyTorch 的全面指南</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch 领域</span><p></p>
                  <p>阅读 PyTorch Domains 文档以了解更多关于特定领域的库的信息</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">博客与新闻</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch 博客</span><p></p>
                  <p>捕捉最新的技术新闻和事件</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">社区博客</span><p></p>
                  <p>PyTorch 生态系统中的故事</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">视频</span><p></p>
                  <p>了解最新的 PyTorch 教程、新内容等</p>
                </a><a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">社区故事</span><p></p>
                  <p>学习我们社区如何使用 PyTorch 解决真实、日常的机器学习问题</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">活动</span><p></p>
                  <p>查找活动、网络研讨会和播客</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">通讯</span><p></p>
                  <p>保持最新更新</p>
                </a>
            </div>
          </div></li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">关于</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch 基金会</span><p></p>
                  <p>了解更多关于 PyTorch 基金会的信息</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">管理委员会</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">云信用计划</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">技术顾问委员会</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">员工</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">联系我们</span><p></p>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">成为会员</a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>



   

    

    <div class="table-of-contents-link-wrapper">
      <span>目录</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="https://pytorch.org/docs/versions.html">主页 (2.7.0+cpu ) ▼</a>
    </div>
    <div id="searchBox">
    <div class="searchbox" id="googleSearchBox">
      <script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
      <div class="gcse-search"></div>
    </div>
    <div id="sphinxSearchBox" style="display: none;">
      <div role="search">
        <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
          <input type="text" name="q" placeholder="Search Docs">
          <input type="hidden" name="check_keywords" value="yes">
          <input type="hidden" name="area" value="default">
        </form>
      </div>
    </div>
  </div>
  <form id="searchForm">
    <label style="margin-bottom: 1rem">
      <input type="radio" name="searchType" value="google" checked="">Google 搜索</label>
    <label style="margin-bottom: 1rem">
      <input type="radio" name="searchType" value="sphinx">经典搜索</label>
  </form>

  <script>
     document.addEventListener('DOMContentLoaded', function() {
      const searchForm = document.getElementById('searchForm');
      const googleSearchBox = document.getElementById('googleSearchBox');
      const sphinxSearchBox = document.getElementById('sphinxSearchBox');
      // Function to toggle search box visibility
      function toggleSearchBox(searchType) {
        googleSearchBox.style.display = searchType === 'google' ? 'block' : 'none';
        sphinxSearchBox.style.display = searchType === 'sphinx' ? 'block' : 'none';
      }
      // Determine the default search type
      let defaultSearchType;
      const currentUrl = window.location.href;
      if (currentUrl.startsWith('https://pytorch.org/docs/stable')) {
        // For the stable documentation, default to Google
        defaultSearchType = localStorage.getItem('searchType') || 'google';
      } else {
        // For any other version, including docs-preview, default to Sphinx
        defaultSearchType = 'sphinx';
      }
      // Set the default search type
      document.querySelector(`input[name="searchType"][value="${defaultSearchType}"]`).checked = true;
      toggleSearchBox(defaultSearchType);
      // Event listener for changes in search type
      searchForm.addEventListener('change', function(event) {
        const selectedSearchType = event.target.value;
        localStorage.setItem('searchType', selectedSearchType);
        toggleSearchBox(selectedSearchType);
      });
      // Set placeholder text for Google search box
      window.onload = function() {
        var placeholderText = "Search Docs";
        var googleSearchboxText = document.querySelector("#gsc-i-id1");
        if (googleSearchboxText) {
          googleSearchboxText.placeholder = placeholderText;
          googleSearchboxText.style.fontFamily = 'FreightSans';
          googleSearchboxText.style.fontSize = "1.2rem";
          googleSearchboxText.style.color = '#262626';
        }
      };
    });
  </script>

          </div>

          

<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html">您正在查看不稳定开发者预览文档。请点击此处查看最新稳定版本的文档。</a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">社区</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../community/build_ci_governance.html">PyTorch 治理 | 构建 + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/contribution_guide.html">PyTorch 贡献指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/design.html">PyTorch 设计哲学</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/governance.html">PyTorch 治理 | 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/persons_of_interest.html">PyTorch 治理 | 维护者</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">开发者笔记</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notes/amp_examples.html">自动混合精度示例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/autograd.html">Autograd 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/broadcasting.html">广播语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/cpu_threading_torchscript_inference.html">CPU 多线程和 TorchScript 推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/cuda.html">CUDA 语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/custom_operators.html">PyTorch 自定义算子页面</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/ddp.html">分布式数据并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/extending.html">扩展 PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/extending.func.html">扩展 torch.func 使用 autograd.Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/faq.html">常见问题解答</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/fsdp.html">FSDP 笔记</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/get_start_xpu.html">Intel GPU 上入门指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/gradcheck.html">Gradcheck 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/hip.html">HIP (ROCm) 语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/large_scale_deployments.html">大规模部署功能</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/libtorch_stable_abi.html">LibTorch 稳定 ABI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/modules.html">模块</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/mps.html">MPS 后端</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/multiprocessing.html">多进程最佳实践</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/numerical_accuracy.html">数值精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/randomness.html">可重现性</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/serialization.html">序列化语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/windows.html">Windows 常见问题解答</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">语言绑定</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor_attributes.html">张量属性</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor_view.html">索引视图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../amp.html">torch.自动混合精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerator.html">torch 加速器</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu.html">torch.cpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_cuda_memory.html">理解 CUDA 内存使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_cuda_memory.html#generating-a-snapshot">生成快照</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_cuda_memory.html#using-the-visualizer">使用可视化工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_cuda_memory.html#snapshot-api-reference">摄像头 API 参考</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mps.html">torch.mps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../xpu.html">torch.xpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mtia.html">torch.mtia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mtia.memory.html">torch.mtia.memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../meta.html">元设备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backends.html">火炬后端</a></li>
<li class="toctree-l1"><a class="reference internal" href="../export.html">torch.export</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.tensor.html">torch.distributed.tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.fsdp.fully_shard.html">torch.distributed.fsdp.fully_shard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.pipelining.html">torch.distributed.pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch.compiler.html">torch.compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../func.html">torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fx.experimental.html">torch.fx.experimental</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hub.html">torch.hub</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../signal.html">torch.signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nn.attention.html">torch.nn 注意力机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../complex_numbers.html">复数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ddp_comm_hooks.html">DDP 通信钩子</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quantization.html">量化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rpc.html">分布式 RPC 框架</a></li>
<li class="toctree-l1"><a class="reference internal" href="../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../masked.html">torch.masked</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../size.html">torch.Size</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">torch.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deterministic.html">torch.utils.deterministic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../module_tracker.html">torch.utils.module_tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../type_info.html">类型信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="../named_tensor.html">命名张量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../name_inference.html">命名张量操作覆盖率</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../future_mod.html">torch.__future__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../logging.html">torch._logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_environment_variables.html">Torch 环境变量</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">图书馆</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/xla/">PyTorch 在 XLA 设备上</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/ao">torchao</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        文档 &gt;</li>

        
          <li><a href="../jit.html">TorchScript</a> &gt;</li>
        
      <li>脚本模块</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/generated/torch.jit.ScriptModule.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg" width="16" height="16"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">快捷键</div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="scriptmodule">
<h1>脚本模块 ¶</h1>
<dl class="py class">
<dt class="sig sig-object py" id="torch.jit.ScriptModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch.jit.</span></span><span class="sig-name descname"><span class="pre">ScriptModule</span></span><a class="reference internal" href="../_modules/torch/jit/_script.html#ScriptModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/jit/_script.py#L513"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule" title="Permalink to this definition">¶</a></dt>
<dd><p>C++ torch::jit::Module 的包装器，具有方法、属性和参数。</p>
<p>C++ 的包装器。 <code class="docutils literal "><span class="pre">torch::jit::Module</span></code> s 包含方法、属性、参数和常量。它们可以像在普通 <code class="docutils literal "><span class="pre">nn.Module</span></code> 中一样访问。</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.add_module">
<span class="sig-name descname"><span class="pre">add_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L624"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.add_module" title="Permalink to this definition">¶</a></dt>
<dd><p>向当前模块添加子模块。</p>
<p>可以使用给定的名称将该模块作为属性访问。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>子模块名称（str）- 子模块的名称。可以使用给定的名称从该模块访问子模块</p></li>
<li><p>模块（Module）- 要添加到模块中的子模块。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1007"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply <code class="docutils literal "><span class="pre">fn</span></code> 递归地应用于每个子模块（如 <code class="docutils literal "><span class="pre">.children()</span></code> 返回的）以及自身。</p>
<p>典型用途包括初始化模型的参数（参见 torch.nn.init）。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>fn ( <code class="xref py py-class docutils literal "><span class="pre">Module</span></code> -&gt; None) – 对每个子模块应用此函数</p>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.bfloat16">
bfloat16()[来源] ¶</dt>
<dd><p>将所有浮点参数和缓冲区转换为 <code class="docutils literal "><span class="pre">bfloat16</span></code> 数据类型。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法会就地修改模块。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回值<span class="colon">:</span></dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.buffers">
buffers(recurse=True)[源代码] ¶</dt>
<dd><p>返回模块缓冲区的迭代器。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>recurse (布尔) – 如果为 True，则生成此模块及其所有子模块的缓冲区。否则，仅生成此模块的直接成员缓冲区。</p>
</dd>
<dt class="field-even">生成<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor – 模块缓冲区</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>迭代器[Tensor]</p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class 'torch.Tensor'&gt; (20L,)</span>
<span class="go">&lt;class 'torch.Tensor'&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.children">
<span class="sig-name descname"><span class="pre">children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2731"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.children" title="Permalink to this definition">¶</a></dt>
<dd><p>返回遍历直接子模块的迭代器。</p>
<dl class="field-list simple">
<dt class="field-odd">生成<span class="colon">:</span></dt>
<dd class="field-odd"><p>模块 - 子模块</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p>Iterator[模块]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.code">
属性代码 ¶</dt>
<dd><p>返回 <code class="docutils literal "><span class="pre">forward</span></code> 方法的内部图的可打印表示（作为有效的 Python 语法）。</p>
<p>详细内容请参见代码检查。</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.code_with_constants">
属性代码_with_constants ¶</dt>
<dd><p>返回一个元组。</p>
<p>返回一个元组：</p>
<p>[0] <code class="docutils literal "><span class="pre">forward</span></code> 方法的内部图的可视化表示（作为有效的 Python 语法）。参见代码。[1]一个遵循[0]输出中 CONSTANT.cN 格式的 ConstMap。在[0]输出中的索引是底层常量值的键。</p>
<p>详细内容请参见代码检查。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2994"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.compile" title="Permalink to this definition">¶</a></dt>
<dd><p>使用 <code class="xref py py-func docutils literal "><span class="pre">torch.compile()</span></code> 编译此模块的前向。</p>
<p>此模块的__call__方法已编译，所有参数都原样传递给 <code class="xref py py-func docutils literal "><span class="pre">torch.compile()</span></code> 。</p>
<p>查看第 0#条以获取此函数参数的详细信息。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.cpu">
cpu()[来源] 方法</dt>
<dd><p>将所有模型参数和缓冲区移动到 CPU。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法会就地修改模块。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回值<span class="colon">:</span></dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1048"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.cuda" title="Permalink to this definition">¶</a></dt>
<dd><p>将所有模型参数和缓冲区移动到 GPU 上。</p>
<p>这也将关联的参数和缓冲区变为不同的对象。因此，如果模块将在 GPU 上优化时继续存在，则应在构建优化器之前调用此方法。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法会就地修改模块。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>设备（整型，可选）- 如果指定，所有参数都将复制到该设备</p>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.double">
double()[来源]</dt>
<dd><p>将所有浮点参数和缓冲区转换为 <code class="docutils literal "><span class="pre">double</span></code> 数据类型。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法会就地修改模块。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回值<span class="colon">:</span></dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.eval">
eval()[源码] ¶</dt>
<dd><p>将模块设置为评估模式。</p>
<p>此操作仅对某些模块有效。请参阅特定模块的文档，了解其在训练/评估模式下的行为细节，例如是否受影响，例如 <code class="xref py py-class docutils literal "><span class="pre">Dropout</span></code> ， <code class="xref py py-class docutils literal "><span class="pre">BatchNorm</span></code> 等。</p>
<p>这与 <code class="xref py py-meth docutils literal "><span class="pre">self.train(False)</span></code> 等效。</p>
<p>请参阅“局部禁用梯度计算”以比较 .eval() 与其他可能与之混淆的类似机制。</p>
<dl class="field-list simple">
<dt class="field-odd">返回值<span class="colon">:</span></dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.extra_repr">
<span class="sig-name descname"><span class="pre">extra_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2934"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>返回模块的额外表示。</p>
<p>要打印自定义的额外信息，您应该在您自己的模块中重新实现此方法。单行和多行字符串均可接受。</p>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.float">
<span class="sig-name descname"><span class="pre">float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1149"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.float" title="Permalink to this definition">¶</a></dt>
<dd><p>将所有浮点参数和缓冲区转换为 <code class="docutils literal "><span class="pre">float</span></code> 数据类型。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法会就地修改模块。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回值<span class="colon">:</span></dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.get_buffer">
<span class="sig-name descname"><span class="pre">get_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L838"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.get_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>如果存在，则返回由 <code class="docutils literal "><span class="pre">target</span></code> 指定的缓冲区，否则抛出错误。</p>
<p>请参阅 <code class="docutils literal "><span class="pre">get_submodule</span></code> 的文档字符串以获取此方法功能以及如何正确指定 <code class="docutils literal "><span class="pre">target</span></code> 的更详细说明。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>目标（str）- 要查找的缓冲区的完全限定字符串名称。（参见 <code class="docutils literal "><span class="pre">get_submodule</span></code> 了解如何指定完全限定字符串。）</p>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>由 <code class="docutils literal "><span class="pre">target</span></code> 引用的缓冲区</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">torch.Tensor</a></p>
</dd>
<dt class="field-even">引发<span class="colon">:</span></dt>
<dd class="field-even"><p>AttributeError - 如果目标字符串引用了无效的路径或解析为不是缓冲区的对象</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.get_extra_state">
<span class="sig-name descname"><span class="pre">get_extra_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L874"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.get_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>将任何额外的状态返回以包含在模块的状态字典中。</p>
<p>如果您需要存储额外的状态，请实现此功能并为您的模块添加相应的 <code class="xref py py-func docutils literal "><span class="pre">set_extra_state()</span></code> 。此函数在构建模块的状态字典时被调用。</p>
<p>注意，额外的状态应该是可序列化的，以确保状态字典的序列化工作正常。我们只为序列化张量提供向后兼容性保证；如果其他对象的序列化 pickle 形式发生变化，它们可能会破坏向后兼容性。</p>
<dl class="field-list simple">
<dt class="field-odd">返回值<span class="colon">:</span></dt>
<dd class="field-odd"><p>将任何额外的状态存储在模块的状态字典中</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)">对象</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.get_parameter">
get_parameter(target)[源代码] ¶</dt>
<dd><p>如果存在，则返回由 <code class="docutils literal "><span class="pre">target</span></code> 指定的参数，否则抛出错误。</p>
<p>请参阅 <code class="docutils literal "><span class="pre">get_submodule</span></code> 的文档字符串以获取此方法功能以及如何正确指定 <code class="docutils literal "><span class="pre">target</span></code> 的更详细说明。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>target (str) – 要查找的参数的完全限定字符串名称。（请参阅 <code class="docutils literal "><span class="pre">get_submodule</span></code> 了解如何指定完全限定字符串。）</p>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>引用的参数 <code class="docutils literal "><span class="pre">target</span></code> </p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Parameter</p>
</dd>
<dt class="field-even">引发<span class="colon">:</span></dt>
<dd class="field-even"><p>属性错误 - 如果目标字符串引用了无效的路径或解析为不是 <code class="docutils literal "><span class="pre">nn.Parameter</span></code> 的内容</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.get_submodule">
<span class="sig-name descname"><span class="pre">get_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L656"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.get_submodule" title="Permalink to this definition">¶</a></dt>
<dd><p>如果存在，则返回由 <code class="docutils literal "><span class="pre">target</span></code> 指定的子模块，否则抛出错误。</p>
<p>例如，假设你有一个类似这样的 <code class="docutils literal "><span class="pre">nn.Module</span></code> <code class="docutils literal "><span class="pre">A</span></code> ：</p>
<div class="highlight-text "><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
        )
        (linear): Linear(in_features=100, out_features=200, bias=True)
    )
)
</pre></div>
</div>
<p>（图中显示了 <code class="docutils literal "><span class="pre">nn.Module</span></code> <code class="docutils literal "><span class="pre">A</span></code> . <code class="docutils literal "><span class="pre">A</span></code> ，它有一个嵌套的子模块 <code class="docutils literal "><span class="pre">net_b</span></code> ，该子模块本身有两个子模块 <code class="docutils literal "><span class="pre">net_c</span></code> 和 <code class="docutils literal "><span class="pre">linear</span></code> 。 <code class="docutils literal "><span class="pre">net_c</span></code> 然后有一个子模块 <code class="docutils literal "><span class="pre">conv</span></code> 。）</p>
<p>要检查我们是否有 <code class="docutils literal "><span class="pre">linear</span></code> 子模块，我们会调用 <code class="docutils literal "><span class="pre">get_submodule("net_b.linear")</span></code> 。要检查我们是否有 <code class="docutils literal "><span class="pre">conv</span></code> 子模块，我们会调用 <code class="docutils literal "><span class="pre">get_submodule("net_b.net_c.conv")</span></code> 。</p>
<p> <code class="docutils literal "><span class="pre">get_submodule</span></code> 的运行时间受模块嵌套程度的限制。对 <code class="docutils literal "><span class="pre">target</span></code> 的查询可以达到相同的结果，但它在传递模块的数量上是 O(N)。因此，为了简单地检查是否存在某个子模块，应该始终使用 <code class="docutils literal "><span class="pre">get_submodule</span></code> 。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>目标（str）- 要查找的子模块的完全限定字符串名称。（参见上面的示例了解如何指定完全限定字符串。）</p>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>由 <code class="docutils literal "><span class="pre">target</span></code> 引用的子模块</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">torch.nn.Module</a></p>
</dd>
<dt class="field-even">引发<span class="colon">:</span></dt>
<dd class="field-even"><p>属性错误 - 如果在从目标字符串生成的路径中，任何（子）路径解析为不存在的属性名称或不是 <code class="docutils literal "><span class="pre">nn.Module</span></code> 实例的对象，则会发生此错误。</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.graph">
属性图 ¶</dt>
<dd><p>返回 <code class="docutils literal "><span class="pre">forward</span></code> 方法的内部图的字符串表示。</p>
<p>详细内容请参阅“解释图”。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.half">
half()[源]</dt>
<dd><p>将所有浮点参数和缓冲区转换为 <code class="docutils literal "><span class="pre">half</span></code> 数据类型。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法会就地修改模块。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回值<span class="colon">:</span></dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.inlined_graph">
内联图属性 ¶</dt>
<dd><p>返回 <code class="docutils literal "><span class="pre">forward</span></code> 方法的内部图的字符串表示。</p>
<p>此图将进行预处理，将所有函数和方法调用内联。请参阅“解释图”以获取详细信息。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.ipu">
<span class="sig-name descname"><span class="pre">ipu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1067"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.ipu" title="Permalink to this definition">¶</a></dt>
<dd><p>将所有模型参数和缓冲区移动到 IPU。</p>
<p>这也将使相关的参数和缓冲区成为不同的对象。因此，如果模块将在 IPU 上运行并优化，则应在构建优化器之前调用此操作。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法会就地修改模块。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>设备（整型，可选）- 如果指定，所有参数都将复制到该设备</p>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2485"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>从 <code class="xref py py-attr docutils literal "><span class="pre">state_dict</span></code> 复制参数和缓冲区到本模块及其子模块。</p>
<p>如果 <code class="xref py py-attr docutils literal "><span class="pre">strict</span></code> 等于 <code class="docutils literal "><span class="pre">True</span></code> ，则 <code class="xref py py-attr docutils literal "><span class="pre">state_dict</span></code> 的键必须与该模块的 <code class="xref py py-meth docutils literal "><span class="pre">state_dict()</span></code> 函数返回的键完全匹配。</p>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>如果 <code class="xref py py-attr docutils literal "><span class="pre">assign</span></code> 等于 <code class="docutils literal "><span class="pre">True</span></code> ，优化器必须在调用 <code class="xref py py-attr docutils literal "><span class="pre">load_state_dict</span></code> 之后创建，除非 <code class="xref py py-func docutils literal "><span class="pre">get_swap_module_params_on_conversion()</span></code> 等于 <code class="docutils literal "><span class="pre">True</span></code> 。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>state_dict (dict) – 包含参数和持久缓冲区的字典。</p></li>
<li><p>strict (bool, 可选) – 是否严格强制 <code class="xref py py-attr docutils literal "><span class="pre">state_dict</span></code> 中的键与该模块的 <code class="xref py py-meth docutils literal "><span class="pre">state_dict()</span></code> 函数返回的键匹配。默认值： <code class="docutils literal "><span class="pre">True</span></code> </p></li>
<li><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">将 (bool, 可选) – 当设置为 <code class="docutils literal "><span class="pre">False</span></code> 时，当前模块中张量的属性被保留，而设置为 <code class="docutils literal "><span class="pre">True</span></code> 则保留状态字典中张量的属性。唯一的例外是 <code class="xref py py-class docutils literal ">
<span class="pre">Default:</span> <span class="pre">``False`</span></code> 的 <code class="docutils literal "><span class="pre">requires_grad</span></code> 字段。</font></font></font></p></li>
</ul>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p></p><ul class="simple">
<li><dl class="simple">
<dt>missing_keys 是一个包含任何预期但缺失于提供的 @0# 中的键的字符串列表。</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">的此模块但缺失的键列表。</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>unexpected_keys 是一个包含不期望的键的字符串列表。</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">由本模块预期但出现在提供的 <code class="docutils literal "><span class="pre">state_dict</span></code> 中。</p>
</dd>
</dl>
</li>
</ul>
<p></p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>使用 <code class="docutils literal "><span class="pre">NamedTuple</span></code> 、 <code class="docutils literal "><span class="pre">missing_keys</span></code> 和 <code class="docutils literal "><span class="pre">unexpected_keys</span></code> 字段</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>如果一个参数或缓冲区被注册为 <code class="docutils literal "><span class="pre">None</span></code> ，并且其对应的关键字存在于 <code class="xref py py-attr docutils literal "><span class="pre">state_dict</span></code> 中， <code class="xref py py-meth docutils literal "><span class="pre">load_state_dict()</span></code> 将引发一个 <code class="docutils literal "><span class="pre">RuntimeError</span></code> 。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.modules">
<span class="sig-name descname"><span class="pre">modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2760"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.modules" title="Permalink to this definition">¶</a></dt>
<dd><p>返回网络中所有模块的迭代器。</p>
<dl class="field-list simple">
<dt class="field-odd">生成<span class="colon">:</span></dt>
<dd class="field-odd"><p>模块 - 网络中的模块</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p>Iterator[模块]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>重复模块只返回一次。在下面的示例中， <code class="docutils literal "><span class="pre">l</span></code> 只会返回一次。</p>
</div>
<p>示例：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">'-&gt;'</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.mtia">
<span class="sig-name descname"><span class="pre">mtia</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1105"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.mtia" title="Permalink to this definition">¶</a></dt>
<dd><p>将所有模型参数和缓冲区移动到 MTIA。</p>
<p>这也将关联的参数和缓冲区变为不同的对象。因此，如果模块将在 MTIA 上优化时继续存在，应该在构建优化器之前调用此方法。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法会就地修改模块。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>设备（整型，可选）- 如果指定，所有参数都将复制到该设备</p>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.named_buffers">
<span class="sig-name descname"><span class="pre">named_buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2700"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.named_buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>返回模块缓冲区的迭代器，同时返回缓冲区的名称以及缓冲区本身。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>prefix（字符串）- 预先添加到所有缓冲区名称的前缀。</p></li>
<li><p>recurse（bool，可选）- 如果为 True，则生成此模块及其所有子模块的缓冲区。否则，仅生成此模块的直接成员缓冲区。默认为 True。</p></li>
<li><p>remove_duplicate（bool，可选）- 是否在结果中删除重复的缓冲区。默认为 True。</p></li>
</ul>
</dd>
<dt class="field-even">生成<span class="colon">:</span></dt>
<dd class="field-even"><p>（str，torch.Tensor）- 包含名称和缓冲区的元组</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>迭代器[tuple[str, torch.Tensor]]</p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'running_var'</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.named_children">
named_children()[源]</dt>
<dd><p>返回一个遍历直接子模块的迭代器，返回模块名称及其本身。</p>
<dl class="field-list simple">
<dt class="field-odd">生成<span class="colon">:</span></dt>
<dd class="field-odd"><p>(str, 模块) - 包含名称和子模块的元组</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p>Iterator[tuple[str, torch.nn.modules.module.Module]]</p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'conv4'</span><span class="p">,</span> <span class="s1">'conv5'</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.named_modules">
named_modules(memo=None, prefix='', remove_duplicate=True)[source]</dt>
<dd><p>返回网络中所有模块的迭代器，同时返回模块的名称及其本身。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>memo (Optional[set[torch.nn.modules.module.Module]]) – 用于存储已添加到结果中的模块集合的备忘录</p></li>
<li><p>prefix (str) – 模块名称前缀，将被添加到模块名称中</p></li>
<li><p>remove_duplicate (bool) – 是否在结果中移除重复的模块实例</p></li>
</ul>
</dd>
<dt class="field-even">生成<span class="colon">:</span></dt>
<dd class="field-even"><p>(str, Module) – 名称和模块的元组</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>重复模块只返回一次。在下面的示例中， <code class="docutils literal "><span class="pre">l</span></code> 只会返回一次。</p>
</div>
<p>示例：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">'-&gt;'</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; ('', Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; ('0', Linear(in_features=2, out_features=2, bias=True))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.named_parameters">
<span class="sig-name descname"><span class="pre">named_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2645"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.named_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>返回模块参数的迭代器，同时返回参数的名称及其本身。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>prefix (str) – 预先添加到所有参数名称的前缀。</p></li>
<li><p>recurse (bool) – 如果为 True，则生成此模块及其所有子模块的参数。否则，仅生成此模块的直接成员参数。</p></li>
<li><p>remove_duplicate (bool, optional) – 是否从结果中移除重复的参数。默认为 True。</p></li>
</ul>
</dd>
<dt class="field-even">生成<span class="colon">:</span></dt>
<dd class="field-even"><p>(str, Parameter) – 包含名称和参数的元组</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>迭代器[tuple[str, torch.nn.parameter.Parameter]]</p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'bias'</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2620"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>返回模块参数的迭代器。</p>
<p>这通常传递给优化器。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>recurse (bool) – 如果为 True，则生成此模块及其所有子模块的参数。否则，仅生成此模块的直接成员参数。</p>
</dd>
<dt class="field-even">生成<span class="colon">:</span></dt>
<dd class="field-even"><p>参数 – 模块参数</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>迭代器[参数]</p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class 'torch.Tensor'&gt; (20L,)</span>
<span class="go">&lt;class 'torch.Tensor'&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.register_backward_hook">
<span class="sig-name descname"><span class="pre">register_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1406"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.register_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>在模块上注册反向钩子。</p>
<p>此功能已被弃用，推荐使用 <code class="xref py py-meth docutils literal "><span class="pre">register_full_backward_hook()</span></code> ，此函数的行为将在未来版本中发生变化。</p>
<dl class="field-list simple">
<dt class="field-odd">返回值<span class="colon">:</span></dt>
<dd class="field-odd"><p>一个可以用来通过调用 <code class="docutils literal "><span class="pre">handle.remove()</span></code> 移除已添加钩子的句柄。</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal "><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.register_buffer">
<span class="sig-name descname"><span class="pre">register_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L512"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.register_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>将缓冲区添加到模块中。</p>
<p>这通常用于注册一个不应被视为模型参数的缓冲区。例如，BatchNorm 的 <code class="docutils literal "><span class="pre">running_mean</span></code> 不是参数，而是模块状态的一部分。缓冲区默认情况下是持久的，将与参数一起保存。通过设置 <code class="xref py py-attr docutils literal "><span class="pre">persistent</span></code> 为 <code class="docutils literal "><span class="pre">False</span></code> 可以改变这种行为。持久缓冲区和非持久缓冲区之间的唯一区别是后者不会成为此模块的 <code class="xref py py-attr docutils literal "><span class="pre">state_dict</span></code> 的一部分。</p>
<p>缓冲区可以通过给定的名称作为属性进行访问。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>name (str) – 缓冲区的名称。可以通过给定的名称从该模块访问缓冲区</p></li>
<li><p>tensor (Tensor 或 None) – 要注册的缓冲区。如果为 <code class="docutils literal "><span class="pre">None</span></code> ，则忽略在缓冲区上运行的运算，如 <code class="xref py py-attr docutils literal "><span class="pre">cuda</span></code> 。如果为 <code class="docutils literal "><span class="pre">None</span></code> ，则该缓冲区不包括在模块的 <code class="xref py py-attr docutils literal "><span class="pre">state_dict</span></code> 中。</p></li>
<li><p>持久性（布尔值）- 是否缓冲区是此模块的 <code class="xref py py-attr docutils literal "><span class="pre">state_dict</span></code> 的一部分。</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">'running_mean'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.register_forward_hook">
<span class="sig-name descname"><span class="pre">register_forward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">always_call</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1658"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.register_forward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>在模块上注册前向钩子。</p>
<p>每当 <code class="xref py py-func docutils literal "><span class="pre">forward()</span></code> 计算输出后，都会调用该钩子。</p>
<p>如果 <code class="docutils literal "><span class="pre">with_kwargs</span></code> 是 <code class="docutils literal "><span class="pre">False</span></code> 或者未指定，则输入只包含传递给模块的位置参数。关键字参数不会传递给钩子，只会传递给 <code class="docutils literal "><span class="pre">forward</span></code> 。钩子可以修改输出。它可以就地修改输入，但对前向没有影响，因为这是在调用 <code class="xref py py-func docutils literal "><span class="pre">forward()</span></code> 之后调用的。钩子应具有以下签名：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<p>如果 <code class="docutils literal "><span class="pre">with_kwargs</span></code> 是 <code class="docutils literal "><span class="pre">True</span></code> ，则前向钩子将传递给前向函数的 <code class="docutils literal "><span class="pre">kwargs</span></code> ，并期望返回可能已修改的输出。钩子应具有以下签名：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>hook（可调用对象）- 用户定义的将被注册的钩子。</p></li>
<li><p>prepend（布尔值）- 如果 <code class="docutils literal "><span class="pre">True</span></code> ，则提供的 <code class="docutils literal "><span class="pre">hook</span></code> 将在所有现有的 <code class="docutils literal "><span class="pre">forward</span></code> 钩子之前触发。否则，提供的 <code class="docutils literal "><span class="pre">hook</span></code> 将在所有现有的 <code class="docutils literal "><span class="pre">forward</span></code> 钩子之后触发。注意，使用 <code class="xref py py-func docutils literal "><span class="pre">register_module_forward_hook()</span></code> 注册的全局 <code class="docutils literal "><span class="pre">forward</span></code> 钩子将在使用此方法注册的所有钩子之前触发。默认： <code class="docutils literal "><span class="pre">False</span></code> </p></li>
<li><p>with_kwargs (bool) – 如果 <code class="docutils literal "><span class="pre">True</span></code> ，则 <code class="docutils literal "><span class="pre">hook</span></code> 将接收传递给 forward 函数的 kwargs 参数。默认： <code class="docutils literal "><span class="pre">False</span></code> </p></li>
<li><p>always_call (bool) – 如果 <code class="docutils literal "><span class="pre">True</span></code> ，则无论在调用 Module 时是否抛出异常， <code class="docutils literal "><span class="pre">hook</span></code> 都将被执行。默认： <code class="docutils literal "><span class="pre">False</span></code> </p></li>
</ul>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>一个可以用来通过调用 <code class="docutils literal "><span class="pre">handle.remove()</span></code> 移除已添加钩子的句柄。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal "><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.register_forward_pre_hook">
register_forward_pre_hook(hook, *, prepend=False, with_kwargs=False)[source]</dt>
<dd><p>在模块上注册一个前置钩子。</p>
<p>每次调用 <code class="xref py py-func docutils literal "><span class="pre">forward()</span></code> 之前都会调用此钩子。</p>
<p>如果 <code class="docutils literal "><span class="pre">with_kwargs</span></code> 为 false 或未指定，则输入仅包含传递给模块的位置参数。关键字参数不会传递给钩子，只会传递给 <code class="docutils literal "><span class="pre">forward</span></code> 。钩子可以修改输入。用户可以在钩子中返回一个元组或单个修改后的值。如果返回单个值（除非该值已经是元组），我们将将其包装成元组。钩子应具有以下签名：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre></div>
</div>
<p>如果 <code class="docutils literal "><span class="pre">with_kwargs</span></code> 为 true，则前置钩子将传递给 forward 函数提供的 kwargs。如果钩子修改了输入，则应返回 args 和 kwargs。钩子应具有以下签名：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">a</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">modified</span> <span class="nb">input</span> <span class="ow">and</span> <span class="n">kwargs</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>hook（可调用对象）- 用户定义的将被注册的钩子。</p></li>
<li><p>prepend（布尔值）- 如果为 true，提供的 <code class="docutils literal "><span class="pre">hook</span></code> 将在所有现有的 <code class="docutils literal "><span class="pre">forward_pre</span></code> 钩子之前触发。否则，提供的 <code class="docutils literal "><span class="pre">hook</span></code> 将在所有现有的 <code class="docutils literal "><span class="pre">forward_pre</span></code> 钩子之后触发。注意，使用 <code class="xref py py-func docutils literal "><span class="pre">register_module_forward_pre_hook()</span></code> 注册的全局 <code class="docutils literal "><span class="pre">forward_pre</span></code> 钩子将在所有通过此方法注册的钩子之前触发。默认值： <code class="docutils literal "><span class="pre">False</span></code> </p></li>
<li><p>with_kwargs（布尔值）- 如果为 true， <code class="docutils literal "><span class="pre">hook</span></code> 将传递给前向函数的 kwargs。默认值： <code class="docutils literal "><span class="pre">False</span></code> </p></li>
</ul>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>一个可以用来通过调用 <code class="docutils literal "><span class="pre">handle.remove()</span></code> 移除已添加钩子的句柄。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal "><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.register_full_backward_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1432"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.register_full_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>在模块上注册反向钩子。</p>
<p>每当计算模块相对于梯度的值时，都会调用此钩子，即当计算模块输出相对于梯度的值时，钩子将执行。钩子应具有以下签名：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p> <code class="xref py py-attr docutils literal "><span class="pre">grad_input</span></code> 和 <code class="xref py py-attr docutils literal "><span class="pre">grad_output</span></code> 是包含相对于输入和输出的梯度的元组。钩子不应修改其参数，但可以可选地返回一个新的相对于输入的梯度，该梯度将用于后续计算中的 <code class="xref py py-attr docutils literal "><span class="pre">grad_input</span></code> 。 <code class="xref py py-attr docutils literal "><span class="pre">grad_input</span></code> 只对应于作为位置参数给出的输入，所有关键字参数都被忽略。 <code class="xref py py-attr docutils literal "><span class="pre">grad_input</span></code> 和 <code class="xref py py-attr docutils literal "><span class="pre">grad_output</span></code> 中的条目对于所有非-Tensor 参数都是 <code class="docutils literal "><span class="pre">None</span></code> 。</p>
<p>由于技术原因，当此钩子应用于模块时，其前向函数将接收传递给模块的每个 Tensor 的视图。同样，调用者将接收模块前向函数返回的每个 Tensor 的视图。</p>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>使用反向钩子时，不允许就地修改输入或输出，否则将引发错误。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>hook (Callable) – 要注册的用户定义钩子。</p></li>
<li><p>prepend (bool) – 如果为 true，则提供的 <code class="docutils literal "><span class="pre">hook</span></code> 将在所有现有的 <code class="docutils literal "><span class="pre">backward</span></code> 钩子之前触发。否则，提供的 <code class="docutils literal "><span class="pre">hook</span></code> 将在所有现有的 <code class="docutils literal "><span class="pre">backward</span></code> 钩子之后触发。请注意，使用 <code class="xref py py-func docutils literal "><span class="pre">register_module_full_backward_hook()</span></code> 注册的全局 <code class="docutils literal "><span class="pre">backward</span></code> 钩子将在使用此方法注册的所有钩子之前触发。</p></li>
</ul>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>一个可以用来通过调用 <code class="docutils literal "><span class="pre">handle.remove()</span></code> 移除已添加钩子的句柄。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal "><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.register_full_backward_pre_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1357"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.register_full_backward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>在模块上注册反向前钩子。</p>
<p>每当计算模块的梯度时，都会调用该钩子。钩子应具有以下签名：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p> <code class="xref py py-attr docutils literal "><span class="pre">grad_output</span></code> 是一个元组。钩子不应该修改其参数，但它可以可选地返回一个关于输出的新梯度，该梯度将用于后续计算中替代 <code class="xref py py-attr docutils literal "><span class="pre">grad_output</span></code> 。 <code class="xref py py-attr docutils literal "><span class="pre">grad_output</span></code> 中的条目对于所有非 Tensor 参数将是 <code class="docutils literal "><span class="pre">None</span></code> 。</p>
<p>由于技术原因，当此钩子应用于模块时，其前向函数将接收传递给模块的每个 Tensor 的视图。同样，调用者将接收模块前向函数返回的每个 Tensor 的视图。</p>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>使用反向钩子时，不允许就地修改输入，否则将引发错误。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>hook (Callable) – 要注册的用户定义钩子。</p></li>
<li><p>prepend (bool) – 如果为 true，则提供的 <code class="docutils literal "><span class="pre">hook</span></code> 将在所有现有的 <code class="docutils literal "><span class="pre">backward_pre</span></code> 钩子之前触发。否则，提供的 <code class="docutils literal "><span class="pre">hook</span></code> 将在所有现有的 <code class="docutils literal "><span class="pre">backward_pre</span></code> 钩子之后触发。请注意，使用 <code class="xref py py-func docutils literal "><span class="pre">register_module_full_backward_pre_hook()</span></code> 注册的全局 <code class="docutils literal "><span class="pre">backward_pre</span></code> 钩子将在使用此方法注册的所有钩子之前触发。</p></li>
</ul>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>一个可以用来通过调用 <code class="docutils literal "><span class="pre">handle.remove()</span></code> 移除已添加钩子的句柄。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal "><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.register_load_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2275"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.register_load_state_dict_post_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>注册一个在模块的 <code class="xref py py-meth docutils literal "><span class="pre">load_state_dict()</span></code> 被调用后运行的钩子。</p>
<dl class="simple">
<dt>应具有以下签名::</dt><dd><p>hook(module, incompatible_keys) -&gt; None</p>
</dd>
</dl>
<p> <code class="docutils literal "><span class="pre">module</span></code> 参数是当前注册此钩子的模块， <code class="docutils literal "><span class="pre">incompatible_keys</span></code> 参数是一个包含属性 <code class="docutils literal "><span class="pre">missing_keys</span></code> 和 <code class="docutils literal "><span class="pre">unexpected_keys</span></code> 的 <code class="docutils literal "><span class="pre">NamedTuple</span></code> 。 <code class="docutils literal "><span class="pre">missing_keys</span></code> 是一个包含缺失键的 <code class="docutils literal "><span class="pre">list</span></code> 的 <code class="docutils literal "><span class="pre">str</span></code> ， <code class="docutils literal "><span class="pre">unexpected_keys</span></code> 是一个包含意外键的 <code class="docutils literal "><span class="pre">list</span></code> 的 <code class="docutils literal "><span class="pre">str</span></code> 。</p>
<p>给定的 incompatible_keys 可以在需要时就地修改。</p>
<p>注意，当调用 <code class="xref py py-func docutils literal "><span class="pre">load_state_dict()</span></code> 时，执行的检查会受到钩子对 <code class="docutils literal "><span class="pre">missing_keys</span></code> 或 <code class="docutils literal "><span class="pre">unexpected_keys</span></code> 的修改的影响，这是预期的。向任一集合添加内容将导致在调用 <code class="docutils literal "><span class="pre">strict=True</span></code> 时抛出错误，清除缺失和意外的键将避免错误。</p>
<dl class="field-list simple">
<dt class="field-odd">返回值<span class="colon">:</span></dt>
<dd class="field-odd"><p>一个可以用来通过调用 <code class="docutils literal "><span class="pre">handle.remove()</span></code> 移除已添加钩子的句柄。</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal "><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.register_load_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2263"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.register_load_state_dict_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>在模块的 <code class="xref py py-meth docutils literal "><span class="pre">load_state_dict()</span></code> 被调用之前注册一个预钩子。</p>
<dl class="simple">
<dt>应具有以下签名::</dt><dd><p>hook(module, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs) -&gt; None  # noqa: B950</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>hook (Callable) – 在加载状态字典之前将被调用的可调用钩子。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.register_module">
注册模块（name，module）[source] ¶</dt>
<dd><p> <code class="xref py py-func docutils literal "><span class="pre">add_module()</span></code> 的别名</p>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.register_parameter">
注册参数（name，param）[source] ¶</dt>
<dd><p>向模块添加参数。</p>
<p>可以使用给定的名称将该参数作为属性访问。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>name (str) – 参数名称。可以使用此名称从该模块访问参数</p></li>
<li><p>param (Parameter 或 None) – 要添加到模块的参数。如果为 <code class="docutils literal "><span class="pre">None</span></code> ，则忽略对参数运行的运算，如 <code class="xref py py-attr docutils literal "><span class="pre">cuda</span></code> 。如果为 <code class="docutils literal "><span class="pre">None</span></code> ，则参数不包括在模块的 <code class="xref py py-attr docutils literal "><span class="pre">state_dict</span></code> 中。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.register_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2073"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.register_state_dict_post_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>注册 <code class="xref py py-meth docutils literal "><span class="pre">state_dict()</span></code> 方法的后钩子。</p>
<dl class="simple">
<dt>应具有以下签名::</dt><dd><p>hook(module, state_dict, prefix, local_metadata) -&gt; None</p>
</dd>
</dl>
<p>已注册的钩子可以修改 <code class="docutils literal "><span class="pre">state_dict</span></code> 内部。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.register_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2097"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.register_state_dict_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>注册 <code class="xref py py-meth docutils literal "><span class="pre">state_dict()</span></code> 方法的预钩子。</p>
<dl class="simple">
<dt>应具有以下签名::</dt><dd><p>hook(module, prefix, keep_vars) -&gt; None</p>
</dd>
</dl>
<p>已注册的钩子可以在执行 <code class="docutils literal "><span class="pre">state_dict</span></code> 调用之前进行预处理。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.requires_grad_">
<span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2876"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.requires_grad_" title="Permalink to this definition">¶</a></dt>
<dd><p>如果自动微分应该记录此模块中参数的操作，请更改。</p>
<p>此方法将参数的 <code class="xref py py-attr docutils literal "><span class="pre">requires_grad</span></code> 属性就地设置。</p>
<p>此方法有助于冻结模块的一部分以进行微调或单独训练模型的一部分（例如，GAN 训练）。</p>
<p>请参阅本地禁用梯度计算以比较 .requires_grad_() 与可能与之混淆的几个类似机制。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>requires_grad (布尔值) – 是否应在此模块的参数上记录 autograd 操作。默认： <code class="docutils literal "><span class="pre">True</span></code> 。</p>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/jit/_script.py#L748"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.save" title="Permalink to this definition">¶</a></dt>
<dd><p>使用文件对象保存。</p>
<p>save(f, _extra_files={})</p>
<p>查看 <code class="xref py py-func docutils literal "><span class="pre">torch.jit.save</span></code> 接受一个文件对象。此函数 torch.save() 将对象转换为字符串，将其视为路径。不要混淆这两个函数在 'f' 参数功能方面的区别。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.set_extra_state">
<span class="sig-name descname"><span class="pre">set_extra_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L895"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.set_extra_state" title="Permalink to this definition">¶</a></dt>
<dd><p>设置加载的状态字典中包含的额外状态。</p>
<p>此函数从 <code class="xref py py-func docutils literal "><span class="pre">load_state_dict()</span></code> 调用，用于处理在 state_dict 中找到的任何额外状态。如果需要在其 state_dict 中存储额外状态，请实现此函数以及相应的 <code class="xref py py-func docutils literal "><span class="pre">get_extra_state()</span></code> 。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>state (dict) – 从 state_dict 中获取的额外状态</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.set_submodule">
<span class="sig-name descname"><span class="pre">set_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L721"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.set_submodule" title="Permalink to this definition">¶</a></dt>
<dd><p>如果存在，设置由 <code class="docutils literal "><span class="pre">target</span></code> 给定的子模块，否则抛出错误。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>如果将 <code class="docutils literal "><span class="pre">strict</span></code> 设置为 <code class="docutils literal "><span class="pre">False</span></code> （默认），则方法将替换现有的子模块或如果父模块存在，则创建新的子模块。如果将 <code class="docutils literal "><span class="pre">strict</span></code> 设置为 <code class="docutils literal "><span class="pre">True</span></code> ，则方法将仅尝试替换现有的子模块，如果子模块不存在，则抛出错误。</p>
</div>
<p>例如，假设你有一个类似这样的 <code class="docutils literal "><span class="pre">nn.Module</span></code> <code class="docutils literal "><span class="pre">A</span></code> ：</p>
<div class="highlight-text "><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(3, 3, 3)
        )
        (linear): Linear(3, 3)
    )
)
</pre></div>
</div>
<p>（图示显示了一个 <code class="docutils literal "><span class="pre">nn.Module</span></code> <code class="docutils literal "><span class="pre">A</span></code> 。 <code class="docutils literal "><span class="pre">A</span></code> 有一个嵌套的子模块 <code class="docutils literal "><span class="pre">net_b</span></code> ，该子模块本身有两个子模块 <code class="docutils literal "><span class="pre">net_c</span></code> 和 <code class="docutils literal "><span class="pre">linear</span></code> 。 <code class="docutils literal "><span class="pre">net_c</span></code> 然后有一个子模块 <code class="docutils literal "><span class="pre">conv</span></code> 。）</p>
<p>要用新的子模块 <code class="docutils literal "><span class="pre">Linear</span></code> 覆盖 <code class="docutils literal "><span class="pre">Conv2d</span></code> ，你可以调用 <code class="docutils literal "><span class="pre">set_submodule("net_b.net_c.conv",</span> <span class="pre">nn.Linear(1,</span> <span class="pre">1))</span></code> ，其中 <code class="docutils literal "><span class="pre">strict</span></code> 可以是 <code class="docutils literal "><span class="pre">True</span></code> 或 <code class="docutils literal "><span class="pre">False</span></code> 。</p>
<p>将新子模块 <code class="docutils literal "><span class="pre">Conv2d</span></code> 添加到现有模块 <code class="docutils literal "><span class="pre">net_b</span></code> 中，您将调用 <code class="docutils literal "><span class="pre">set_submodule("net_b.conv",</span> <span class="pre">nn.Conv2d(1,</span> <span class="pre">1,</span> <span class="pre">1))</span></code> 。</p>
<p>在上述示例中，如果您设置了 <code class="docutils literal "><span class="pre">strict=True</span></code> 并调用了 <code class="docutils literal "><span class="pre">set_submodule("net_b.conv",</span> <span class="pre">nn.Conv2d(1,</span> <span class="pre">1,</span> <span class="pre">1),</span> <span class="pre">strict=True)</span></code> ，则会引发 AttributeError 异常，因为 <code class="docutils literal "><span class="pre">net_b</span></code> 没有名为 <code class="docutils literal "><span class="pre">conv</span></code> 的子模块。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>目标（str）- 要查找的子模块的完全限定字符串名称。（参见上面的示例了解如何指定完全限定字符串。）</p></li>
<li><p>module (Module) – 要设置的子模块所在的模块。</p></li>
<li><p>strict（布尔值）- 如果 <code class="docutils literal "><span class="pre">False</span></code> ，该方法将替换现有子模块或如果父模块存在则创建新子模块。如果 <code class="docutils literal "><span class="pre">True</span></code> ，该方法将仅尝试替换现有子模块，如果子模块不存在则抛出错误。</p></li>
</ul>
</dd>
<dt class="field-even">引发<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p>ValueError - 如果 <code class="docutils literal "><span class="pre">target</span></code> 字符串为空或如果 <code class="docutils literal "><span class="pre">module</span></code> 不是 <code class="docutils literal "><span class="pre">nn.Module</span></code> 的实例。</p></li>
<li><p>AttributeError - 如果从 <code class="docutils literal "><span class="pre">target</span></code> 字符串生成的路径上的任何点，(子)路径解析为不存在的属性名称或不是 <code class="docutils literal "><span class="pre">nn.Module</span></code> 实例的对象。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.share_memory">
share_memory()[source]</dt>
<dd><p>见 <code class="xref py py-meth docutils literal "><span class="pre">torch.Tensor.share_memory_()</span></code> 。</p>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>T</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L2154"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>返回包含模块整个状态的引用字典。</p>
<p>包含参数和持久缓冲区（例如运行平均值）。键对应参数和缓冲区名称。设置为 <code class="docutils literal "><span class="pre">None</span></code> 的参数和缓冲区不包括在内。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>返回的对象是浅拷贝。它包含对模块参数和缓冲区的引用。</p>
</div>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>目前 <code class="docutils literal "><span class="pre">state_dict()</span></code> 也接受 <code class="docutils literal "><span class="pre">destination</span></code> 、 <code class="docutils literal "><span class="pre">prefix</span></code> 和 <code class="docutils literal "><span class="pre">keep_vars</span></code> 的位置参数，但这一功能将被弃用，未来版本将强制使用关键字参数。</p>
</div>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>请避免使用 <code class="docutils literal "><span class="pre">destination</span></code> 参数，因为它不是为最终用户设计的。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>destination (dict, optional) – 如果提供，模块的状态将被更新到 dict 中，并返回相同的对象。否则，将创建一个 <code class="docutils literal "><span class="pre">OrderedDict</span></code> 并返回。默认： <code class="docutils literal "><span class="pre">None</span></code> 。</p></li>
<li><p>prefix (str, optional) – 添加到参数和缓冲区名称的前缀，用于在 state_dict 中组成键。默认： <code class="docutils literal "><span class="pre">''</span></code> 。</p></li>
<li><p>keep_vars (bool, 可选) – 默认情况下，状态字典中返回的 <code class="xref py py-class docutils literal "><span class="pre">Tensor</span></code> s 将从 autograd 中分离。如果设置为 <code class="docutils literal "><span class="pre">True</span></code> ，则不会执行分离。默认： <code class="docutils literal "><span class="pre">False</span></code> 。</p></li>
</ul>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>包含整个模块状态的字典</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">字典</a></p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">['bias', 'weight']</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1228"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.to" title="Permalink to this definition">¶</a></dt>
<dd><p>移动和/或转换参数和缓冲区。</p>
<p>这可以称为</p>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1228"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1228"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1228"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
to(memory_format=torch.channels_last)[源码]</dt>
<dd></dd></dl>

<p>其签名与 <code class="xref py py-meth docutils literal "><span class="pre">torch.Tensor.to()</span></code> 相似，但仅接受浮点或复数 <code class="xref py py-attr docutils literal "><span class="pre">dtype</span></code> 。此外，此方法将仅将浮点或复数参数和缓冲区转换为 <code class="xref py py-attr docutils literal "><span class="pre">dtype</span></code> （如果提供）。如果提供，整数参数和缓冲区将移动 <code class="xref py py-attr docutils literal "><span class="pre">device</span></code> ，但数据类型不变。当 <code class="xref py py-attr docutils literal "><span class="pre">non_blocking</span></code> 设置时，如果可能，将尝试相对于主机异步转换/移动，例如，将具有固定内存的 CPU 张量移动到 CUDA 设备。</p>
<p>以下为示例。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法会就地修改模块。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>设备（ <code class="xref py py-class docutils literal "><span class="pre">torch.device</span></code> ）- 本模块中参数和缓冲区的期望设备</p></li>
<li><p>数据类型（ <code class="xref py py-class docutils literal "><span class="pre">torch.dtype</span></code> ）- 本模块中参数和缓冲区的期望浮点或复杂数据类型</p></li>
<li><p>张量（torch.Tensor）- 张量的数据类型和设备为本模块中所有参数和缓冲区的期望数据类型和设备</p></li>
<li><p>内存格式（ <code class="xref py py-class docutils literal "><span class="pre">torch.memory_format</span></code> ）- 本模块中 4D 参数和缓冲区的期望内存格式（关键字参数）</p></li>
</ul>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1913, -0.3420],</span>
<span class="go">        [-0.5113, -0.2325]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1913, -0.3420],</span>
<span class="go">        [-0.5113, -0.2325]], dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gpu1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:1"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">gpu1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">half</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1914, -0.3420],</span>
<span class="go">        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cpu</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1914, -0.3420],</span>
<span class="go">        [-0.5112, -0.2324]], dtype=torch.float16)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.3741+0.j,  0.2382+0.j],</span>
<span class="go">        [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span><span class="p">))</span>
<span class="go">tensor([[0.6122+0.j, 0.1150+0.j],</span>
<span class="go">        [0.6122+0.j, 0.1150+0.j],</span>
<span class="go">        [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.to_empty">
<span class="sig-name descname"><span class="pre">to_empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1193"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.to_empty" title="Permalink to this definition">¶</a></dt>
<dd><p>将参数和缓冲区移动到指定的设备，而不复制存储。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>device ( <code class="xref py py-class docutils literal "><span class="pre">torch.device</span></code> ) – 此模块中参数和缓冲区所期望的设备。</p></li>
<li><p>recurse (bool) – 是否递归地将子模块的参数和缓冲区移动到指定的设备。</p></li>
</ul>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.train">
train(mode=True)[source]</dt>
<dd><p>设置模块为训练模式。</p>
<p>此设置仅对某些模块有效。有关特定模块在训练/评估模式下的行为细节，请参阅相应模块的文档，例如它们是否受影响，例如 <code class="xref py py-class docutils literal "><span class="pre">Dropout</span></code> ， <code class="xref py py-class docutils literal "><span class="pre">BatchNorm</span></code> 等。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>mode (bool) – 是否设置训练模式（ <code class="docutils literal "><span class="pre">True</span></code> ）或评估模式（ <code class="docutils literal "><span class="pre">False</span></code> ）。默认： <code class="docutils literal "><span class="pre">True</span></code> 。</p>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.type">
type(dst_type)[源]</dt>
<dd><p>将所有参数和缓冲区转换为 <code class="xref py py-attr docutils literal "><span class="pre">dst_type</span></code> 。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法会就地修改模块。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>dst_type (类型或字符串) – 所需类型</p>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.xpu">
<span class="sig-name descname"><span class="pre">xpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/nn/modules/module.py#L1086"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.jit.ScriptModule.xpu" title="Permalink to this definition">¶</a></dt>
<dd><p>将所有模型参数和缓冲区移动到 XPU。</p>
<p>这也将关联的参数和缓冲区变为不同的对象。因此，如果模块将在 XPU 上运行并优化，则应在构建优化器之前调用此方法。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法会就地修改模块。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>设备（整型，可选）- 如果指定，所有参数都将复制到该设备</p>
</dd>
<dt class="field-even">返回值<span class="colon">:</span></dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">模块</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.jit.ScriptModule.zero_grad">
zero_grad(set_to_none=True)[source]</dt>
<dd><p>重置所有模型参数的梯度。</p>
<p>更多上下文，请参阅 <code class="xref py py-class docutils literal "><span class="pre">torch.optim.Optimizer</span></code> 下的类似函数。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>set_to_none (布尔值) – 不是设置为 0，而是将 grads 设置为 None。详见 <code class="xref py py-meth docutils literal "><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> 。</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        下一页 <img height="16" width="16" class="next-page" src="../_static/images/chevron-right-orange.svg"> <img height="16" width="16" class="previous-page" src="../_static/images/chevron-right-orange.svg"> 上一页
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>© 版权所有 PyTorch 贡献者。</p>
  </div>
    
      <div>使用 Sphinx 构建，并使用 Read the Docs 提供的主题。</div>
     

</footer>

          </div>
<script>

var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">脚本模块</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/clipboard.min.js"></script>
         <script src="../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script="" type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0">


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>文档</h2>
          <p>PyTorch 的全面开发者文档</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">查看文档</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>教程</h2>
          <p>深入了解初学者和高级开发者的教程</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">查看教程</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>资源</h2>
          <p>查找开发资源并获得您的疑问解答</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">查看资源</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">开始使用</a></li>
            <li><a href="https://pytorch.org/features">功能</a></li>
            <li><a href="https://pytorch.org/ecosystem">生态系统</a></li>
            <li><a href="https://pytorch.org/blog/">博客</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">贡献</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">资源</a></li>
            <li><a href="https://pytorch.org/tutorials">教程</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">文档</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">讨论</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">GitHub 问题和任务</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">品牌指南</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">保持更新</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">推特</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">领英</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch 播客</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">苹果</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">谷歌</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">亚马逊</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">条款</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">隐私</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© 版权所有 Linux 基金会。PyTorch 基金会是 Linux 基金会的一个项目。有关 PyTorch 基金会的网站使用条款、商标政策以及其他适用政策，请参阅 www.linuxfoundation.org/policies/。PyTorch 基金会支持 PyTorch 开源项目，该项目已被确立为 LF Projects, LLC 的 PyTorch 项目系列。有关适用于 PyTorch 项目系列 LF Projects, LLC 的政策，请参阅 www.lfprojects.org/policies/。</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">为了分析流量并优化您的体验，我们在本网站上提供 cookies。通过点击或导航，您同意允许我们使用 cookies。作为本网站的当前维护者，Facebook 的 Cookies 政策适用。了解更多信息，包括可用的控制选项：Cookies 政策。</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg" width="16" height="16">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>学习</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">开始使用</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">教程</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">学习基础知识</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch 菜谱</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">PyTorch 入门 - YouTube 系列</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>生态系统</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">工具</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">社区</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">论坛</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">开发者资源</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">贡献者奖项 - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>边缘</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">关于 PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">执行火炬</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch 文档</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>文档</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch 领域</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>博客 &amp; 新闻</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch 博客</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">社区博客</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">视频</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">社区故事</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">活动</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">通讯</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>关于</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch 基金会</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">治理委员会</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">云信用计划</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">技术顾问委员会</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">员工</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">联系我们</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>

</body></html>