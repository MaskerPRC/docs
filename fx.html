<!DOCTYPE html>
<html lang="zh_CN">
<head>
  <meta charset="UTF-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.fx — PyTorch main documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/fx.html">
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css">
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css">
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css">
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css">
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css">
  <link rel="stylesheet" href="_static/sphinx-dropdown.css" type="text/css">
  <link rel="stylesheet" href="_static/panels-bootstrap.min.css" type="text/css">
  <link rel="stylesheet" href="_static/css/jit.css" type="text/css">
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css">
    <link rel="index" title="Index" href="genindex.html">
    <link rel="search" title="Search" href="search.html">
    <link rel="next" title="torch.fx.experimental" href="fx.experimental.html">
    <link rel="prev" title="torch.futures" href="futures.html">

<!--
  Search engines should not index the main version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head><body class="pytorch-body"><div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">学习</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class="dropdown-title">开始使用</span>
                  <p>在本地运行 PyTorch 或快速开始使用支持的云平台之一</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">教程</span><p></p>
                  <p>PyTorch 教程中的新内容</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">学习基础知识</span><p></p>
                  <p>熟悉 PyTorch 的概念和模块</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch 食谱</span><p></p>
                  <p>精简版、可直接部署的 PyTorch 代码示例</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">PyTorch 入门 - YouTube 系列</span><p></p>
                  <p>通过我们引人入胜的 YouTube 教程系列掌握 PyTorch 基础知识</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">生态系统</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">工具</span><p></p>
                  <p>了解 PyTorch 生态系统中的工具和框架</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">社区</span>
                  <p>加入 PyTorch 开发者社区，贡献、学习并获得问题解答</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">论坛</span>
                  <p>讨论 PyTorch 代码、问题、安装、研究的地方</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">开发者资源</span>
                  <p>查找资源并获得问题解答</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">贡献者奖项 - 2024</span><p></p>
                  <p>本届 PyTorch 会议揭晓获奖者</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">关于 PyTorch Edge</span><p></p>
                  <p>为边缘设备构建创新和隐私感知的 AI 体验</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span><p></p>
                  <p>基于移动和边缘设备的端到端推理能力解决方案</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch 文档</span><p></p>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">文档</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span><p></p>
                  <p>探索文档以获取全面指导，了解如何使用 PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch 领域</span><p></p>
                  <p>阅读 PyTorch 领域的文档，了解更多关于特定领域库的信息</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">博客与新闻</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch 博客</span><p></p>
                  <p>捕捉最新的技术新闻和事件</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">社区博客</span><p></p>
                  <p>PyTorch 生态系统故事</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">视频</span><p></p>
                  <p>了解最新的 PyTorch 教程、新内容等</p>
                </a><a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">社区故事</span><p></p>
                  <p>学习如何我们的社区使用 PyTorch 解决真实、日常的机器学习问题</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">活动</span><p></p>
                  <p>查找活动、网络研讨会和播客</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">通讯</span><p></p>
                  <p>跟踪最新更新</p>
                </a>
            </div>
          </div></li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">关于</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch 基金会</span><p></p>
                  <p>了解更多关于 PyTorch 基金会的信息</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">管理委员会</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">云信用计划</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">技术顾问委员会</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">员工</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">联系我们</span><p></p>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">成为会员</a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>



   

    

    <div class="table-of-contents-link-wrapper">
      <span>目录</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="https://pytorch.org/docs/versions.html">主程序 (2.7.0+cpu ) ▼</a>
    </div>
    <div id="searchBox">
    <div class="searchbox" id="googleSearchBox">
      <script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
      <div class="gcse-search"></div>
    </div>
    <div id="sphinxSearchBox" style="display: none;">
      <div role="search">
        <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
          <input type="text" name="q" placeholder="Search Docs">
          <input type="hidden" name="check_keywords" value="yes">
          <input type="hidden" name="area" value="default">
        </form>
      </div>
    </div>
  </div>
  <form id="searchForm">
    <label style="margin-bottom: 1rem">
      <input type="radio" name="searchType" value="google" checked="">谷歌搜索</label>
    <label style="margin-bottom: 1rem">
      <input type="radio" name="searchType" value="sphinx">经典搜索</label>
  </form>

  <script>
     document.addEventListener('DOMContentLoaded', function() {
      const searchForm = document.getElementById('searchForm');
      const googleSearchBox = document.getElementById('googleSearchBox');
      const sphinxSearchBox = document.getElementById('sphinxSearchBox');
      // Function to toggle search box visibility
      function toggleSearchBox(searchType) {
        googleSearchBox.style.display = searchType === 'google' ? 'block' : 'none';
        sphinxSearchBox.style.display = searchType === 'sphinx' ? 'block' : 'none';
      }
      // Determine the default search type
      let defaultSearchType;
      const currentUrl = window.location.href;
      if (currentUrl.startsWith('https://pytorch.org/docs/stable')) {
        // For the stable documentation, default to Google
        defaultSearchType = localStorage.getItem('searchType') || 'google';
      } else {
        // For any other version, including docs-preview, default to Sphinx
        defaultSearchType = 'sphinx';
      }
      // Set the default search type
      document.querySelector(`input[name="searchType"][value="${defaultSearchType}"]`).checked = true;
      toggleSearchBox(defaultSearchType);
      // Event listener for changes in search type
      searchForm.addEventListener('change', function(event) {
        const selectedSearchType = event.target.value;
        localStorage.setItem('searchType', selectedSearchType);
        toggleSearchBox(selectedSearchType);
      });
      // Set placeholder text for Google search box
      window.onload = function() {
        var placeholderText = "Search Docs";
        var googleSearchboxText = document.querySelector("#gsc-i-id1");
        if (googleSearchboxText) {
          googleSearchboxText.placeholder = placeholderText;
          googleSearchboxText.style.fontFamily = 'FreightSans';
          googleSearchboxText.style.fontSize = "1.2rem";
          googleSearchboxText.style.color = '#262626';
        }
      };
    });
  </script>

          </div>

          

<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/fx.html">您正在查看不稳定开发者预览文档。请点击此处查看最新稳定版本的文档。</a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">社区</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community/build_ci_governance.html">PyTorch 治理 | 构建 + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/contribution_guide.html">PyTorch 贡献指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/design.html">PyTorch 设计哲学</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/governance.html">PyTorch 治理 | 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/persons_of_interest.html">PyTorch 治理 | 维护者</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">开发者笔记</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/amp_examples.html">自动混合精度示例</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/autograd.html">Autograd 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/broadcasting.html">广播语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cpu_threading_torchscript_inference.html">CPU 多线程和 TorchScript 推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cuda.html">CUDA 语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/custom_operators.html">PyTorch 自定义算子页面</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/ddp.html">分布式数据并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.html">扩展 PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.func.html">使用 autograd.Function 扩展 torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/faq.html">常见问题解答</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/fsdp.html">FSDP 笔记</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/get_start_xpu.html">在 Intel GPU 上入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/gradcheck.html">Gradcheck 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/hip.html">HIP (ROCm)语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/large_scale_deployments.html">大规模部署功能</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/libtorch_stable_abi.html">LibTorch 稳定 ABI</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/modules.html">模块</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/mps.html">MPS 后端</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/multiprocessing.html">多进程最佳实践</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/numerical_accuracy.html">数值精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/randomness.html">可重现性</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/serialization.html">序列化语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/windows.html">Windows 常见问题解答</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">语言绑定</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">torch::deploy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">张量属性</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_view.html">张量视图</a></li>
<li class="toctree-l1"><a class="reference internal" href="amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="accelerator.html">torch.accelerator</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu.html">torch.cpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_cuda_memory.html">理解 CUDA 内存使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_cuda_memory.html#generating-a-snapshot">生成快照</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_cuda_memory.html#using-the-visualizer">使用可视化工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_cuda_memory.html#snapshot-api-reference">快照 API 参考</a></li>
<li class="toctree-l1"><a class="reference internal" href="mps.html">torch.mps</a></li>
<li class="toctree-l1"><a class="reference internal" href="xpu.html">torch.xpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="mtia.html">torch.mtia</a></li>
<li class="toctree-l1"><a class="reference internal" href="mtia.memory.html">torch.mtia.memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="meta.html">元设备</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="export.html">torch.export</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.tensor.html">torch.distributed.tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.fsdp.fully_shard.html">torch.distributed.fsdp.fully_shard</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.pipelining.html">torch.distributed.pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch.compiler.html">torch.compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="func.html">torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="futures.html">torch.futures</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="fx.experimental.html">torch.fx.experimental</a></li>
<li class="toctree-l1"><a class="reference internal" href="hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="signal.html">torch.signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.attention.html">torch.nn.attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="complex_numbers.html">复数</a></li>
<li class="toctree-l1"><a class="reference internal" href="ddp_comm_hooks.html">DDP 通信钩子</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">量化</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc.html">分布式 RPC 框架</a></li>
<li class="toctree-l1"><a class="reference internal" href="random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="masked.html">torch.masked</a></li>
<li class="toctree-l1"><a class="reference internal" href="nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="size.html">torch.Size</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">torch.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="deterministic.html">torch.utils.deterministic</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="module_tracker.html">torch.utils.module_tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="type_info.html">类型信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="named_tensor.html">命名张量</a></li>
<li class="toctree-l1"><a class="reference internal" href="name_inference.html">命名张量操作覆盖率</a></li>
<li class="toctree-l1"><a class="reference internal" href="config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="future_mod.html">torch.__future__</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">torch._logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_environment_variables.html">火炬环境变量</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">库</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">火炬推荐</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/xla/">PyTorch 在 XLA 设备上</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/ao">torchao</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        文档 &gt;</li>

        
      <li>torch.fx</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/fx.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg" width="16" height="16"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">快捷键</div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="torch-fx">
<h1>torch.fx<a class="headerlink" href="#torch-fx" title="Permalink to this heading">¶</a></h1>
<section id="module-torch.fx">
<span id="overview"></span><h2>概述 ¶</h2>
<p>FX 是开发者用来转换 <code class="docutils literal "><span class="pre">nn.Module</span></code> 实例的工具包。FX 包含三个主要组件：符号追踪器、中间表示和 Python 代码生成。以下是这些组件在行动中的演示：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>


<span class="c1"># Simple module for demonstration</span>
<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>


<span class="n">module</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">torch.fx</span> <span class="kn">import</span> <span class="n">symbolic_trace</span>

<span class="c1"># Symbolic tracing frontend - captures the semantics of the module</span>
<span class="n">symbolic_traced</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span> <span class="o">=</span> <span class="n">symbolic_trace</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

<span class="c1"># High-level intermediate representation (IR) - Graph representation</span>
<span class="nb">print</span><span class="p">(</span><span class="n">symbolic_traced</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
<span class="sd">"""</span>
<span class="sd">graph():</span>
<span class="sd">    %x : [num_users=1] = placeholder[target=x]</span>
<span class="sd">    %param : [num_users=1] = get_attr[target=param]</span>
<span class="sd">    %add : [num_users=1] = call_function[target=operator.add](args = (%x, %param), kwargs = {})</span>
<span class="sd">    %linear : [num_users=1] = call_module[target=linear](args = (%add,), kwargs = {})</span>
<span class="sd">    %clamp : [num_users=1] = call_method[target=clamp](args = (%linear,), kwargs = {min: 0.0, max: 1.0})</span>
<span class="sd">    return clamp</span>
<span class="sd">"""</span>

<span class="c1"># Code generation - valid Python code</span>
<span class="nb">print</span><span class="p">(</span><span class="n">symbolic_traced</span><span class="o">.</span><span class="n">code</span><span class="p">)</span>
<span class="sd">"""</span>
<span class="sd">def forward(self, x):</span>
<span class="sd">    param = self.param</span>
<span class="sd">    add = x + param;  x = param = None</span>
<span class="sd">    linear = self.linear(add);  add = None</span>
<span class="sd">    clamp = linear.clamp(min = 0.0, max = 1.0);  linear = None</span>
<span class="sd">    return clamp</span>
<span class="sd">"""</span>
</pre></div>
</div>
<p>符号追踪器执行 Python 代码的“符号执行”。它通过代码传递称为代理的假值。记录这些代理的操作。有关符号追踪的更多信息，请参阅 <code class="xref py py-func docutils literal "><span class="pre">symbolic_trace()</span></code> 和 <code class="xref py py-class docutils literal "><span class="pre">Tracer</span></code> 文档。</p>
<p>中间表示是记录在符号追踪期间的操作的容器。它由表示函数输入、调用点（到函数、方法或 <code class="xref py py-class docutils literal "><span class="pre">torch.nn.Module</span></code> 实例）和返回值的节点列表组成。有关 IR 的更多信息，请参阅 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 的文档。IR 是应用转换的格式。</p>
<p>Python 代码生成是 FX 成为 Python 到 Python（或模块到模块）转换工具包的原因。对于每个图 IR，我们可以创建与图语义匹配的有效 Python 代码。此功能封装在 <code class="xref py py-class docutils literal "><span class="pre">GraphModule</span></code> 中，它是一个 <code class="xref py py-class docutils literal "><span class="pre">torch.nn.Module</span></code> 实例，包含一个 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 以及从图生成的 <code class="docutils literal "><span class="pre">forward</span></code> 方法。</p>
<p>综合来看，这个组件管道（符号跟踪 -&gt; 中间表示 -&gt; 转换 -&gt; Python 代码生成）构成了 FX 的 Python 到 Python 转换管道。此外，这些组件也可以单独使用。例如，符号跟踪可以单独使用来捕获代码的一种形式以供分析（而非转换）目的。代码生成可以用于程序化生成模型，例如从配置文件中生成。FX 有很多用途！</p>
<p>几个示例转换可以在示例仓库中找到。</p>
</section>
<section id="writing-transformations">
<span id="id1"></span><h2>编写转换</h2>
<p>什么是 FX 转换？本质上，它是一个看起来像这样的函数。</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>

<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
              <span class="n">tracer_class</span> <span class="p">:</span> <span class="nb">type</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Tracer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="c1"># Step 1: Acquire a Graph representing the code in `m`</span>

    <span class="c1"># NOTE: torch.fx.symbolic_trace is a wrapper around a call to</span>
    <span class="c1"># fx.Tracer.trace and constructing a GraphModule. We'll</span>
    <span class="c1"># split that out in our transform to allow the caller to</span>
    <span class="c1"># customize tracing behavior.</span>
    <span class="n">graph</span> <span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Graph</span> <span class="o">=</span> <span class="n">tracer_class</span><span class="p">()</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="c1"># Step 2: Modify this Graph or create a new one</span>
    <span class="n">graph</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Step 3: Construct a Module to return</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<p>您的转换将接受一个 <code class="xref py py-class docutils literal "><span class="pre">torch.nn.Module</span></code> ，从中获取一个 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> ，进行一些修改，然后返回一个新的 <code class="xref py py-class docutils literal "><span class="pre">torch.nn.Module</span></code> 。您应该将您的 FX 转换返回的 <code class="xref py py-class docutils literal "><span class="pre">torch.nn.Module</span></code> 视为与常规的 <code class="xref py py-class docutils literal "><span class="pre">torch.nn.Module</span></code> 相同 – 您可以将其传递给另一个 FX 转换，可以传递给 TorchScript，或者可以运行它。确保您的 FX 转换的输入和输出是 <code class="xref py py-class docutils literal "><span class="pre">torch.nn.Module</span></code> 将允许进行组合。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>也可以修改现有的 <code class="xref py py-class docutils literal "><span class="pre">GraphModule</span></code> 而不是创建一个新的，如下所示：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>

<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">m</span> <span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="n">gm</span> <span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="c1"># Modify gm.graph</span>
    <span class="c1"># &lt;...&gt;</span>

    <span class="c1"># Recompile the forward() method of `gm` from its Graph</span>
    <span class="n">gm</span><span class="o">.</span><span class="n">recompile</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">gm</span>
</pre></div>
</div>
<p>注意，您必须调用 <code class="xref py py-meth docutils literal "><span class="pre">GraphModule.recompile()</span></code> 来使生成的 <code class="docutils literal "><span class="pre">forward()</span></code> 方法与修改后的 <code class="docutils literal "><span class="pre">GraphModule</span></code> 同步。</p>
</div>
<p>既然您已经传递了一个已经被追踪到 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 的 <code class="xref py py-class docutils literal "><span class="pre">torch.nn.Module</span></code> ，现在有两种主要方法可以构建一个新的 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 。</p>
<section id="a-quick-primer-on-graphs">
<h3>图论快速入门指南</h3>
<p>图的语义的全面介绍可以在 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 文档中找到，但在这里我们将介绍基础知识。 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 是一种数据结构，它表示在 <code class="xref py py-class docutils literal "><span class="pre">GraphModule</span></code> 上的方法。这需要的信息包括：</p>
<ul class="simple">
<li><p>该方法有哪些输入？</p></li>
<li><p>方法内部运行的操作有哪些？</p></li>
<li><p>该方法输出的（即返回的）值是什么？</p></li>
</ul>
<p>这三个概念都用 <code class="xref py py-class docutils literal "><span class="pre">Node</span></code> 实例表示。让我们用一个简短的例子来看看我们是什么意思：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>

<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">relu</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">()</span>
<span class="n">gm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

<span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">print_tabular</span><span class="p">()</span>
</pre></div>
</div>
<p>在这里，我们定义一个用于演示的模块 <code class="docutils literal "><span class="pre">MyModule</span></code> ，实例化它，进行符号跟踪，然后调用 <code class="xref py py-meth docutils literal "><span class="pre">Graph.print_tabular()</span></code> 方法打印出显示此 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 节点的表格：</p>
<blockquote>
<div><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>指令码</p></th>
<th class="head"><p>名称</p></th>
<th class="head"><p>目标</p></th>
<th class="head"><p>参数</p></th>
<th class="head"><p>关键字参数</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>占位符</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>()</p></td>
<td><p>{}</p></td>
</tr>
<tr class="row-odd"><td><p>获取属性</p></td>
<td><p>线性权重</p></td>
<td><p>线性.weight</p></td>
<td><p>()</p></td>
<td><p>{}</p></td>
</tr>
<tr class="row-even"><td><p>调用函数</p></td>
<td><p>加 1</p></td>
<td><p>&lt;内置函数加&gt;</p></td>
<td><p>(x, 线性权重)</p></td>
<td><p>{}</p></td>
</tr>
<tr class="row-odd"><td><p>调用模块</p></td>
<td><p>线性_1</p></td>
<td><p>线性</p></td>
<td><p>(add_1,)</p></td>
<td><p>{}</p></td>
</tr>
<tr class="row-even"><td><p>调用方法</p></td>
<td><p>relu_1</p></td>
<td><p>relu</p></td>
<td><p>(线性_1,)</p></td>
<td><p>{}</p></td>
</tr>
<tr class="row-odd"><td><p>调用函数</p></td>
<td><p>求和 1</p></td>
<td><p>&lt;内置方法 sum …&gt;</p></td>
<td><p>(relu_1,)</p></td>
<td><p>{‘维度’：-1}</p></td>
</tr>
<tr class="row-even"><td><p>调用函数</p></td>
<td><p>topk_1</p></td>
<td><p>&lt;内置方法 topk …&gt;</p></td>
<td><p>(和_1, 3)</p></td>
<td><p>{}</p></td>
</tr>
<tr class="row-odd"><td><p>输出</p></td>
<td><p>输出</p></td>
<td><p>输出</p></td>
<td><p>(topk_1,)</p></td>
<td><p>{}</p></td>
</tr>
</tbody>
</table>
</div></blockquote>
<p>我们可以使用这些信息来回答我们上面提出的问题。</p>
<ul class="simple">
<li><p>该方法有哪些输入？在 FX 中，方法输入通过特殊的 <code class="docutils literal "><span class="pre">placeholder</span></code> 节点指定。在这种情况下，我们有一个单独的 <code class="docutils literal "><span class="pre">placeholder</span></code> 节点，其 <code class="docutils literal "><span class="pre">target</span></code> 为 <code class="docutils literal "><span class="pre">x</span></code> ，这意味着我们有一个名为 x 的单个（非自身）参数。</p></li>
<li><p>方法中包含哪些操作？ <code class="docutils literal "><span class="pre">get_attr</span></code> 、 <code class="docutils literal "><span class="pre">call_function</span></code> 、 <code class="docutils literal "><span class="pre">call_module</span></code> 和 <code class="docutils literal "><span class="pre">call_method</span></code> 节点代表方法中的操作。所有这些操作的语义的全面解释可以在 <code class="xref py py-class docutils literal "><span class="pre">Node</span></code> 文档中找到。</p></li>
<li><p>该方法返回值是什么？在 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 中，返回值由一个特殊的 <code class="docutils literal "><span class="pre">output</span></code> 节点指定。</p></li>
</ul>
<p>既然我们已经了解了 FX 中代码表示的基础知识，现在我们可以探索如何编辑 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 。</p>
</section>
<section id="graph-manipulation">
<h3>图形操作 ¶</h3>
<section id="direct-graph-manipulation">
<h4>直接图形操作 ¶</h4>
<p>建立这种新 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 的一种方法就是直接操作你的旧版本。为了帮助实现这一点，我们可以简单地从符号跟踪中获取的 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 进行修改。例如，假设我们希望用 <code class="xref py py-func docutils literal "><span class="pre">torch.mul()</span></code> 调用替换 <code class="xref py py-func docutils literal "><span class="pre">torch.add()</span></code> 调用。</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>

<span class="c1"># Sample module</span>
<span class="k">class</span> <span class="nc">M</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">m</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
              <span class="n">tracer_class</span> <span class="p">:</span> <span class="nb">type</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Tracer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="n">graph</span> <span class="p">:</span> <span class="n">fx</span><span class="o">.</span><span class="n">Graph</span> <span class="o">=</span> <span class="n">tracer_class</span><span class="p">()</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="c1"># FX represents its Graph as an ordered list of</span>
    <span class="c1"># nodes, so we can iterate through them.</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="c1"># Checks if we're calling a function (i.e:</span>
        <span class="c1"># torch.add)</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s1">'call_function'</span><span class="p">:</span>
            <span class="c1"># The target attribute is the function</span>
            <span class="c1"># that call_function calls.</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">:</span>
                <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span>

    <span class="n">graph</span><span class="o">.</span><span class="n">lint</span><span class="p">()</span> <span class="c1"># Does some checks to make sure the</span>
                 <span class="c1"># Graph is well-formed.</span>

    <span class="k">return</span> <span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<p>我们还可以进行更复杂的 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 重写，例如删除或添加节点。为了帮助这些转换，FX 提供了用于转换图的实用函数，这些函数可以在 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 文档中找到。以下是一个使用这些 API 添加 <code class="xref py py-func docutils literal "><span class="pre">torch.relu()</span></code> 调用的示例。</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="c1"># Specifies the insertion point. Any nodes added to the</span>
<span class="c1"># Graph within this scope will be inserted after `node`</span>
<span class="k">with</span> <span class="n">traced</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">inserting_after</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
    <span class="c1"># Insert a new `call_function` node calling `torch.relu`</span>
    <span class="n">new_node</span> <span class="o">=</span> <span class="n">traced</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">node</span><span class="p">,))</span>

    <span class="c1"># We want all places that used the value of `node` to</span>
    <span class="c1"># now use that value after the `relu` call we've added.</span>
    <span class="c1"># We use the `replace_all_uses_with` API to do this.</span>
    <span class="n">node</span><span class="o">.</span><span class="n">replace_all_uses_with</span><span class="p">(</span><span class="n">new_node</span><span class="p">)</span>
</pre></div>
</div>
<p>对于只包含替换的简单转换，你还可以使用子图重写器。</p>
</section>
<section id="subgraph-rewriting-with-replace-pattern">
<h4>使用 replace_pattern() 进行子图重写</h4>
<p>FX 还在直接图操作之上提供另一层自动化。 <code class="xref py py-func docutils literal "><span class="pre">replace_pattern()</span></code> API 实质上是一个用于编辑 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 的“查找/替换”工具。它允许您指定一个 <code class="docutils literal "><span class="pre">pattern</span></code> 和 <code class="docutils literal "><span class="pre">replacement</span></code> 函数，然后它会追踪这些函数，在 <code class="docutils literal "><span class="pre">pattern</span></code> 图中找到操作组的实例，并将这些实例替换为 <code class="docutils literal "><span class="pre">replacement</span></code> 图的副本。这可以帮助极大地自动化繁琐的图操作代码，随着变换变得更加复杂，这些代码可能会变得难以控制。</p>
</section>
<section id="graph-manipulation-examples">
<h4>图操作示例 ¶</h4>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/pytorch/examples/blob/master/fx/replace_op.py">替换一个操作</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/pytorch/blob/40cbf342d3c000712da92cfafeaca651b3e0bd3e/torch/fx/experimental/optimization.py#L50">卷积/批归一化融合</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/examples/blob/master/fx/subgraph_rewriter_basic_use.py">替换模式：基本用法</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/main/quantization.html#prototype-fx-graph-mode-quantization">量化</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/examples/blob/master/fx/invert.py">反转转换</a></p></li>
</ul>
</section>
</section>
<section id="proxy-retracing">
<h3>代理/重绘</h3>
<p>另一种操作 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 的方法是重用符号跟踪中使用的 <code class="xref py py-class docutils literal "><span class="pre">Proxy</span></code> 机制。例如，让我们想象我们想要编写一个将 PyTorch 函数分解成更小操作的转换。它将把每个 <code class="docutils literal "><span class="pre">F.relu(x)</span></code> 调用转换成 <code class="docutils literal "><span class="pre">(x</span> <span class="pre">&gt;</span> <span class="pre">0)</span> <span class="pre">*</span> <span class="pre">x</span></code> 。一种可能性是在 <code class="docutils literal "><span class="pre">F.relu</span></code> 之后插入比较和乘法所需的图重写，然后清理原始的 <code class="docutils literal "><span class="pre">F.relu</span></code> 。然而，我们可以通过使用 <code class="xref py py-class docutils literal "><span class="pre">Proxy</span></code> 对象来自动记录操作到 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 来自动化此过程。</p>
<p>使用此方法，我们将要插入的操作以常规 PyTorch 代码的形式编写，并使用 <code class="xref py py-class docutils literal "><span class="pre">Proxy</span></code> 对象作为参数调用该代码。这些 <code class="xref py py-class docutils literal "><span class="pre">Proxy</span></code> 对象将捕获对它们的操作并将它们追加到 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 。</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="c1"># Note that this decomposition rule can be read as regular Python</span>
<span class="k">def</span> <span class="nf">relu_decomposition</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>

<span class="n">decomposition_rules</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">decomposition_rules</span><span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">]</span> <span class="o">=</span> <span class="n">relu_decomposition</span>

<span class="k">def</span> <span class="nf">decompose</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
              <span class="n">tracer_class</span> <span class="p">:</span> <span class="nb">type</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Tracer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Decompose `model` into smaller constituent operations.</span>
<span class="sd">    Currently,this only supports decomposing ReLU into its</span>
<span class="sd">    mathematical definition: (x &gt; 0) * x</span>
<span class="sd">    """</span>
    <span class="n">graph</span> <span class="p">:</span> <span class="n">fx</span><span class="o">.</span><span class="n">Graph</span> <span class="o">=</span> <span class="n">tracer_class</span><span class="p">()</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">new_graph</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="n">env</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">tracer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">proxy</span><span class="o">.</span><span class="n">GraphAppendingTracer</span><span class="p">(</span><span class="n">new_graph</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s1">'call_function'</span> <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="ow">in</span> <span class="n">decomposition_rules</span><span class="p">:</span>
            <span class="c1"># By wrapping the arguments with proxies,</span>
            <span class="c1"># we can dispatch to the appropriate</span>
            <span class="c1"># decomposition rule and implicitly add it</span>
            <span class="c1"># to the Graph by symbolically tracing it.</span>
            <span class="n">proxy_args</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">fx</span><span class="o">.</span><span class="n">Proxy</span><span class="p">(</span><span class="n">env</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">],</span> <span class="n">tracer</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fx</span><span class="o">.</span><span class="n">Node</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">args</span><span class="p">]</span>
            <span class="n">output_proxy</span> <span class="o">=</span> <span class="n">decomposition_rules</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">](</span><span class="o">*</span><span class="n">proxy_args</span><span class="p">)</span>

            <span class="c1"># Operations on `Proxy` always yield new `Proxy`s, and the</span>
            <span class="c1"># return value of our decomposition rule is no exception.</span>
            <span class="c1"># We need to extract the underlying `Node` from the `Proxy`</span>
            <span class="c1"># to use it in subsequent iterations of this transform.</span>
            <span class="n">new_node</span> <span class="o">=</span> <span class="n">output_proxy</span><span class="o">.</span><span class="n">node</span>
            <span class="n">env</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_node</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Default case: we don't have a decomposition rule for this</span>
            <span class="c1"># node, so just copy the node over into the new graph.</span>
            <span class="n">new_node</span> <span class="o">=</span> <span class="n">new_graph</span><span class="o">.</span><span class="n">node_copy</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">env</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">])</span>
            <span class="n">env</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_node</span>
    <span class="k">return</span> <span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">new_graph</span><span class="p">)</span>
</pre></div>
</div>
<p>除了避免显式图操作外，使用 <code class="xref py py-class docutils literal "><span class="pre">Proxy</span></code> 还可以让您将重写规则指定为原生 Python 代码。对于需要大量重写规则（如 vmap 或 grad）的转换，这通常可以提高规则的可读性和可维护性。请注意，在调用 <code class="xref py py-class docutils literal "><span class="pre">Proxy</span></code> 时，我们还传递了一个指向底层变量图的跟踪器。这样做是为了如果图中的操作是 n 元（例如，add 是一个二元运算符）时，调用 <code class="xref py py-class docutils literal "><span class="pre">Proxy</span></code> 不会创建多个图跟踪器实例，这可能导致意外的运行时错误。我们建议在底层运算符不能安全假设为一元时，特别使用此方法使用 <code class="xref py py-class docutils literal "><span class="pre">Proxy</span></code> 。</p>
<p>使用 <code class="xref py py-class docutils literal "><span class="pre">Proxy</span></code> 进行 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 操作的示例可以在此处找到。</p>
</section>
<section id="the-interpreter-pattern">
<h3>解释器模式 ¶</h3>
<p>在 FX 中，一种有用的代码组织模式是遍历一个模块中的所有 <code class="xref py py-class docutils literal "><span class="pre">Node</span></code> ，并执行它们。这可以用于多种用途，包括对通过图流动的值的运行时分析或通过 <code class="xref py py-class docutils literal "><span class="pre">Proxy</span></code> 进行回溯来转换代码。例如，假设我们想要运行一个 <code class="xref py py-class docutils literal "><span class="pre">GraphModule</span></code> 并记录节点在运行时看到的 <code class="xref py py-class docutils literal "><span class="pre">torch.Tensor</span></code> 形状和 dtype 属性。这可能看起来像：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>
<span class="kn">from</span> <span class="nn">torch.fx.node</span> <span class="kn">import</span> <span class="n">Node</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>

<span class="k">class</span> <span class="nc">ShapeProp</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Shape propagation. This class takes a `GraphModule`.</span>
<span class="sd">    Then, its `propagate` method executes the `GraphModule`</span>
<span class="sd">    node-by-node with the given arguments. As each operation</span>
<span class="sd">    executes, the ShapeProp class stores away the shape and</span>
<span class="sd">    element type for the output values of each operation on</span>
<span class="sd">    the `shape` and `dtype` attributes of the operation's</span>
<span class="sd">    `Node`.</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mod</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mod</span> <span class="o">=</span> <span class="n">mod</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modules</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mod</span><span class="o">.</span><span class="n">named_modules</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">propagate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">args_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="n">env</span> <span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Node</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">def</span> <span class="nf">load_arg</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">map_arg</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="n">env</span><span class="p">[</span><span class="n">n</span><span class="o">.</span><span class="n">name</span><span class="p">])</span>

        <span class="k">def</span> <span class="nf">fetch_attr</span><span class="p">(</span><span class="n">target</span> <span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">target_atoms</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'.'</span><span class="p">)</span>
            <span class="n">attr_itr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mod</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">atom</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">target_atoms</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">attr_itr</span><span class="p">,</span> <span class="n">atom</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Node referenced nonexistent target </span><span class="si">{</span><span class="s1">'.'</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_atoms</span><span class="p">[:</span><span class="n">i</span><span class="p">])</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="n">attr_itr</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">attr_itr</span><span class="p">,</span> <span class="n">atom</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">attr_itr</span>

        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s1">'placeholder'</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">args_iter</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s1">'get_attr'</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">fetch_attr</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s1">'call_function'</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="o">*</span><span class="n">load_arg</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">load_arg</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s1">'call_method'</span><span class="p">:</span>
                <span class="n">self_obj</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span> <span class="o">=</span> <span class="n">load_arg</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">args</span><span class="p">)</span>
                <span class="n">kwargs</span> <span class="o">=</span> <span class="n">load_arg</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="n">result</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">self_obj</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s1">'call_module'</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">](</span><span class="o">*</span><span class="n">load_arg</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">load_arg</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

            <span class="c1"># This is the only code specific to shape propagation.</span>
            <span class="c1"># you can delete this `if` branch and this becomes</span>
            <span class="c1"># a generic GraphModule interpreter.</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">node</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">node</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">dtype</span>

            <span class="n">env</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>

        <span class="k">return</span> <span class="n">load_arg</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>如您所见，FX 的完整解释器并不复杂，但它非常有用。为了简化使用这种模式，我们提供了一个 <code class="xref py py-class docutils literal "><span class="pre">Interpreter</span></code> 类，它以这种方式封装了上述逻辑，使得解释器执行的一些方面可以通过方法重写来覆盖。</p>
<p>除了执行操作外，我们还可以通过将 <code class="xref py py-class docutils literal "><span class="pre">Proxy</span></code> 值通过解释器传递来生成一个新的图。同样，我们提供了一个 <code class="xref py py-class docutils literal "><span class="pre">Transformer</span></code> 类来封装这种模式。 <code class="xref py py-class docutils literal "><span class="pre">Transformer</span></code> 的行为与 <code class="xref py py-class docutils literal "><span class="pre">Interpreter</span></code> 类似，但您不是调用 <code class="docutils literal "><span class="pre">run</span></code> 方法从 Module 获取具体的输出值，而是调用 <code class="xref py py-meth docutils literal "><span class="pre">Transformer.transform()</span></code> 方法返回一个新的 <code class="xref py py-class docutils literal "><span class="pre">GraphModule</span></code> ，该新图已应用您安装的任何转换规则作为重写方法。</p>
<section id="examples-of-the-interpreter-pattern">
<h4>解释器模式的示例</h4>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/fx/passes/shape_prop.py">形状传播</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/tutorials/pull/1319">性能分析器</a></p></li>
</ul>
</section>
</section>
</section>
<section id="debugging">
<h2>调试</h2>
<section id="introduction">
<h3>简介</h3>
<p>在编写变换的过程中，我们的代码可能并不完全正确。在这种情况下，我们可能需要进行一些调试。关键是要逆向工作：首先，检查调用生成的模块的结果以证明或反驳正确性。然后，检查和调试生成的代码。然后，调试导致生成代码的变换过程。</p>
<p>如果您不熟悉调试器，请参阅辅助部分“可用的调试器”。</p>
</section>
<section id="common-pitfalls-in-transform-authoring">
<h3>常见在转换创作中的陷阱 ¶</h3>
<ul class="simple">
<li><p>非确定性的 <code class="docutils literal "><span class="pre">set</span></code> 迭代顺序。在 Python 中， <code class="docutils literal "><span class="pre">set</span></code> 数据类型是无序的。使用 <code class="docutils literal "><span class="pre">set</span></code> 来包含对象集合，例如，可以导致意外的非确定性。一个例子是遍历一组 <code class="docutils literal "><span class="pre">Node</span></code> s 以将其插入到 <code class="docutils literal "><span class="pre">Node</span></code> 。因为 <code class="docutils literal "><span class="pre">Graph</span></code> 数据类型是无序的，输出程序中操作的顺序将是非确定性的，并且可以在程序调用之间发生变化。建议的替代方案是使用 <code class="docutils literal "><span class="pre">set</span></code> 数据类型，该数据类型自 Python 3.7（以及 cPython 3.6）起为插入顺序。可以使用 <code class="docutils literal "><span class="pre">dict</span></code> 相当于一个集合，通过将需要去重的值存储在 <code class="docutils literal "><span class="pre">dict</span></code> 的键中。</p></li>
</ul>
</section>
<section id="checking-correctness-of-modules">
<h3>检查模块的正确性 ¶</h3>
<p>由于大多数深度学习模块的输出由浮点 <code class="xref py py-class docutils literal "><span class="pre">torch.Tensor</span></code> 实例组成，检查两个 <code class="xref py py-class docutils literal "><span class="pre">torch.nn.Module</span></code> 的结果之间的等价性并不像进行简单的相等性检查那样简单。为了说明这一点，让我们用一个例子来说明：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>

<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">m</span> <span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="n">gm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="c1"># Imagine we're doing some transforms here</span>
    <span class="c1"># &lt;...&gt;</span>

    <span class="n">gm</span><span class="o">.</span><span class="n">recompile</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">gm</span>

<span class="n">resnet18</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">()</span>
<span class="n">transformed_resnet18</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">resnet18</span><span class="p">)</span>

<span class="n">input_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span> <span class="o">==</span> <span class="n">transformed_resnet18</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
<span class="sd">"""</span>
<span class="sd">RuntimeError: Boolean value of Tensor with more than one value is ambiguous</span>
<span class="sd">"""</span>
</pre></div>
</div>
<p>在这里，我们尝试使用 <code class="docutils literal "><span class="pre">==</span></code> 等价运算符检查两个深度学习模型的值是否相等。然而，这并不明确，一方面是因为该运算符返回一个张量而不是布尔值，另一方面是因为浮点数的比较应该使用误差范围（或 epsilon）来考虑浮点运算的非交换性（更多详情请见此处）。我们可以使用 <code class="xref py py-func docutils literal "><span class="pre">torch.allclose()</span></code> ，它将给出一个近似比较，考虑到相对和绝对容差阈值：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">resnet18</span><span class="p">(</span><span class="n">input_image</span><span class="p">),</span> <span class="n">transformed_resnet18</span><span class="p">(</span><span class="n">input_image</span><span class="p">))</span>
</pre></div>
</div>
<p>这是我们的工具箱中第一个检查转换后的模块是否按预期与参考实现相比表现良好的工具。</p>
</section>
<section id="debugging-the-generated-code">
<h3>生成代码的调试</h3>
<p>因为 FX 在 <code class="xref py py-class docutils literal "><span class="pre">GraphModule</span></code> 上生成 <code class="docutils literal "><span class="pre">forward()</span></code> 函数，所以使用传统的调试技术，如 <code class="docutils literal "><span class="pre">print</span></code> 语句或 <code class="docutils literal "><span class="pre">pdb</span></code> ，并不那么直接。幸运的是，我们有几种可以用来调试生成代码的技术。</p>
<section id="use-pdb">
<h4>使用 <code class="docutils literal "><span class="pre">pdb</span></code> ¶</h4>
<p>使用 <code class="docutils literal "><span class="pre">pdb</span></code> 进入正在运行的程序。虽然代表 <code class="xref py py-class docutils literal "><span class="pre">Graph</span></code> 的代码不在任何源文件中，但在调用前向传递时，我们仍然可以使用 <code class="docutils literal "><span class="pre">pdb</span></code> 手动进入。</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>

<span class="k">def</span> <span class="nf">my_pass</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">tracer_class</span> <span class="p">:</span> <span class="nb">type</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Tracer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="n">graph</span> <span class="o">=</span> <span class="n">tracer_class</span><span class="p">()</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
    <span class="c1"># Transformation logic here</span>
    <span class="c1"># &lt;...&gt;</span>

    <span class="c1"># Return new Module</span>
    <span class="k">return</span> <span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">graph</span><span class="p">)</span>

<span class="n">my_module</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">()</span>
<span class="n">my_module_transformed</span> <span class="o">=</span> <span class="n">my_pass</span><span class="p">(</span><span class="n">my_module</span><span class="p">)</span>

<span class="n">input_value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>

<span class="c1"># When this line is executed at runtime, we will be dropped into an</span>
<span class="c1"># interactive `pdb` prompt. We can use the `step` or `s` command to</span>
<span class="c1"># step into the execution of the next line</span>
<span class="kn">import</span> <span class="nn">pdb</span><span class="p">;</span> <span class="n">pdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>

<span class="n">my_module_transformed</span><span class="p">(</span><span class="n">input_value</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="print-the-generated-code">
<span id="id2"></span><h4>打印生成的代码 ¶</h4>
<p>如果你想多次运行相同的代码，那么使用 <code class="docutils literal "><span class="pre">pdb</span></code> 步进到正确的代码可能会有些繁琐。在这种情况下，一种方法是将生成的 <code class="docutils literal "><span class="pre">forward</span></code> 传递复制粘贴到你的代码中，并从那里进行检查。</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="c1"># Assume that `traced` is a GraphModule that has undergone some</span>
<span class="c1"># number of transforms</span>

<span class="c1"># Copy this code for later</span>
<span class="nb">print</span><span class="p">(</span><span class="n">traced</span><span class="p">)</span>
<span class="c1"># Print the code generated from symbolic tracing. This outputs:</span>
<span class="sd">"""</span>
<span class="sd">def forward(self, y):</span>
<span class="sd">    x = self.x</span>
<span class="sd">    add_1 = x + y;  x = y = None</span>
<span class="sd">    return add_1</span>
<span class="sd">"""</span>

<span class="c1"># Subclass the original Module</span>
<span class="k">class</span> <span class="nc">SubclassM</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># Paste the generated `forward` function (the one we printed and</span>
    <span class="c1"># copied above) here</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span>
        <span class="n">add_1</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">;</span>  <span class="n">x</span> <span class="o">=</span> <span class="n">y</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">add_1</span>

<span class="c1"># Create an instance of the original, untraced Module. Then, create an</span>
<span class="c1"># instance of the Module with the copied `forward` function. We can</span>
<span class="c1"># now compare the output of both the original and the traced version.</span>
<span class="n">pre_trace</span> <span class="o">=</span> <span class="n">M</span><span class="p">()</span>
<span class="n">post_trace</span> <span class="o">=</span> <span class="n">SubclassM</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="use-the-to-folder-function-from-graphmodule">
<h4>使用 <code class="docutils literal "><span class="pre">to_folder</span></code> 函数从 <code class="docutils literal "><span class="pre">GraphModule</span></code> ¶</h4>
<p> <code class="xref py py-meth docutils literal "><span class="pre">GraphModule.to_folder()</span></code> 是 <code class="docutils literal "><span class="pre">GraphModule</span></code> 中的一个方法，允许您将生成的 FX 代码导出到文件夹。尽管将前向传递复制到代码中通常就足够了，如在“打印生成的代码”中，但使用 <code class="docutils literal "><span class="pre">to_folder</span></code> 可能更容易检查模块和参数。</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">symbolic_trace</span><span class="p">(</span><span class="n">M</span><span class="p">())</span>
<span class="n">m</span><span class="o">.</span><span class="n">to_folder</span><span class="p">(</span><span class="s2">"foo"</span><span class="p">,</span> <span class="s2">"Bar"</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">foo</span> <span class="kn">import</span> <span class="n">Bar</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Bar</span><span class="p">()</span>
</pre></div>
</div>
<p>在运行上述示例之后，我们就可以查看 <code class="docutils literal "><span class="pre">foo/module.py</span></code> 中的代码并根据需要对其进行修改（例如添加 <code class="docutils literal "><span class="pre">print</span></code> 语句或使用 <code class="docutils literal "><span class="pre">pdb</span></code> ）以调试生成的代码。</p>
</section>
</section>
<section id="debugging-the-transformation">
<h3>调试转换 ¶</h3>
<p>现在我们已经确定一个转换正在生成错误的代码，现在是时候调试这个转换本身了。首先，我们将检查文档中的“符号跟踪的限制”部分。一旦我们验证跟踪是否按预期工作，目标就变成了找出我们的 <code class="docutils literal "><span class="pre">GraphModule</span></code> 转换中出了什么问题。在《编写转换》中可能有一个快速的答案，但如果没有，我们有几种方法可以检查我们的跟踪模块：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="c1"># Sample Module</span>
<span class="k">class</span> <span class="nc">M</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>

<span class="c1"># Create an instance of `M`</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">M</span><span class="p">()</span>

<span class="c1"># Symbolically trace an instance of `M` (returns a GraphModule). In</span>
<span class="c1"># this example, we'll only be discussing how to inspect a</span>
<span class="c1"># GraphModule, so we aren't showing any sample transforms for the</span>
<span class="c1"># sake of brevity.</span>
<span class="n">traced</span> <span class="o">=</span> <span class="n">symbolic_trace</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

<span class="c1"># Print the code produced by tracing the module.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">traced</span><span class="p">)</span>
<span class="c1"># The generated `forward` function is:</span>
<span class="sd">"""</span>
<span class="sd">def forward(self, x, y):</span>
<span class="sd">    add = x + y;  x = y = None</span>
<span class="sd">    return add</span>
<span class="sd">"""</span>

<span class="c1"># Print the internal Graph.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">traced</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
<span class="c1"># This print-out returns:</span>
<span class="sd">"""</span>
<span class="sd">graph():</span>
<span class="sd">    %x : [num_users=1] = placeholder[target=x]</span>
<span class="sd">    %y : [num_users=1] = placeholder[target=y]</span>
<span class="sd">    %add : [num_users=1] = call_function[target=operator.add](args = (%x, %y), kwargs = {})</span>
<span class="sd">    return add</span>
<span class="sd">"""</span>

<span class="c1"># Print a tabular representation of the internal Graph.</span>
<span class="n">traced</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">print_tabular</span><span class="p">()</span>
<span class="c1"># This gives us:</span>
<span class="sd">"""</span>
<span class="sd">opcode         name    target                   args    kwargs</span>
<span class="sd">-------------  ------  -----------------------  ------  --------</span>
<span class="sd">placeholder    x       x                        ()      {}</span>
<span class="sd">placeholder    y       y                        ()      {}</span>
<span class="sd">call_function  add     &lt;built-in function add&gt;  (x, y)  {}</span>
<span class="sd">output         output  output                   (add,)  {}</span>
<span class="sd">"""</span>
</pre></div>
</div>
<p>使用上面的实用函数，我们可以比较我们在应用转换前后跟踪的模块。有时，简单的视觉比较就足以追踪到错误。如果仍然不清楚出了什么问题，使用 <code class="docutils literal "><span class="pre">pdb</span></code> 这样的调试器可以是一个好的下一步。</p>
<p>根据上面的例子，考虑以下代码：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="c1"># Sample user-defined function</span>
<span class="k">def</span> <span class="nf">transform_graph</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">tracer_class</span> <span class="p">:</span> <span class="nb">type</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Tracer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="c1"># Get the Graph from our traced Module</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">tracer_class</span><span class="p">()</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Transformations on `g` go here</span>
<span class="sd">    """</span>

    <span class="k">return</span> <span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>

<span class="c1"># Transform the Graph</span>
<span class="n">transformed</span> <span class="o">=</span> <span class="n">transform_graph</span><span class="p">(</span><span class="n">traced</span><span class="p">)</span>

<span class="c1"># Print the new code after our transforms. Check to see if it was</span>
<span class="c1"># what we expected</span>
<span class="nb">print</span><span class="p">(</span><span class="n">transformed</span><span class="p">)</span>
</pre></div>
</div>
<p>使用上面的例子，假设 <code class="docutils literal "><span class="pre">print(traced)</span></code> 的调用显示我们的转换中存在错误。我们想通过调试器找出错误所在。我们启动一个 <code class="docutils literal "><span class="pre">pdb</span></code> 会话。我们可以通过在 <code class="docutils literal "><span class="pre">transform_graph(traced)</span></code> 处中断，然后按 <code class="docutils literal "><span class="pre">s</span></code> “进入” <code class="docutils literal "><span class="pre">transform_graph(traced)</span></code> 的调用来查看转换过程中的情况。</p>
<p>我们也可以通过编辑 <code class="docutils literal "><span class="pre">print_tabular</span></code> 方法来打印图中节点不同的属性。（例如，我们可能想看到节点的 <code class="docutils literal "><span class="pre">input_nodes</span></code> 和 <code class="docutils literal "><span class="pre">users</span></code> 。）</p>
</section>
<section id="available-debuggers">
<span id="id3"></span><h3>可用调试器 §</h3>
<p>最常用的 Python 调试器是 pdb。您可以通过在命令行中输入 <code class="docutils literal "><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">pdb</span> <span class="pre">FILENAME.py</span></code> 以“调试模式”启动您的程序，其中 <code class="docutils literal "><span class="pre">FILENAME</span></code> 是要调试的文件名。之后，您可以使用 <code class="docutils literal "><span class="pre">pdb</span></code> 调试器命令逐步执行您的程序。通常，在开始 <code class="docutils literal "><span class="pre">pdb</span></code> 时设置一个断点（ <code class="docutils literal "><span class="pre">b</span> <span class="pre">LINE-NUMBER</span></code> ），然后调用 <code class="docutils literal "><span class="pre">c</span></code> 运行程序直到该点。这可以防止您必须逐行执行（使用 <code class="docutils literal "><span class="pre">s</span></code> 或 <code class="docutils literal "><span class="pre">n</span></code> ）才能到达想要检查的代码部分。或者，您可以在想要中断的行之前写入 <code class="docutils literal "><span class="pre">import</span> <span class="pre">pdb;</span> <span class="pre">pdb.set_trace()</span></code> 。如果添加 <code class="docutils literal "><span class="pre">pdb.set_trace()</span></code> ，则您的程序将在运行时自动进入调试模式。（换句话说，您可以直接在命令行中输入 <code class="docutils literal "><span class="pre">python</span> <span class="pre">FILENAME.py</span></code> 而不是 <code class="docutils literal "><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">pdb</span> <span class="pre">FILENAME.py</span></code> 。）一旦您以调试模式运行文件，您就可以使用某些命令逐步执行代码并检查程序的内部状态。网上有许多关于 <code class="docutils literal "><span class="pre">pdb</span></code> 的优秀教程，包括 RealPython 的“使用 pdb 进行 Python 调试”。</p>
<p>PyCharm 或 VSCode 等集成开发环境通常内置了调试器。在您的 IDE 中，您可以选择以下方式之一：a) 通过在 IDE 中打开终端窗口（例如 VSCode 中的“视图→终端”）来使用 <code class="docutils literal "><span class="pre">pdb</span></code> ；b) 使用内置的调试器（通常是一个围绕 <code class="docutils literal "><span class="pre">pdb</span></code> 的图形包装器）。</p>
</section>
</section>
<section id="limitations-of-symbolic-tracing">
<span id="id4"></span><h2>符号跟踪的限制</h2>
<p>FX 使用符号跟踪（也称为符号执行）系统来以可转换/可分析的形式捕获程序的语义。该系统是跟踪的，因为它执行程序（实际上是 <code class="xref py py-class docutils literal "><span class="pre">torch.nn.Module</span></code> 或函数）以记录操作。它是符号的，因为在执行过程中通过程序的数据不是真实数据，而是符号（在 FX 术语中为 <code class="xref py py-class docutils literal "><span class="pre">Proxy</span></code> ）。</p>
<p>虽然符号跟踪对于大多数神经网络代码都有效，但它有一些局限性。</p>
<section id="dynamic-control-flow">
<h3>动态控制流</h3>
<p>符号跟踪的主要局限性是它目前不支持动态控制流。也就是说，循环或 <code class="docutils literal "><span class="pre">if</span></code> 语句的条件可能依赖于程序输入的值。</p>
<p>例如，让我们分析以下程序：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">func_to_trace</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">func_to_trace</span><span class="p">)</span>
<span class="sd">"""</span>
<span class="sd">  &lt;...&gt;</span>
<span class="sd">  File "dyn.py", line 6, in func_to_trace</span>
<span class="sd">    if x.sum() &gt; 0:</span>
<span class="sd">  File "pytorch/torch/fx/proxy.py", line 155, in __bool__</span>
<span class="sd">    return self.tracer.to_bool(self)</span>
<span class="sd">  File "pytorch/torch/fx/proxy.py", line 85, in to_bool</span>
<span class="sd">    raise TraceError('symbolically traced variables cannot be used as inputs to control flow')</span>
<span class="sd">torch.fx.proxy.TraceError: symbolically traced variables cannot be used as inputs to control flow</span>
<span class="sd">"""</span>
</pre></div>
</div>
<p> <code class="docutils literal "><span class="pre">if</span></code> 语句的条件依赖于 <code class="docutils literal "><span class="pre">x.sum()</span></code> 的值，而 <code class="docutils literal "><span class="pre">x.sum()</span></code> 的值又依赖于 <code class="docutils literal "><span class="pre">x</span></code> 的值，这是一个函数输入。由于 <code class="docutils literal "><span class="pre">x</span></code> 可以改变（即如果你向跟踪函数传递新的输入张量），这就是动态控制流。回溯会沿着你的代码向上走，以显示这种情况发生的位置。</p>
<section id="static-control-flow">
<h4>静态控制流 ¶</h4>
<p>另一方面，所谓的静态控制流得到了支持。静态控制流是指值在调用之间不能改变的循环或 <code class="docutils literal "><span class="pre">if</span></code> 语句。通常，在 PyTorch 程序中，这种控制流出现在根据超参数做出决策的代码中。作为一个具体的例子：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>

<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">do_activation</span> <span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_activation</span> <span class="o">=</span> <span class="n">do_activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># This if-statement is so-called static control flow.</span>
        <span class="c1"># Its condition does not depend on any input values</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_activation</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">without_activation</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">(</span><span class="n">do_activation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">with_activation</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">(</span><span class="n">do_activation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">traced_without_activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">without_activation</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">traced_without_activation</span><span class="o">.</span><span class="n">code</span><span class="p">)</span>
<span class="sd">"""</span>
<span class="sd">def forward(self, x):</span>
<span class="sd">    linear_1 = self.linear(x);  x = None</span>
<span class="sd">    return linear_1</span>
<span class="sd">"""</span>

<span class="n">traced_with_activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">with_activation</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">traced_with_activation</span><span class="o">.</span><span class="n">code</span><span class="p">)</span>
<span class="sd">"""</span>
<span class="sd">import torch</span>
<span class="sd">def forward(self, x):</span>
<span class="sd">    linear_1 = self.linear(x);  x = None</span>
<span class="sd">    relu_1 = torch.relu(linear_1);  linear_1 = None</span>
<span class="sd">    return relu_1</span>
<span class="sd">"""</span>
</pre></div>
</div>
<p>if-语句 <code class="docutils literal "><span class="pre">if</span> <span class="pre">self.do_activation</span></code> 不依赖于任何函数输入，因此它是静态的。 <code class="docutils literal "><span class="pre">do_activation</span></code> 可以被视为一个超参数，而 <code class="docutils literal "><span class="pre">MyModule</span></code> 的不同实例的痕迹，该参数有不同的值，有不同的代码。这是一个有效的模式，也是符号跟踪所支持的。</p>
<p>许多动态控制流的实例在语义上是静态控制流。通过移除对输入值的依赖，例如通过将值移动到 <code class="docutils literal "><span class="pre">Module</span></code> 属性或绑定具体值到符号跟踪期间的参数，可以将这些实例转换为支持符号跟踪：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">flag</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">flag</span><span class="p">:</span> <span class="k">return</span> <span class="n">x</span>
    <span class="k">else</span><span class="p">:</span> <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="mi">2</span>

<span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="c1"># Fails!</span>

<span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">concrete_args</span><span class="o">=</span><span class="p">{</span><span class="s1">'flag'</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
</pre></div>
</div>
<p>对于真正的动态控制流，包含此代码的程序部分可以被视为对方法（请参阅使用 Tracer 类自定义跟踪）或函数（请参阅 <code class="xref py py-func docutils literal "><span class="pre">wrap()</span></code> ）的调用，而不是通过它们进行跟踪。</p>
</section>
</section>
<section id="non-torch-functions">
<h3>非函数 <code class="docutils literal "><span class="pre">torch</span></code> </h3>
<p>FX 使用 <code class="docutils literal "><span class="pre">__torch_function__</span></code> 作为拦截调用的机制（有关此内容的更多信息，请参阅技术概述）。一些函数，例如内置的 Python 函数或 <code class="docutils literal "><span class="pre">math</span></code> 模块中的函数，不受 <code class="docutils literal "><span class="pre">__torch_function__</span></code> 的保护，但我们仍然希望将它们捕获在符号跟踪中。例如：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>

<span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Normalize `x` by the size of the batch dimension</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="c1"># It's valid Python code</span>
<span class="n">normalize</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">normalize</span><span class="p">)</span>
<span class="sd">"""</span>
<span class="sd">  &lt;...&gt;</span>
<span class="sd">  File "sqrt.py", line 9, in normalize</span>
<span class="sd">    return x / sqrt(len(x))</span>
<span class="sd">  File "pytorch/torch/fx/proxy.py", line 161, in __len__</span>
<span class="sd">    raise RuntimeError("'len' is not supported in symbolic tracing by default. If you want "</span>
<span class="sd">RuntimeError: 'len' is not supported in symbolic tracing by default. If you want this call to be recorded, please call torch.fx.wrap('len') at module scope</span>
<span class="sd">"""</span>
</pre></div>
</div>
<p>错误提示我们内置函数 <code class="docutils literal "><span class="pre">len</span></code> 不受支持。我们可以使此类函数在跟踪中以直接调用方式记录，使用 <code class="xref py py-func docutils literal "><span class="pre">wrap()</span></code> API：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span><span class="p">(</span><span class="s1">'len'</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span><span class="p">(</span><span class="s1">'sqrt'</span><span class="p">)</span>

<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">normalize</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">traced</span><span class="o">.</span><span class="n">code</span><span class="p">)</span>
<span class="sd">"""</span>
<span class="sd">import math</span>
<span class="sd">def forward(self, x):</span>
<span class="sd">    len_1 = len(x)</span>
<span class="sd">    sqrt_1 = math.sqrt(len_1);  len_1 = None</span>
<span class="sd">    truediv = x / sqrt_1;  x = sqrt_1 = None</span>
<span class="sd">    return truediv</span>
<span class="sd">"""</span>
</pre></div>
</div>
</section>
<section id="customizing-tracing-with-the-tracer-class">
<span id="customizing-tracing"></span><h3>使用 <code class="docutils literal "><span class="pre">Tracer</span></code> 类定制跟踪 ¶</h3>
<p> <code class="xref py py-class docutils literal "><span class="pre">Tracer</span></code> 类是实现 <code class="docutils literal "><span class="pre">symbolic_trace</span></code> 的底层类。可以通过子类化 Tracer 来自定义跟踪的行为，如下所示：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyCustomTracer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Tracer</span><span class="p">):</span>
    <span class="c1"># Inside here you can override various methods</span>
    <span class="c1"># to customize tracing. See the `Tracer` API</span>
    <span class="c1"># reference</span>
    <span class="k">pass</span>


<span class="c1"># Let's use this custom tracer to trace through this module</span>
<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">mod</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">()</span>

<span class="n">traced_graph</span> <span class="o">=</span> <span class="n">MyCustomTracer</span><span class="p">()</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
<span class="c1"># trace() returns a Graph. Let's wrap it up in a</span>
<span class="c1"># GraphModule to make it runnable</span>
<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">traced_graph</span><span class="p">)</span>
</pre></div>
</div>
<section id="leaf-modules">
<h4>叶模块</h4>
<p>叶模块是出现在符号跟踪中的调用模块，而不是通过跟踪实现的模块。默认的叶模块集是标准 <code class="docutils literal "><span class="pre">torch.nn</span></code> 模块实例的集合。例如：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpecialSubmodule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">submod</span> <span class="o">=</span> <span class="n">MySpecialSubmodule</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">submod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">MyModule</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">traced</span><span class="o">.</span><span class="n">code</span><span class="p">)</span>
<span class="c1"># `linear` is preserved as a call, yet `submod` is traced though.</span>
<span class="c1"># This is because the default set of "Leaf Modules" includes all</span>
<span class="c1"># standard `torch.nn` modules.</span>
<span class="sd">"""</span>
<span class="sd">import torch</span>
<span class="sd">def forward(self, x):</span>
<span class="sd">    linear_1 = self.linear(x);  x = None</span>
<span class="sd">    neg_1 = torch.neg(linear_1);  linear_1 = None</span>
<span class="sd">    return neg_1</span>
<span class="sd">"""</span>
</pre></div>
</div>
<p>可以通过覆盖 <code class="xref py py-meth docutils literal "><span class="pre">Tracer.is_leaf_module()</span></code> 来自定义叶模块集。</p>
</section>
</section>
<section id="miscellanea">
<h3>杂项 ¶</h3>
<ul>
<li><p>索引构造函数（例如 <code class="docutils literal "><span class="pre">torch.zeros</span></code> ， <code class="docutils literal "><span class="pre">torch.ones</span></code> ， <code class="docutils literal "><span class="pre">torch.rand</span></code> ， <code class="docutils literal "><span class="pre">torch.randn</span></code> ， <code class="docutils literal "><span class="pre">torch.sparse_coo_tensor</span></code> ）目前无法追踪。</p>
<ul class="simple">
<li><p>确定性构造函数（ <code class="docutils literal "><span class="pre">zeros</span></code> ， <code class="docutils literal "><span class="pre">ones</span></code> ）可以使用，它们产生的值将被嵌入到追踪中作为常量。这只有在这些构造函数的参数引用动态输入大小时才会成为问题。在这种情况下， <code class="docutils literal "><span class="pre">ones_like</span></code> 或 <code class="docutils literal "><span class="pre">zeros_like</span></code> 可能是可行的替代品。</p></li>
<li><p>非确定性构造函数（ <code class="docutils literal "><span class="pre">rand</span></code> ， <code class="docutils literal "><span class="pre">randn</span></code> ）将在追踪中嵌入单个随机值。这很可能不是预期的行为。一种解决方案是将 <code class="docutils literal "><span class="pre">torch.randn</span></code> 包裹在 <code class="docutils literal "><span class="pre">torch.fx.wrap</span></code> 函数中，并调用该函数。</p></li>
</ul>
<blockquote>
<div><div class="highlight-default "><div class="highlight"><pre><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span>
<span class="k">def</span> <span class="nf">torch_randn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">torch_randn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<ul class="simple">
<li><p>该行为可能在未来的版本中得到修复。</p></li>
</ul>
</li>
<li><p>类型注解</p>
<ul class="simple">
<li><p>支持 Python 3 风格的类型注解（例如 <code class="docutils literal "><span class="pre">func(x</span> <span class="pre">:</span> <span class="pre">torch.Tensor,</span> <span class="pre">y</span> <span class="pre">:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">torch.Tensor</span></code> ），并且符号跟踪将保留这些注解。</p></li>
<li><p>目前不支持 Python 2 风格的注释类型注解 <code class="docutils literal "><span class="pre">#</span> <span class="pre">type:</span> <span class="pre">(torch.Tensor,</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">torch.Tensor</span></code> 。</p></li>
<li><p>函数内部对局部名称的注释目前不支持。</p></li>
</ul>
</li>
<li><p>关于 <code class="docutils literal "><span class="pre">training</span></code> 标志和子模块的注意事项。</p>
<ul class="simple">
<li><p>当使用 <code class="docutils literal "><span class="pre">torch.nn.functional.dropout</span></code> 等函数时，训练参数通常会被传递为 <code class="docutils literal "><span class="pre">self.training</span></code> 。在 FX 追踪期间，这很可能会被固化为一个常量值。</p></li>
</ul>
<blockquote>
<div><div class="highlight-default "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>

<span class="k">class</span> <span class="nc">DropoutRepro</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>


<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">DropoutRepro</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">traced</span><span class="o">.</span><span class="n">code</span><span class="p">)</span>
<span class="sd">"""</span>
<span class="sd">def forward(self, x):</span>
<span class="sd">  dropout = torch.nn.functional.dropout(x, p = 0.5, training = True, inplace = False);  x = None</span>
<span class="sd">  return dropout</span>
<span class="sd">"""</span>

<span class="n">traced</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span><span class="n">traced</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>
<span class="sd">"""</span>
<span class="sd">AssertionError: Tensor-likes are not close!</span>

<span class="sd">Mismatched elements: 15 / 15 (100.0%)</span>
<span class="sd">Greatest absolute difference: 1.6207983493804932 at index (0, 2) (up to 1e-05 allowed)</span>
<span class="sd">Greatest relative difference: 1.0 at index (0, 0) (up to 0.0001 allowed)</span>
<span class="sd">"""</span>
</pre></div>
</div>
</div></blockquote>
<ul class="simple">
<li><p>然而，当使用标准 <code class="docutils literal "><span class="pre">nn.Dropout()</span></code> 子模块时，训练标志被封装，并且由于保留了 <code class="docutils literal "><span class="pre">nn.Module</span></code> 对象模型，可以更改。</p></li>
</ul>
<blockquote>
<div><div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DropoutRepro2</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">DropoutRepro2</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">traced</span><span class="o">.</span><span class="n">code</span><span class="p">)</span>
<span class="sd">"""</span>
<span class="sd">def forward(self, x):</span>
<span class="sd">  drop = self.drop(x);  x = None</span>
<span class="sd">  return drop</span>
<span class="sd">"""</span>

<span class="n">traced</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span><span class="n">traced</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
<blockquote>
<div><ul class="simple">
<li><p>由于这种差异，请考虑将动态交互 <code class="docutils literal "><span class="pre">training</span></code> 标志的模块标记为叶模块。</p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="api-reference">
<h2>API 参考指南</h2>
<dl class="py function">
<dt class="sig sig-object py" id="torch.fx.symbolic_trace">
torch.fx.symbolic_trace(root, concrete_args=None)[source][source] 参考指南</dt>
<dd><p>符号追踪 API</p>
<p>给定一个 <code class="docutils literal "><span class="pre">nn.Module</span></code> 或函数实例 <code class="docutils literal "><span class="pre">root</span></code> ，此函数将返回一个通过记录在 <code class="docutils literal "><span class="pre">root</span></code> 中看到的操作所构建的 <code class="docutils literal "><span class="pre">GraphModule</span></code> 。</p>
<p> <code class="docutils literal "><span class="pre">concrete_args</span></code> 允许您部分专门化您的函数，无论是要移除控制流还是数据结构。</p>
<p>例如：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">b</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">a</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="mi">2</span>
</pre></div>
</div>
<p>由于存在控制流，FX 通常无法追踪此操作。但是，我们可以使用 concrete_args 来专门化 b 的值以追踪此操作：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">concrete_args</span><span class="o">=</span><span class="p">{</span><span class="s2">"b"</span><span class="p">:</span> <span class="kc">False</span><span class="p">})</span>
<span class="k">assert</span> <span class="n">f</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="o">==</span> <span class="mi">6</span>
</pre></div>
</div>
<p>注意，尽管您仍然可以传入不同的 b 值，但它们将被忽略。</p>
<p>我们还可以使用 concrete_args 来消除函数中的数据结构处理。这将使用 pytrees 来简化您的输入。为了避免过度专业化，对于不应专业化的值，请传入 fx.PH。例如：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="n">out</span> <span class="o">+=</span> <span class="n">v</span>
    <span class="k">return</span> <span class="n">out</span>


<span class="n">f</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">concrete_args</span><span class="o">=</span><span class="p">{</span><span class="s2">"x"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"a"</span><span class="p">:</span> <span class="n">fx</span><span class="o">.</span><span class="n">PH</span><span class="p">,</span> <span class="s2">"b"</span><span class="p">:</span> <span class="n">fx</span><span class="o">.</span><span class="n">PH</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">:</span> <span class="n">fx</span><span class="o">.</span><span class="n">PH</span><span class="p">}})</span>
<span class="k">assert</span> <span class="n">f</span><span class="p">({</span><span class="s2">"a"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">"b"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">:</span> <span class="mi">4</span><span class="p">})</span> <span class="o">==</span> <span class="mi">7</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>root (Union[torch.nn.Module, Callable]) – 要追踪和转换为图表示的模块或函数。</p></li>
<li><p>concrete_args (Optional[Dict[str, any]]) – 部分专业化的输入</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>由 <code class="docutils literal "><span class="pre">root</span></code> 记录的操作创建的模块</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.fx.GraphModule" title="torch.fx.GraphModule">图模块</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torch.fx.wrap">
<span class="sig-prename descclassname"><span class="pre">torch.fx.</span></span><span class="sig-name descname"><span class="pre">wrap</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn_or_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/_symbolic_trace.html#wrap"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/_symbolic_trace.py#L1195"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.wrap" title="Permalink to this definition">¶</a></dt>
<dd><p>此函数可以在模块级作用域中调用，将 fn_or_name 注册为“叶子函数”。一个“叶子函数”将被保留为 FX 跟踪中的 CallFunction 节点，而不是被跟踪：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="c1"># foo/bar/baz.py</span>
<span class="k">def</span> <span class="nf">my_custom_function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">y</span>


<span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span><span class="p">(</span><span class="s2">"my_custom_function"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">fn_to_be_traced</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="c1"># When symbolic tracing, the below call to my_custom_function will be inserted into</span>
    <span class="c1"># the graph rather than tracing it.</span>
    <span class="k">return</span> <span class="n">my_custom_function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>此函数也可以等效地用作装饰器：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="c1"># foo/bar/baz.py</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span>
<span class="k">def</span> <span class="nf">my_custom_function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">y</span>
</pre></div>
</div>
<p>被包装的函数可以被视为“叶子函数”，类似于“叶子模块”的概念，即它们是保留在 FX 跟踪中的调用，而不是被跟踪的函数。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>fn_or_name (Union[str, Callable]) – 当调用时，将函数或全局函数的名称插入到图中的函数</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 保证向后兼容性。</p>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch.fx.GraphModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch.fx.</span></span><span class="sig-name descname"><span class="pre">GraphModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph_module.html#GraphModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph_module.py#L409"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.GraphModule" title="Permalink to this definition">¶</a></dt>
<dd><p>GraphModule 是由 fx.Graph 生成的 nn.Module。Graphmodule 具有从 <code class="docutils literal "><span class="pre">graph</span></code> 属性生成的 <code class="docutils literal "><span class="pre">code</span></code> 以及 <code class="docutils literal "><span class="pre">forward</span></code> 和 <code class="docutils literal "><span class="pre">graph</span></code> 属性。</p>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>当 <code class="docutils literal "><span class="pre">graph</span></code> 被重新赋值时， <code class="docutils literal "><span class="pre">code</span></code> 和 <code class="docutils literal "><span class="pre">forward</span></code> 将会自动重新生成。然而，如果您编辑了 <code class="docutils literal "><span class="pre">graph</span></code> 的内容而没有重新赋值 <code class="docutils literal "><span class="pre">graph</span></code> 属性本身，您必须调用 <code class="docutils literal "><span class="pre">recompile()</span></code> 来更新生成的代码。</p>
</div>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 保证向后兼容。</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.GraphModule.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'GraphModule'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph_module.html#GraphModule.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph_module.py#L443"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.GraphModule.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>构建一个 GraphModule。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>root (Union[torch.nn.Module, Dict[str, Any]) – <code class="docutils literal "><span class="pre">root</span></code> 可以是 nn.Module 实例或映射字符串到任何属性类型的 Dict。如果 <code class="docutils literal "><span class="pre">root</span></code> 是 Module，则 Graph 的 Nodes 的 <code class="docutils literal "><span class="pre">target</span></code> 字段中通过限定名称引用的基于 Module 的对象将被从 <code class="docutils literal "><span class="pre">root</span></code> 的 Module 层级复制到 GraphModule 的模块层级。如果 <code class="docutils literal "><span class="pre">root</span></code> 是 dict，则 Node 的 <code class="docutils literal "><span class="pre">target</span></code> 中找到的限定名称将直接在 dict 的键中查找。映射到 Dict 的对象将被复制到 GraphModule 的模块层级中相应的位置。</p></li>
<li><p>图（图）- <code class="docutils literal "><span class="pre">graph</span></code> 包含此 GraphModule 应使用的节点以进行代码生成</p></li>
<li><p>class_name（字符串）- <code class="docutils literal "><span class="pre">name</span></code> 表示此 GraphModule 的调试名称。如果未设置，所有错误消息都将报告为来自 <code class="docutils literal "><span class="pre">GraphModule</span></code> 。将其设置为 <code class="docutils literal "><span class="pre">root</span></code> 的原始名称或适合您转换上下文的名称可能很有帮助。</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.GraphModule.add_submodule">
add_submodule(target, m)[源代码][源代码] ¶</dt>
<dd><p>将给定的子模块添加到 <code class="docutils literal "><span class="pre">self</span></code> 。</p>
<p>如果不存在，则安装空的模块，这些模块是 <code class="docutils literal "><span class="pre">target</span></code> 的子路径。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>target (str) – 新子模块的完全限定字符串名称（参见 <code class="docutils literal "><span class="pre">nn.Module.get_submodule</span></code> 中的示例，了解如何指定完全限定字符串。）</p></li>
<li><p>m (Module) – 子模块本身；我们想要安装到当前模块的实际对象</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p></p><dl class="simple">
<dt>子模块是否可以插入。</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">此方法返回 True，链中的每个对象（由 <code class="docutils literal "><span class="pre">target</span></code> 表示）必须满足以下条件之一：a)尚不存在，或 b)引用 <code class="docutils literal "><span class="pre">nn.Module</span></code> （不是参数或其他属性）</p>
</dd>
</dl>
<p></p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">布尔型</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 的后向兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch.fx.GraphModule.code">
属性 codestr ¶</dt>
<dd><p>返回由 <code class="docutils literal "><span class="pre">Graph</span></code> 生成的 Python 代码。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.GraphModule.delete_all_unused_submodules">
<span class="sig-name descname"><span class="pre">delete_all_unused_submodules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph_module.html#GraphModule.delete_all_unused_submodules"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph_module.py#L733"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.GraphModule.delete_all_unused_submodules" title="Permalink to this definition">¶</a></dt>
<dd><p>从 <code class="docutils literal "><span class="pre">self</span></code> 中删除所有未使用的子模块。</p>
<p>模块被认为“被使用”，如果以下任何一个条件成立：1. 它有被使用的子模块 2. 它的前向操作通过一个 <code class="docutils literal "><span class="pre">call_module</span></code> 节点直接调用 3. 它有一个非模块属性，该属性从一个 <code class="docutils literal "><span class="pre">get_attr</span></code> 节点被使用</p>
<p>可以调用此方法来清理 <code class="docutils literal "><span class="pre">nn.Module</span></code> ，而无需手动对每个未使用的子模块调用 <code class="docutils literal "><span class="pre">delete_submodule</span></code> 。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.GraphModule.delete_submodule">
<span class="sig-name descname"><span class="pre">delete_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph_module.html#GraphModule.delete_submodule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph_module.py#L691"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.GraphModule.delete_submodule" title="Permalink to this definition">¶</a></dt>
<dd><p>从 <code class="docutils literal "><span class="pre">self</span></code> 中删除指定的子模块。</p>
<p>模块在 <code class="docutils literal "><span class="pre">target</span></code> 不是一个有效目标时不会被删除。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>目标（字符串）- 新子模块的完全限定字符串名称（参见 <code class="docutils literal "><span class="pre">nn.Module.get_submodule</span></code> 中的示例，了解如何指定完全限定字符串。）</p>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p></p><dl class="simple">
<dt>无论目标字符串是否引用了</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">子模块我们要删除。返回值 <code class="docutils literal "><span class="pre">False</span></code> 表示 <code class="docutils literal "><span class="pre">target</span></code> 不是一个有效的子模块引用。</p>
</dd>
</dl>
<p></p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">布尔型</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 保证向后兼容。</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch.fx.GraphModule.graph">
属性图 Graph ¶</dt>
<dd><p>返回此 <code class="docutils literal "><span class="pre">Graph</span></code> 的底层 <code class="docutils literal "><span class="pre">GraphModule</span></code> </p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.GraphModule.print_readable">
打印可读输出（print_output=True，include_stride=False，include_device=False，colored=False）[source][source] ¶</dt>
<dd><p>返回当前 GraphModule 及其子 GraphModule 生成的 Python 代码</p>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>此 API 为实验性，且不向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.GraphModule.recompile">
<span class="sig-name descname"><span class="pre">recompile</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph_module.html#GraphModule.recompile"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph_module.py#L800"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.GraphModule.recompile" title="Permalink to this definition">¶</a></dt>
<dd><p>从其 <code class="docutils literal "><span class="pre">graph</span></code> 属性重新编译此 GraphModule。编辑包含的 <code class="docutils literal "><span class="pre">graph</span></code> 之后，应该调用此操作，否则此 <code class="docutils literal "><span class="pre">GraphModule</span></code> 生成的代码将过时。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性有保证。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Python 代码</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.GraphModule.to_folder">
<span class="sig-name descname"><span class="pre">to_folder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">folder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'FxModule'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph_module.html#GraphModule.to_folder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph_module.py#L568"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.GraphModule.to_folder" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>输出模块到 <code class="docutils literal "><span class="pre">folder</span></code> ，使用 <code class="docutils literal "><span class="pre">module_name</span></code> 以便可以</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">使用 <code class="docutils literal "><span class="pre">from</span> <span class="pre">&lt;folder&gt;</span> <span class="pre">import</span> <span class="pre">&lt;module_name&gt;</span></code> 导入</p>
<p>Args:</p>
<blockquote>
<div><p>文件夹（Union[str, os.PathLike]）：输出代码的文件夹</p>
<dl class="simple">
<dt>module_name (str)：用于 <code class="docutils literal "><span class="pre">Module</span></code> while 的顶级名称</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出代码</p>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>此 API 为实验性，且不向后兼容。</p>
</div>
<dl class="field-list simple">
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch.fx.Graph">
class torch.fx.Graph(拥有模块=None, 跟踪器类=None, 跟踪器额外参数=None)[source][source] ¶</dt>
<dd><p> <code class="docutils literal "><span class="pre">Graph</span></code> 是 FX 中间表示法中使用的最主要的数据结构。它由一系列 <code class="docutils literal "><span class="pre">Node</span></code> 组成，每个 <code class="docutils literal "><span class="pre">Node</span></code> 代表一个调用点（或其他语法结构）。 <code class="docutils literal "><span class="pre">Node</span></code> 的列表，合在一起，构成一个有效的 Python 函数。</p>
<p>例如，以下代码</p>
<div class="highlight-python "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>


<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">relu</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">3</span>
        <span class="p">)</span>


<span class="n">m</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">()</span>
<span class="n">gm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
<p>将产生以下 Graph：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text "><div class="highlight"><pre><span></span>graph(x):
    %linear_weight : [num_users=1] = self.linear.weight
    %add_1 : [num_users=1] = call_function[target=operator.add](args = (%x, %linear_weight), kwargs = {})
    %linear_1 : [num_users=1] = call_module[target=linear](args = (%add_1,), kwargs = {})
    %relu_1 : [num_users=1] = call_method[target=relu](args = (%linear_1,), kwargs = {})
    %sum_1 : [num_users=1] = call_function[target=torch.sum](args = (%relu_1,), kwargs = {dim: -1})
    %topk_1 : [num_users=1] = call_function[target=torch.topk](args = (%sum_1, 3), kwargs = {})
    return topk_1
</pre></div>
</div>
<p>关于在 <code class="docutils literal "><span class="pre">Graph</span></code> 中表示的操作的语义，请参阅 <code class="xref py py-class docutils literal "><span class="pre">Node</span></code> 。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 保证向下兼容。</p>
</div>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">owning_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tracer_cls</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tracer_extras</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L960"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>构建一个空图。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 保证向后兼容。</p>
</div>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.call_function">
<span class="sig-name descname"><span class="pre">call_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">the_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_expr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.call_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1439"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.call_function" title="Permalink to this definition">¶</a></dt>
<dd><p>在 <code class="docutils literal "><span class="pre">Graph</span></code> 中插入 <code class="docutils literal "><span class="pre">call_function</span></code> <code class="docutils literal "><span class="pre">Node</span></code> 。一个 <code class="docutils literal "><span class="pre">call_function</span></code> 节点表示对 Python 可调用对象的调用，该对象由 <code class="docutils literal "><span class="pre">the_function</span></code> 指定。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>the_function (Callable[..., Any]) – 要调用的函数。可以是任何 PyTorch 操作符、Python 函数或 <code class="docutils literal "><span class="pre">builtins</span></code> 或 <code class="docutils literal "><span class="pre">operator</span></code> 命名空间中的成员。</p></li>
<li><p>args (可选[Tuple[Argument, ...]]) – 要传递给被调用函数的位置参数。</p></li>
<li><p>kwargs (可选[Dict[str, Argument]]) – 要传递给被调用函数的关键字参数</p></li>
<li><p>type_expr (可选[Any]) – 表示此节点输出将具有的 Python 类型的可选类型注解。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>新创建并插入的 <code class="docutils literal "><span class="pre">call_function</span></code> 节点。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.fx.Node" title="torch.fx.node.Node"><em>节点</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法的插入点类型表达式规则与 <code class="xref py py-meth docutils literal "><span class="pre">Graph.create_node()</span></code> 相同。</p>
</div>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.call_method">
<span class="sig-name descname"><span class="pre">call_method</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">method_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_expr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.call_method"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1400"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.call_method" title="Permalink to this definition">¶</a></dt>
<dd><p>在 <code class="docutils literal "><span class="pre">Graph</span></code> 中插入 <code class="docutils literal "><span class="pre">call_method</span></code> <code class="docutils literal "><span class="pre">Node</span></code> 。一个 <code class="docutils literal "><span class="pre">call_method</span></code> 节点表示对 <code class="docutils literal "><span class="pre">args</span></code> 的第 0 个元素调用给定方法。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>method_name (str) – 要应用到 self 参数上的方法名称。例如，如果 args[0]是一个表示 <code class="docutils literal "><span class="pre">Tensor</span></code> 的 <code class="docutils literal "><span class="pre">Node</span></code> ，那么要调用 <code class="docutils literal "><span class="pre">Tensor</span></code> 上的 <code class="docutils literal "><span class="pre">relu()</span></code> ，需要将 <code class="docutils literal "><span class="pre">relu</span></code> 传递给 <code class="docutils literal "><span class="pre">method_name</span></code> 。</p></li>
<li><p>args (Optional[Tuple[Argument, ...]]) – 要传递给被调用方法的定位参数。注意，这应该包括一个 <code class="docutils literal "><span class="pre">self</span></code> 参数。</p></li>
<li><p>kwargs (Optional[Dict[str, Argument]]) – 要传递给被调用方法的键值参数</p></li>
<li><p>type_expr (Optional[Any]) – 表示此节点输出将具有的 Python 类型的可选类型注解。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>新创建并插入的 <code class="docutils literal "><span class="pre">call_method</span></code> 节点。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.fx.Node" title="torch.fx.node.Node"><em>节点</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法的插入点和类型表达式规则与 <code class="xref py py-meth docutils literal "><span class="pre">Graph.create_node()</span></code> 相同。</p>
</div>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 保证向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.call_module">
<span class="sig-name descname"><span class="pre">call_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_expr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.call_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1350"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.call_module" title="Permalink to this definition">¶</a></dt>
<dd><p>在 <code class="docutils literal "><span class="pre">Graph</span></code> 中插入 <code class="docutils literal "><span class="pre">call_module</span></code> <code class="docutils literal "><span class="pre">Node</span></code> 。一个 <code class="docutils literal "><span class="pre">call_module</span></code> 节点代表对 <code class="docutils literal "><span class="pre">Module</span></code> 层次结构中 <code class="docutils literal "><span class="pre">Module</span></code> 的 forward()函数的调用。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>module_name (str) – 要调用的 <code class="docutils literal "><span class="pre">Module</span></code> 在 <code class="docutils literal "><span class="pre">Module</span></code> 层次结构中的限定名称。例如，如果被跟踪的 <code class="docutils literal "><span class="pre">Module</span></code> 有一个名为 <code class="docutils literal "><span class="pre">foo</span></code> 的子模块，该子模块有一个名为 <code class="docutils literal "><span class="pre">bar</span></code> 的子模块，则应将限定名称 <code class="docutils literal "><span class="pre">foo.bar</span></code> 作为 <code class="docutils literal "><span class="pre">module_name</span></code> 传递以调用该模块。</p></li>
<li><p>args（可选[Tuple[Argument, ...]]）- 要传递给调用方法的定位参数。请注意，此参数不应包括 <code class="docutils literal "><span class="pre">self</span></code> 参数。</p></li>
<li><p>kwargs（可选[Dict[str, Argument]]）- 要传递给调用方法的键值参数</p></li>
<li><p>type_expr（可选[Any]）- 表示此节点输出将具有的 Python 类型的可选类型注解。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>新创建并插入的 <code class="docutils literal "><span class="pre">call_module</span></code> 节点。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.fx.Node" title="torch.fx.node.Node"><em>节点</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法的插入点类型表达式规则与 <code class="xref py py-meth docutils literal "><span class="pre">Graph.create_node()</span></code> 相同。</p>
</div>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.create_node">
<span class="sig-name descname"><span class="pre">create_node</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">op</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_expr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.create_node"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1087"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.create_node" title="Permalink to this definition">¶</a></dt>
<dd><p>创建一个 <code class="docutils literal "><span class="pre">Node</span></code> 并将其添加到当前插入点处的 <code class="docutils literal "><span class="pre">Graph</span></code> 。请注意，当前插入点可以通过 <code class="xref py py-meth docutils literal "><span class="pre">Graph.inserting_before()</span></code> 和 <code class="xref py py-meth docutils literal "><span class="pre">Graph.inserting_after()</span></code> 设置。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>op (str) – 此节点的操作码。可以是 'call_function'、'call_method'、'get_attr'、'call_module'、'placeholder' 或 'output' 之一。这些操作码的语义在 <code class="docutils literal "><span class="pre">Graph</span></code> 文档字符串中描述。</p></li>
<li><p>args (Optional[Tuple[Argument, ...]]) – 是一个包含此节点参数的元组。</p></li>
<li><p>kwargs (Optional[Dict[str, Argument]]) – 此节点的 kwargs</p></li>
<li><p>可选的字符串名称（Optional[str]） - 为 <code class="docutils literal "><span class="pre">Node</span></code> . 分配的值提供可选的字符串名称。这将影响 Python 生成的代码中分配的值名称。</p></li>
<li><p>类型表达式（Optional[Any]） - 表示此节点输出将具有的 Python 类型的可选类型注解。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>新创建并插入的节点。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.fx.Node" title="torch.fx.node.Node"><em>节点</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 保证向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.eliminate_dead_code">
<span class="sig-name descname"><span class="pre">eliminate_dead_code</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">is_impure_node</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.eliminate_dead_code"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1786"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.eliminate_dead_code" title="Permalink to this definition">¶</a></dt>
<dd><p>根据每个节点的用户数量以及节点是否有副作用，从图中删除所有死代码。调用之前必须对图进行拓扑排序。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>is_impure_node (Optional[Callable[[Node], bool]]) – 一个返回</p></li>
<li><p>（节点是否不纯。如果是） –</p></li>
<li><p>（那么默认行为是） –</p></li>
<li><p>（使用）Node.is_impure. –</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>（该图是否因为该遍历而改变。）</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">布尔型</a></p>
</dd>
</dl>
<p>示例：</p>
<p>在消除死代码之前，一个如下的 a = x + 1 没有用户，因此可以从图中删除而不会产生影响。</p>
<div class="highlight-python "><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr_1</span>
</pre></div>
</div>
<p>在消除死代码之后，a = x + 1 已被删除，其余的前向操作仍然保留。</p>
<div class="highlight-python "><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr_1</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>死代码消除有一些启发式方法来避免删除有副作用的节点（见 Node.is_impure），但总体覆盖率非常差，因此你应该假设除非你知道你的 FX 图完全由函数操作组成，或者你提供了自己的自定义函数来检测有副作用的节点，否则这种方法是不可靠的。</p>
</div>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 的向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.erase_node">
erase_node(to_erase)[源代码][源代码]</dt>
<dd><p>从 <code class="docutils literal "><span class="pre">Graph</span></code> 中删除 <code class="docutils literal "><span class="pre">Node</span></code> 。如果该节点在 <code class="docutils literal "><span class="pre">Graph</span></code> 中仍有用户，则抛出异常。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>to_erase (节点) – 从 <code class="docutils literal "><span class="pre">Graph</span></code> 中删除的 <code class="docutils literal "><span class="pre">Node</span></code> 。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性有保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.find_nodes">
<span class="sig-name descname"><span class="pre">find_nodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.find_nodes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1011"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.find_nodes" title="Permalink to this definition">¶</a></dt>
<dd><p>允许快速查询节点</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>op (str) – 操作名称</p></li>
<li><p>target (Optional[Target]) – 节点的目标。对于 call_function，目标为必需。对于其他操作，目标为可选。</p></li>
<li><p>是否按在图上出现的顺序返回节点。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>具有请求操作和目标的节点可迭代。</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>此 API 为实验性，且不向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.get_attr">
<span class="sig-name descname"><span class="pre">get_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">qualified_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_expr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.get_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1282"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.get_attr" title="Permalink to this definition">¶</a></dt>
<dd><p>在图中插入一个 <code class="docutils literal "><span class="pre">get_attr</span></code> 节点。A <code class="docutils literal "><span class="pre">get_attr</span></code> <code class="docutils literal "><span class="pre">Node</span></code> 表示从 <code class="docutils literal "><span class="pre">Module</span></code> 层次中获取属性。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>完整名称（str）- 要检索的属性的完整名称。例如，如果跟踪的模块有一个名为 <code class="docutils literal "><span class="pre">foo</span></code> 的子模块，该子模块有一个名为 <code class="docutils literal "><span class="pre">bar</span></code> 的子模块，该子模块有一个名为 <code class="docutils literal "><span class="pre">baz</span></code> 的属性，则应将合格名称 <code class="docutils literal "><span class="pre">foo.bar.baz</span></code> 传递为 <code class="docutils literal "><span class="pre">qualified_name</span></code> 。</p></li>
<li><p>type_expr（可选[Any]）- 表示此节点输出将具有的 Python 类型的可选类型注解。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>新创建并插入的 <code class="docutils literal "><span class="pre">get_attr</span></code> 节点。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.fx.Node" title="torch.fx.node.Node"><em>节点</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法与 <code class="docutils literal "><span class="pre">Graph.create_node</span></code> 的插入点及类型表达式规则相同。</p>
</div>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.graph_copy">
<span class="sig-name descname"><span class="pre">graph_copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">g</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_map</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_output_node</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.graph_copy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1037"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.graph_copy" title="Permalink to this definition">¶</a></dt>
<dd><p>将给定图中的所有节点复制到 <code class="docutils literal "><span class="pre">self</span></code> 。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>g（图）- 从中复制节点的源图。</p></li>
<li><p>val_map（Dict[Node, Node]）- 一个字典，将填充从 <code class="docutils literal "><span class="pre">g</span></code> 到 <code class="docutils literal "><span class="pre">self</span></code> 的节点映射。注意，如果 <code class="docutils literal "><span class="pre">val_map</span></code> 已经包含值，则可以传入以覆盖某些值的复制。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>如果 <code class="docutils literal "><span class="pre">g</span></code> 有一个 <code class="docutils literal "><span class="pre">output</span></code> 节点，则 <code class="docutils literal "><span class="pre">self</span></code> 中的值现在等同于 <code class="docutils literal "><span class="pre">g</span></code> 的输出值。否则为 <code class="docutils literal "><span class="pre">None</span></code> 。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[Union[ tuple[Union[ForwardRef('Argument'), ...], collections.abc.Sequence[ForwardRef('Argument')], collections.abc.Mapping[ str, ForwardRef('Argument')], slice, range, torch.fx.node.Node, str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, torch.SymInt, torch.SymBool, torch.SymFloat, NoneType], …], Sequence[Optional[Union[ tuple[ForwardRef('Argument'), …], Sequence[Argument], Mapping[ str, Argument], slice, range, Node, str, int, float, bool, complex, dtype, Tensor, device, memory_format, layout, OpOverload, SymInt, SymBool, SymFloat]]], Mapping[ str, Optional[Union[ tuple[ForwardRef('Argument'), …], Sequence[Argument], Mapping[ str, Argument], slice, range, Node, str, int, float, bool, complex, dtype, Tensor, device, memory_format, layout, OpOverload, SymInt, SymBool, SymFloat]]], slice, range, Node, str, int, float, bool, complex, dtype, Tensor, device, memory_format, layout, OpOverload, SymInt, SymBool, SymFloat]]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.inserting_after">
<span class="sig-name descname"><span class="pre">inserting_after</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.inserting_after"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1225"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.inserting_after" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>设置 create_node 和伴随方法将插入到图中的点。</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">当在“with”语句中使用时，这将临时设置插入点，并在退出“with”语句时恢复：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">inserting_after</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="o">...</span>  <span class="c1"># inserting after node n</span>
<span class="o">...</span>  <span class="c1"># insert point restored to what it was previously</span>
<span class="n">g</span><span class="o">.</span><span class="n">inserting_after</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>  <span class="c1">#  set the insert point permanently</span>
</pre></div>
</div>
<p>参数：</p>
<blockquote>
<div><dl class="simple">
<dt>n (可选[节点]): 要插入其前的节点。如果为 None，则将在整个图的开始之后插入。</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">的位置。</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>返回：</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">一个将恢复插入点在 <code class="docutils literal "><span class="pre">__exit__</span></code> 的资源管理器。</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.inserting_before">
<span class="sig-name descname"><span class="pre">inserting_before</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.inserting_before"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1201"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.inserting_before" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>设置 create_node 和伴随方法将插入到图中的点。</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">当在“with”语句中使用时，这将临时设置插入点，并在退出“with”语句时恢复：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">inserting_before</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="o">...</span>  <span class="c1"># inserting before node n</span>
<span class="o">...</span>  <span class="c1"># insert point restored to what it was previously</span>
<span class="n">g</span><span class="o">.</span><span class="n">inserting_before</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>  <span class="c1">#  set the insert point permanently</span>
</pre></div>
</div>
<p>参数：</p>
<blockquote>
<div><dl class="simple">
<dt>n (可选[节点]): 要插入其前的节点。如果为 None，则将在整个图的开始处插入。</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">的位置。</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>返回：</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">一个将恢复 <code class="docutils literal "><span class="pre">__exit__</span></code> .插入点的资源管理器。</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.lint">
lint()[源码][源码] ¶</dt>
<dd><p>对此图进行各种检查以确保其格式正确。特别是：- 检查节点拥有正确的所有权（由此图拥有）- 检查节点按拓扑顺序出现- 如果此图有一个拥有 GraphModule，检查该 GraphModule 中存在目标</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 的向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.node_copy">
node_copy(node, arg_transform=&gt;)[源码][源码] ¶</dt>
<dd><p>将一个节点从一张图复制到另一张图。 <code class="docutils literal "><span class="pre">arg_transform</span></code> 需要将节点所在图的参数转换为自身图的参数。示例：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="c1"># Copying all the nodes in `g` into `new_graph`</span>
<span class="n">g</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Graph</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">new_graph</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">graph</span><span class="p">()</span>
<span class="n">value_remap</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
    <span class="n">value_remap</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_graph</span><span class="o">.</span><span class="n">node_copy</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="n">value_remap</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>节点（Node）- 要复制的节点 <code class="docutils literal "><span class="pre">self</span></code> 。</p></li>
<li><p>arg_transform (Callable[[Node], Argument]) - 一个函数，用于将节点 <code class="docutils literal "><span class="pre">args</span></code> 和 <code class="docutils literal "><span class="pre">kwargs</span></code> 中的参数转换为 <code class="docutils literal "><span class="pre">self</span></code> 中的等效参数。在简单情况下，这应该从将原始图中的节点映射到 <code class="docutils literal "><span class="pre">self</span></code> 的表中检索值。</p></li>
</ul>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#torch.fx.Node" title="torch.fx.node.Node"><em>节点</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch.fx.Graph.nodes">
属性节点_node_list _</dt>
<dd><p>获取构成此图的节点列表。</p>
<p>注意，此 <code class="docutils literal "><span class="pre">Node</span></code> 列表表示形式是双向链表。迭代期间的变异（例如删除节点、添加节点）是安全的。</p>
<dl class="field-list simple">
<dt class="field-odd">返回<span class="colon">:</span></dt>
<dd class="field-odd"><p>双向链表的节点。注意，可以通过 <code class="docutils literal "><span class="pre">reversed</span></code> 来切换此列表的迭代顺序。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.on_generate_code">
on_generate_code(make_transformer)[source][source]</dt>
<dd><p>在生成 Python 代码时注册转换器函数</p>
<blockquote>
<div><dl>
<dt>参数：</dt><dd><dl>
<dt>make_transformer (Callable[[Optional[TransformCodeFunc]], TransformCodeFunc]):</dt><dd><p>一个返回要注册的代码转换器的函数。此函数由 on_generate_code 调用以获取代码转换器。</p>
<p>此函数还接收当前已注册的代码转换器（如果没有注册则为 None），以防不希望覆盖它。这对于将代码转换器链接在一起很有用。</p>
</dd>
</dl>
</dd>
<dt>返回：</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">一个上下文管理器，当在 with 语句中使用时，会自动恢复之前注册的代码转换器。</p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python "><div class="highlight"><pre><span></span><span class="n">gm</span><span class="p">:</span> <span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span> <span class="o">=</span> <span class="o">...</span>


<span class="c1"># This is a code transformer we want to register. This code</span>
<span class="c1"># transformer prepends a pdb import and trace statement at the very</span>
<span class="c1"># beginning of the generated torch.fx code to allow for manual</span>
<span class="c1"># debugging with the PDB library.</span>
<span class="k">def</span> <span class="nf">insert_pdb</span><span class="p">(</span><span class="n">body</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="s2">"import pdb; pdb.set_trace()</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="o">*</span><span class="n">body</span><span class="p">]</span>


<span class="c1"># Registers `insert_pdb`, and overwrites the current registered</span>
<span class="c1"># code transformer (given by `_` to the lambda):</span>
<span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">on_generate_code</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">insert_pdb</span><span class="p">)</span>

<span class="c1"># Or alternatively, registers a code transformer which first</span>
<span class="c1"># runs `body` through existing registered transformer, then</span>
<span class="c1"># through `insert_pdb`:</span>
<span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">on_generate_code</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">current_trans</span><span class="p">:</span> <span class="p">(</span>
        <span class="k">lambda</span> <span class="n">body</span><span class="p">:</span> <span class="n">insert_pdb</span><span class="p">(</span><span class="n">current_trans</span><span class="p">(</span><span class="n">body</span><span class="p">)</span> <span class="k">if</span> <span class="n">current_trans</span> <span class="k">else</span> <span class="n">body</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">gm</span><span class="o">.</span><span class="n">recompile</span><span class="p">()</span>
<span class="n">gm</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>  <span class="c1"># drops into pdb</span>
</pre></div>
</div>
<p>此功能也可以用作上下文管理器，具有自动恢复先前注册的代码转换器的优势：</p>
<div class="highlight-python "><div class="highlight"><pre><span></span><span class="c1"># ... continue from previous example</span>

<span class="k">with</span> <span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">on_generate_code</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">insert_pdb</span><span class="p">):</span>
    <span class="c1"># do more stuff with `gm`...</span>
    <span class="n">gm</span><span class="o">.</span><span class="n">recompile</span><span class="p">()</span>
    <span class="n">gm</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>  <span class="c1"># drops into pdb</span>

<span class="c1"># now previous code transformer is restored (but `gm`'s code with pdb</span>
<span class="c1"># remains - that means you can run `gm` with pdb here too, until you</span>
<span class="c1"># run next `recompile()`).</span>
</pre></div>
</div>
</div></blockquote>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>此 API 为实验性，且不向后兼容。</p>
</div>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.output">
<span class="sig-name descname"><span class="pre">output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_expr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1513"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.output" title="Permalink to this definition">¶</a></dt>
<dd><p>在 <code class="docutils literal "><span class="pre">Graph</span></code> 中插入 <code class="docutils literal "><span class="pre">output</span></code> <code class="docutils literal "><span class="pre">Node</span></code> 。一个 <code class="docutils literal "><span class="pre">output</span></code> 节点代表 Python 代码中的一个 <code class="docutils literal "><span class="pre">return</span></code> 语句。 <code class="docutils literal "><span class="pre">result</span></code> 是应该返回的值。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>result (参数) – 要返回的值。</p></li>
<li><p>type_expr (Optional[Any]) – 表示此节点输出将具有的 Python 类型的可选类型注解。</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法与 <code class="docutils literal "><span class="pre">Graph.create_node</span></code> 适用于相同的插入点和类型表达式规则。</p>
</div>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 保证向后兼容性。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.output_node">
<span class="sig-name descname"><span class="pre">output_node</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.output_node"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1005"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.output_node" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="admonition-title">警告</p>
<p>此 API 为实验性，且不向后兼容。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.fx.Node" title="torch.fx.node.Node"><em>Node</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.placeholder">
placeholder(名称, 类型表达式=None, 默认值)[源代码][源代码] ¶</dt>
<dd><p>在图中插入一个 <code class="docutils literal "><span class="pre">placeholder</span></code> 节点。 <code class="docutils literal "><span class="pre">placeholder</span></code> 代表函数输入。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>名称 (str) – 输入值的名称。这对应于该 <code class="docutils literal "><span class="pre">Graph</span></code> 代表的函数的位置参数名称。</p></li>
<li><p>type_expr (Optional[Any]) – 表示此节点输出将具有的 Python 类型的可选类型注解。在某些情况下，这对于正确的代码生成是必需的（例如，当函数在 TorchScript 编译中随后使用时）。</p></li>
<li><p>default_value (Any) – 此函数参数应采用的默认值。注意：为了允许 None 作为默认值，应将 inspect.Signature.empty 传递给此参数，以指定该参数没有默认值。</p></li>
</ul>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#torch.fx.Node" title="torch.fx.node.Node"><em>节点</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此方法与 <code class="docutils literal "><span class="pre">Graph.create_node</span></code> 一样适用相同的插入点和类型表达式规则。</p>
</div>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 保证向下兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.print_tabular">
<span class="sig-name descname"><span class="pre">print_tabular</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.print_tabular"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1662"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.print_tabular" title="Permalink to this definition">¶</a></dt>
<dd><p>以表格形式打印图的中间表示。请注意，此 API 需要安装 <code class="docutils literal "><span class="pre">tabulate</span></code> 模块。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 保证向下兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.process_inputs">
<span class="sig-name descname"><span class="pre">process_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.process_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1150"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.process_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>处理参数，以便将它们传递给 FX 图。</p>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>此 API 为实验性，且不向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.process_outputs">
<span class="sig-name descname"><span class="pre">process_outputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.process_outputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1157"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.process_outputs" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="admonition-title">警告</p>
<p>此 API 为实验性，且不向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.python_code">
<span class="sig-name descname"><span class="pre">python_code</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root_module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colored</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.python_code"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1547"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.python_code" title="Permalink to this definition">¶</a></dt>
<dd><p>将这个 <code class="docutils literal "><span class="pre">Graph</span></code> 转换为有效的 Python 代码。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>root_module（字符串）- 要查找合格名称目标的根模块名称。这通常是‘self’。</p>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>src：表示对象的 Python 源代码 globals：src 中的全局名称的字典 -&gt; 它们引用的对象。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>一个 PythonCode 对象，包含两个字段</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 保证向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Graph.set_codegen">
<span class="sig-name descname"><span class="pre">set_codegen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">codegen</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.set_codegen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/graph.py#L1851"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Graph.set_codegen" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="admonition-title">警告</p>
<p>此 API 为实验性，且不向后兼容。</p>
</div>
<dl class="field-list simple">
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch.fx.Node">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch.fx.</span></span><span class="sig-name descname"><span class="pre">Node</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/node.py#L200"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Node" title="Permalink to this definition">¶</a></dt>
<dd><p> <code class="docutils literal "><span class="pre">Node</span></code> 是表示 <code class="docutils literal "><span class="pre">Graph</span></code> 中单个操作的抽象数据类型。大部分情况下，节点代表对各种实体（如算子、方法、模块等）的调用点（一些例外包括指定函数输入和输出的节点）。每个节点都有一个由其 <code class="docutils literal "><span class="pre">op</span></code> 属性指定的函数。 <code class="docutils literal "><span class="pre">Node</span></code> 的语义如下：</p>
<ul class="simple">
<li><p> <code class="docutils literal "><span class="pre">placeholder</span></code> 代表函数输入。 <code class="docutils literal "><span class="pre">name</span></code> 属性指定该值将采用的名称。 <code class="docutils literal "><span class="pre">target</span></code> 类似地是参数的名称。 <code class="docutils literal "><span class="pre">args</span></code> 包含以下两种情况之一：1）无内容，或 2）一个表示函数输入默认参数的单个参数。 <code class="docutils literal "><span class="pre">kwargs</span></code> 是无关紧要的。占位符对应于图打印中的函数参数（例如 <code class="docutils literal "><span class="pre">x</span></code> ）。</p></li>
<li><p> <code class="docutils literal "><span class="pre">get_attr</span></code> 从模块层次结构中检索参数。 <code class="docutils literal "><span class="pre">name</span></code> 类似地是分配给检索结果的名称。 <code class="docutils literal "><span class="pre">target</span></code> 是参数在模块层次结构中的完全限定名称。 <code class="docutils literal "><span class="pre">args</span></code> 和 <code class="docutils literal "><span class="pre">kwargs</span></code> 是无关紧要的。</p></li>
<li><p> <code class="docutils literal "><span class="pre">call_function</span></code> 将一个自由函数应用于一些值。 <code class="docutils literal "><span class="pre">name</span></code> 类似地是分配给值的名称。 <code class="docutils literal "><span class="pre">target</span></code> 是要应用的功能。 <code class="docutils literal "><span class="pre">args</span></code> 和 <code class="docutils literal "><span class="pre">kwargs</span></code> 代表函数的参数，遵循 Python 调用约定。</p></li>
<li><p> <code class="docutils literal "><span class="pre">call_module</span></code> 将模块层次结构中的 <code class="docutils literal "><span class="pre">forward()</span></code> 方法应用于给定的参数。 <code class="docutils literal "><span class="pre">name</span></code> 如前所述。 <code class="docutils literal "><span class="pre">target</span></code> 是要调用的模块在模块层次结构中的完全限定名称。 <code class="docutils literal "><span class="pre">args</span></code> 和 <code class="docutils literal "><span class="pre">kwargs</span></code> 代表调用模块时要传递的参数，不包括 self 参数。</p></li>
<li><p> <code class="docutils literal "><span class="pre">call_method</span></code> 调用值上的方法。 <code class="docutils literal "><span class="pre">name</span></code> 与此类似。 <code class="docutils literal "><span class="pre">target</span></code> 是要应用到 <code class="docutils literal "><span class="pre">self</span></code> 参数上的方法的字符串名称。 <code class="docutils literal "><span class="pre">args</span></code> 和 <code class="docutils literal "><span class="pre">kwargs</span></code> 代表调用模块时的参数，包括 self 参数</p></li>
<li><p> <code class="docutils literal "><span class="pre">output</span></code> 包含被跟踪函数的输出，存储在其 <code class="docutils literal "><span class="pre">args[0]</span></code> 属性中。这对应于图打印输出中的“return”语句。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="torch.fx.Node.all_input_nodes">
属性 all_input_nodeslist[torch.fx.node.Node] ¶</dt>
<dd><p>返回所有是该节点输入的节点。这相当于遍历 <code class="docutils literal "><span class="pre">args</span></code> 和 <code class="docutils literal "><span class="pre">kwargs</span></code> ，并仅收集值为节点的值。</p>
<dl class="field-list simple">
<dt class="field-odd">返回<span class="colon">:</span></dt>
<dd class="field-odd"><p>列出在 <code class="docutils literal "><span class="pre">args</span></code> 和 <code class="docutils literal "><span class="pre">kwargs</span></code> 中出现的 <code class="docutils literal "><span class="pre">Nodes</span></code> ，顺序如下。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Node.append">
<span class="sig-name descname"><span class="pre">append</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node.append"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/node.py#L414"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Node.append" title="Permalink to this definition">¶</a></dt>
<dd><p>在图中节点列表中在此节点之后插入 <code class="docutils literal "><span class="pre">x</span></code> 。相当于 <code class="docutils literal "><span class="pre">self.next.prepend(x)</span></code> </p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>x（节点）- 要放在此节点之后的节点。必须是同一图中的成员。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch.fx.Node.args">
属性 argstuple[typing.Union[tuple[typing.Union[tuple[ForwardRef('Argument'), ...], collections.abc.Sequence[ForwardRef('Argument')], collections.abc.Mapping[str, ForwardRef('Argument')], slice, range, torch.fx.node.Node, str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, torch.SymInt, torch.SymBool, torch.SymFloat, NoneType], ...], collections.abc.Sequence[typing.Union[tuple[ForwardRef('Argument'), ...], collections.abc.Sequence[ForwardRef('Argument')], collections.abc.Mapping[str, ForwardRef('Argument')], slice, range, torch.fx.node.Node, str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, torch.SymInt, torch.SymBool, torch.SymFloat, NoneType]], collections.abc.Mapping[str, typing.Union[tuple[ForwardRef('Argument'), ...], collections.abc.Sequence[ForwardRef('Argument')], collections.abc.Mapping[str, ForwardRef('Argument')], slice, range, torch.fx.node.Node, str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, torch.SymInt, torch.SymBool, torch.SymFloat, NoneType]]] torch.SymFloat, NoneType]], slice, range, torch.fx.node.Node, str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, torch.SymInt, torch.SymBool, torch.SymFloat, NoneType], ...] ¶</dt>
<dd><p>此函数的参数元组。参数的解释取决于节点的操作码。有关更多信息，请参阅 <code class="xref py py-class docutils literal "><span class="pre">Node</span></code> 的文档字符串。</p>
<p>允许对此属性进行赋值。在赋值时，所有使用情况和用户的会计信息将自动更新。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Node.format_node">
<span class="sig-name descname"><span class="pre">format_node</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">placeholder_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maybe_return_typename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node.format_node"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/node.py#L591"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Node.format_node" title="Permalink to this definition">¶</a></dt>
<dd><p>返回对 <code class="docutils literal "><span class="pre">self</span></code> 的描述性字符串表示。</p>
<p>此方法可以无参数使用，作为调试工具。</p>
<p>此函数还用于 <code class="docutils literal "><span class="pre">Graph</span></code> 的 <code class="docutils literal "><span class="pre">__str__</span></code> 方法内部。 <code class="docutils literal "><span class="pre">placeholder_names</span></code> 和 <code class="docutils literal "><span class="pre">maybe_return_typename</span></code> 中的字符串共同构成了此 Graph 周围 GraphModule 中自动生成的 <code class="docutils literal "><span class="pre">forward</span></code> 函数的签名。 <code class="docutils literal "><span class="pre">placeholder_names</span></code> 和 <code class="docutils literal "><span class="pre">maybe_return_typename</span></code> 不应在其他情况下使用。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>placeholder_names（可选[字符串列表]）- 一个列表，将存储表示生成的 <code class="docutils literal "><span class="pre">forward</span></code> 函数中占位符的格式化字符串。仅限内部使用。</p></li>
<li><p>maybe_return_typename (Optional[list[str]]) – 存储生成 <code class="docutils literal "><span class="pre">forward</span></code> 函数输出的格式化字符串的单元素列表。仅内部使用。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p></p><dl class="simple">
<dt>如果 1) 我们使用 <code class="docutils literal "><span class="pre">format_node</span></code> 作为内部辅助函数</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在 <code class="docutils literal "><span class="pre">Graph</span></code> 的 <code class="docutils literal "><span class="pre">__str__</span></code> 方法中，并且 2) <code class="docutils literal "><span class="pre">self</span></code> 是一个占位符节点，则返回 <code class="docutils literal "><span class="pre">None</span></code> 。否则，返回当前节点的描述性字符串表示。</p>
</dd>
</dl>
<p></p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 的向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Node.insert_arg">
<span class="sig-name descname"><span class="pre">insert_arg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node.insert_arg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/node.py#L504"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Node.insert_arg" title="Permalink to this definition">¶</a></dt>
<dd><p>在指定索引处向参数列表插入一个位置参数。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>idx (int) – 要插入到 <code class="docutils literal "><span class="pre">self.args</span></code> 之前的位置元素的索引。</p></li>
<li><p>arg (Argument) – 要插入到 <code class="docutils literal "><span class="pre">args</span></code> 中的新参数值。</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 保证向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Node.is_impure">
<span class="sig-name descname"><span class="pre">is_impure</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node.is_impure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/node.py#L716"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Node.is_impure" title="Permalink to this definition">¶</a></dt>
<dd><p>返回此操作是否为不纯，即其操作是否为占位符或输出，或者是否为不纯的 call_function 或 call_module。</p>
<dl class="field-list simple">
<dt class="field-odd">返回<span class="colon">:</span></dt>
<dd class="field-odd"><p>判断操作是否为不纯。</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">布尔型</a></p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>此 API 为实验性，且不向后兼容。</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch.fx.Node.kwargs">
属性 kwargsdict[str, typing.Union[tuple[ForwardRef('Argument'), ...], collections.abc.Sequence[ForwardRef('Argument')], collections.abc.Mapping[str, ForwardRef('Argument')], slice, range, torch.fx.node.Node, str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, torch.SymInt, torch.SymBool, torch.SymFloat, NoneType], ...], collections.abc.Sequence[typing.Union[tuple[ForwardRef('Argument'), ...], collections.abc.Sequence[ForwardRef('Argument')], collections.abc.Mapping[str, ForwardRef('Argument')], slice, range, torch.fx.node.Node, str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, torch.SymInt, torch.SymBool, torch.SymFloat, NoneType]], collections.abc.Mapping[str, typing.Union[tuple[ForwardRef('Argument'), ...], collections.abc.Sequence[ForwardRef('Argument')], collections.abc.Mapping[str, ForwardRef('Argument')], slice, range, torch.fx.node.Node, str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, torch.SymInt, torch.SymBool, torch.SymFloat, NoneType]]] torch.SymFloat, NoneType]], slice, range, torch.fx.node.Node, str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, torch.SymInt, torch.SymBool, torch.SymFloat, NoneType]] ¶</dt>
<dd><p>该函数的关键字参数字典。参数的解释取决于节点的操作码。请参阅 <code class="xref py py-class docutils literal "><span class="pre">Node</span></code> 的文档字符串以获取更多信息。</p>
<p>允许对此属性进行赋值。在赋值时，所有使用情况和用户的会计信息将自动更新。</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch.fx.Node.next">
属性 nextNode</dt>
<dd><p>返回节点链表中的下一个 <code class="docutils literal "><span class="pre">Node</span></code> 。</p>
<dl class="field-list simple">
<dt class="field-odd">返回<span class="colon">:</span></dt>
<dd class="field-odd"><p>节点链表中的下一个 <code class="docutils literal "><span class="pre">Node</span></code> 。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Node.normalized_arguments">
<span class="sig-name descname"><span class="pre">normalized_arguments</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwarg_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_to_only_use_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node.normalized_arguments"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/node.py#L754"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Node.normalized_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>返回用于 Python 目标的标准化参数。这意味着 args/kwargs 将与模块/函数的签名匹配，如果 normalize_to_only_use_kwargs 为 true，则仅按位置顺序返回 kwargs。同时填充默认值。不支持位置只写参数或可变参数。</p>
<p>支持模块调用。</p>
<p>可能需要 arg_types 和 kwarg_types 来区分重载。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>root (torch.nn.Module) – 要解析模块目标的模块。</p></li>
<li><p>arg_types (可选[Tuple[Any]]) – 参数类型的元组。</p></li>
<li><p>kwarg_types (Optional[Dict[str, Any]]) – 参数类型字典</p></li>
<li><p>normalize_to_only_use_kwargs (bool) – 是否规范化为仅使用 kwargs。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>返回 NamedTuple ArgsKwargsPair，或未成功时返回 None。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><em>Optional</em></a>[<em>ArgsKwargsPair</em>]</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>此 API 为实验性，且不向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Node.prepend">
prepend(x)[来源][来源] ¶</dt>
<dd><p>在图中的节点列表中在此节点之前插入 x。例如：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="n">Before</span><span class="p">:</span> <span class="n">p</span> <span class="o">-&gt;</span> <span class="bp">self</span>
        <span class="n">bx</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">ax</span>
<span class="n">After</span><span class="p">:</span>  <span class="n">p</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="bp">self</span>
        <span class="n">bx</span> <span class="o">-&gt;</span> <span class="n">ax</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>x（节点）- 要插入此节点之前的节点。必须是同一图中的成员。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 兼容旧版本有保证。</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch.fx.Node.prev">
属性 prevNode ¶</dt>
<dd><p>返回节点链表中的前一个 <code class="docutils literal "><span class="pre">Node</span></code> </p>
<dl class="field-list simple">
<dt class="field-odd">返回<span class="colon">:</span></dt>
<dd class="field-odd"><p>节点链表中的前一个 <code class="docutils literal "><span class="pre">Node</span></code> </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Node.replace_all_uses_with">
<span class="sig-name descname"><span class="pre">replace_all_uses_with</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">replace_with</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delete_user_cb=&lt;function</span> <span class="pre">Node.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">propagate_meta=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node.replace_all_uses_with"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/node.py#L657"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Node.replace_all_uses_with" title="Permalink to this definition">¶</a></dt>
<dd><p>在 Graph 中将所有使用 <code class="docutils literal "><span class="pre">self</span></code> 的地方替换为 Node <code class="docutils literal "><span class="pre">replace_with</span></code> 。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>替换为（节点）- 要替换所有使用 <code class="docutils literal "><span class="pre">self</span></code> 的节点。</p></li>
<li><p>delete_user_cb（可调用）- 当确定是否应该从 self 节点移除给定用户时被调用的回调。</p></li>
<li><p>propagate_meta（布尔值）- 是否将原始节点的.meta 字段上的所有属性复制到替换节点上。出于安全考虑，仅在替换节点尚未具有现有的.meta 字段时才有效。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>已更改此更改的节点列表。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[torch.fx.node.Node]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Node.replace_input_with">
replace_input_with(old_input, new_input)[source][source]</dt>
<dd><p>遍历输入节点 <code class="docutils literal "><span class="pre">self</span></code> ，并将所有 <code class="docutils literal "><span class="pre">old_input</span></code> 替换为 <code class="docutils literal "><span class="pre">new_input</span></code> 。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>旧输入（节点）- 要替换的旧输入节点。</p></li>
<li><p>新输入（节点）- 替换 <code class="docutils literal "><span class="pre">old_input</span></code> 的新输入节点。</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch.fx.Node.stack_trace">
属性 stack_traceOptional[str] ¶</dt>
<dd><p>返回在跟踪期间记录的 Python 调用栈，如果有的话。当使用 fx.Tracer 跟踪时，此属性通常由 Tracer.create_proxy 填充。为了在跟踪期间记录调用栈以进行调试，请在 Tracer 实例上设置 record_stack_traces = True。当使用 dynamo 跟踪时，此属性将默认由 OutputGraph.create_proxy 填充。</p>
<p>stack_trace 将在字符串末尾具有最内层的帧。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Node.update_arg">
<span class="sig-name descname"><span class="pre">update_arg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node.update_arg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/node.py#L489"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Node.update_arg" title="Permalink to this definition">¶</a></dt>
<dd><p>更新现有位置参数以包含新值 <code class="docutils literal "><span class="pre">arg</span></code> 。调用后， <code class="docutils literal "><span class="pre">self.args[idx]</span> <span class="pre">==</span> <span class="pre">arg</span></code> 。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>idx (int) – 更新元素的索引 <code class="docutils literal "><span class="pre">self.args</span></code> </p></li>
<li><p>arg (Argument) – 要写入 <code class="docutils literal "><span class="pre">args</span></code> 的新参数值</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Node.update_kwarg">
<span class="sig-name descname"><span class="pre">update_kwarg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node.update_kwarg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/node.py#L530"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Node.update_kwarg" title="Permalink to this definition">¶</a></dt>
<dd><p>更新现有的关键字参数以包含新值 <code class="docutils literal "><span class="pre">arg</span></code> 。调用后， <code class="docutils literal "><span class="pre">self.kwargs[key]</span> <span class="pre">==</span> <span class="pre">arg</span></code> 。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>key (str) – 要更新的元素的 <code class="docutils literal "><span class="pre">self.kwargs</span></code> 中的键</p></li>
<li><p>arg (Argument) – 要写入 <code class="docutils literal "><span class="pre">kwargs</span></code> 的新参数值</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 保证向后兼容。</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch.fx.Tracer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch.fx.</span></span><span class="sig-name descname"><span class="pre">Tracer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">autowrap_modules</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(math,)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">autowrap_functions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/_symbolic_trace.html#Tracer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/_symbolic_trace.py#L231"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Tracer" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p> <code class="docutils literal "><span class="pre">Tracer</span></code> 是实现 <code class="docutils literal "><span class="pre">torch.fx.symbolic_trace</span></code> 符号跟踪功能的类。对 <code class="docutils literal "><span class="pre">symbolic_trace(m)</span></code> 的调用等同于 <code class="docutils literal "><span class="pre">Tracer().trace(m)</span></code> 。</p>
<p>Tracer 可以被继承以覆盖跟踪过程的多种行为。可以覆盖的不同行为在类上方法的文档字符串中描述。</p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 保证向后兼容。</p>
</div>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.call_module">
<span class="sig-name descname"><span class="pre">call_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/_symbolic_trace.html#Tracer.call_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/_symbolic_trace.py#L482"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Tracer.call_module" title="Permalink to this definition">¶</a></dt>
<dd><p>指定此 <code class="docutils literal "><span class="pre">Tracer</span></code> 在遇到对 <code class="docutils literal "><span class="pre">nn.Module</span></code> 实例的调用时的行为的方法。</p>
<p>默认情况下，行为是检查被调用的模块是否是叶子模块通过 <code class="docutils literal "><span class="pre">is_leaf_module</span></code> 。如果是，则在 <code class="docutils literal "><span class="pre">Graph</span></code> 中引用 <code class="docutils literal "><span class="pre">m</span></code> 发射一个 <code class="docutils literal "><span class="pre">call_module</span></code> 节点。否则，正常调用 <code class="docutils literal "><span class="pre">Module</span></code> ，通过其 <code class="docutils literal "><span class="pre">forward</span></code> 函数中的操作进行跟踪。</p>
<p>此方法可以被重写，例如创建嵌套的已跟踪 GraphModules，或者跨 <code class="docutils literal "><span class="pre">Module</span></code> 边界时你想要的任何其他行为。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>m（模块）- 正在发出调用的模块</p></li>
<li><p>forward（可调用）- 要调用的 <code class="docutils literal "><span class="pre">Module</span></code> 的 forward()方法</p></li>
<li><p>args（元组）- 模块调用位置的参数</p></li>
<li><p>kwargs (字典) – 模块调用位置的 kwargs</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>模块的返回值。如果生成了 <code class="docutils literal "><span class="pre">call_module</span></code> 节点，则此为 <code class="docutils literal "><span class="pre">Proxy</span></code> 值。否则，就是 <code class="docutils literal "><span class="pre">Module</span></code> 调用返回的任何值。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><em>任何</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.create_arg">
create_arg(a)[source][source]</dt>
<dd><p>一种指定在准备用作节点参数的值时的跟踪行为的方法。</p>
<p>默认情况下，行为包括：</p>
<ol class="arabic">
<li><p>遍历集合类型（例如元组、列表、字典）并对元素递归调用 <code class="docutils literal "><span class="pre">create_args</span></code> 。</p></li>
<li><p>给定一个代理对象，返回底层 IR 的引用 <code class="docutils literal "><span class="pre">Node</span></code> 。</p></li>
<li><p>对于非代理张量对象，针对各种情况发出 IR</p>
<blockquote>
<div><ul class="simple">
<li><p>对于参数，发出指向该参数的 <code class="docutils literal "><span class="pre">get_attr</span></code> 节点</p></li>
<li><p>对于非参数张量，将该张量存储在特殊属性中，以引用该属性</p></li>
</ul>
</div></blockquote>
</li>
</ol>
<p>此方法可以被重写以支持更多类型</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>一个（任何）- 要作为 <code class="docutils literal "><span class="pre">Graph</span></code> 发出的值 <code class="docutils literal "><span class="pre">Argument</span></code> 。</p>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>将 <code class="docutils literal "><span class="pre">a</span></code> 转换为适当的 <code class="docutils literal "><span class="pre">Argument</span></code> 的值。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>参数</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.create_args_for_root">
<span class="sig-name descname"><span class="pre">create_args_for_root</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concrete_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/_symbolic_trace.html#Tracer.create_args_for_root"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/_symbolic_trace.py#L605"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Tracer.create_args_for_root" title="Permalink to this definition">¶</a></dt>
<dd><p>创建对应于 <code class="docutils literal "><span class="pre">root</span></code> 模块签名的 <code class="docutils literal "><span class="pre">placeholder</span></code> 节点。此方法会检查 root 的签名并相应地发出这些节点，同时支持 <code class="docutils literal "><span class="pre">*args</span></code> 和 <code class="docutils literal "><span class="pre">**kwargs</span></code> 。</p>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>此 API 为实验性，且不向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.create_node">
<span class="sig-name descname"><span class="pre">create_node</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kind</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_expr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/proxy.py#L148"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Tracer.create_node" title="Permalink to this definition">¶</a></dt>
<dd><p>插入一个图节点，给定目标、参数、关键字参数和名称。</p>
<p>此方法可以被重写以进行额外的检查、验证或修改用于节点创建的值。例如，可能希望禁止记录原地操作。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.fx.Node" title="torch.fx.node.Node"><em>Node</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.create_proxy">
<span class="sig-name descname"><span class="pre">create_proxy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kind</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_expr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proxy_factory_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/proxy.py#L214"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Tracer.create_proxy" title="Permalink to this definition">¶</a></dt>
<dd><p>从给定的参数创建一个节点，然后返回一个包装在代理对象中的节点。</p>
<p>如果 kind = ‘placeholder’，则我们正在创建一个表示函数参数的节点。如果需要编码默认参数，我们使用 <code class="docutils literal "><span class="pre">args</span></code> 元组。对于 <code class="docutils literal "><span class="pre">placeholder</span></code> 节点， <code class="docutils literal "><span class="pre">args</span></code> 为空。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.get_fresh_qualname">
<span class="sig-name descname"><span class="pre">get_fresh_qualname</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/_symbolic_trace.html#Tracer.get_fresh_qualname"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/_symbolic_trace.py#L315"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Tracer.get_fresh_qualname" title="Permalink to this definition">¶</a></dt>
<dd><p>获取一个前缀的新名称并返回它。此函数确保它不会与图上的现有属性冲突。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.getattr">
<span class="sig-name descname"><span class="pre">getattr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attr_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_proxy_cache</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/_symbolic_trace.html#Tracer.getattr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/_symbolic_trace.py#L541"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Tracer.getattr" title="Permalink to this definition">¶</a></dt>
<dd><p>指定在调用 <code class="docutils literal "><span class="pre">nn.Module</span></code> 实例的 getattr 时此 <code class="docutils literal "><span class="pre">Tracer</span></code> 的行为的方法。</p>
<p>默认情况下，行为是返回属性的代理值。它还会将代理值存储在 <code class="docutils literal "><span class="pre">parameter_proxy_cache</span></code> 中，以便未来的调用将重用代理而不是创建一个新的。</p>
<p>此方法可以被覆盖，例如，在查询参数时不返回代理。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>查询的属性名称（字符串）</p></li>
<li><p>属性值（任意类型）</p></li>
<li><p>parameter_proxy_cache（字典[str, 任意类型]）- 属性名称到代理的缓存</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>getattr 调用返回值</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>此 API 为实验性，且不向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.is_leaf_module">
<span class="sig-name descname"><span class="pre">is_leaf_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_qualified_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/_symbolic_trace.html#Tracer.is_leaf_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/_symbolic_trace.py#L430"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Tracer.is_leaf_module" title="Permalink to this definition">¶</a></dt>
<dd><p>一个用于指定给定的 <code class="docutils literal "><span class="pre">nn.Module</span></code> 是否为“叶子”模块的方法。</p>
<p>叶子模块是出现在 IR 中的原子单元，通过 <code class="docutils literal "><span class="pre">call_module</span></code> 调用进行引用。默认情况下，PyTorch 标准库命名空间（torch.nn）中的模块都是叶子模块。除非通过此参数指定，否则所有其他模块都会进行跟踪，并记录其构成的操作。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>m (模块) – 正在被查询的模块</p></li>
<li><p>模块限定名称（字符串）- 此模块根路径。例如，如果您有一个模块层次结构，其中子模块 <code class="docutils literal "><span class="pre">foo</span></code> 包含子模块 <code class="docutils literal "><span class="pre">bar</span></code> ，该子模块又包含子模块 <code class="docutils literal "><span class="pre">baz</span></code> ，则该模块将在此处以限定名称 <code class="docutils literal "><span class="pre">foo.bar.baz</span></code> 出现。</p></li>
</ul>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">布尔型</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.iter">
iter(obj)[source]</dt>
<dd><dl class="simple">
<dt>当代理对象正在被迭代时调用，例如</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">当用于控制流时。通常我们不知道该做什么，因为我们不知道代理的值，但自定义跟踪器可以使用 create_node 将更多信息附加到图节点，并可以选择返回一个迭代器。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 的向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterator" title="(in Python v3.13)"><em>迭代器</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.keys">
keys(obj)[source]</dt>
<dd><dl class="simple">
<dt>当代理对象调用 keys()方法时触发。</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">当在代理上调用**时会发生这种情况。这应该返回一个迭代器 it**，在你的自定义跟踪器中应该正常工作。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><em>任何</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.path_of_module">
<span class="sig-name descname"><span class="pre">path_of_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mod</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/_symbolic_trace.html#Tracer.path_of_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/_symbolic_trace.py#L455"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Tracer.path_of_module" title="Permalink to this definition">¶</a></dt>
<dd><p>在模块层次结构中查找 <code class="docutils literal "><span class="pre">mod</span></code> 的限定名称的辅助方法。例如，如果 <code class="docutils literal "><span class="pre">root</span></code> 有一个子模块名为 <code class="docutils literal "><span class="pre">foo</span></code> ，而 <code class="docutils literal "><span class="pre">foo</span></code> 又有子模块名为 <code class="docutils literal "><span class="pre">bar</span></code> ，将 <code class="docutils literal "><span class="pre">bar</span></code> 传递给此函数将返回字符串“foo.bar”。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>mod (str) – 获取限定名称的 <code class="docutils literal "><span class="pre">Module</span></code> 。</p>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.proxy">
proxy(node)[source]</dt>
<dd><div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 保证向后兼容。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.fx.Proxy" title="torch.fx.proxy.Proxy"><em>代理</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.to_bool">
to_bool(obj)[源码] ¶</dt>
<dd><dl class="simple">
<dt>当代理对象被转换为布尔值时调用，例如</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">当用于控制流时。通常我们不知道该做什么，因为我们不知道代理的值，但自定义跟踪器可以使用 create_node 将更多信息附加到图节点，并可以选择返回一个值。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">布尔型</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Tracer.trace">
<span class="sig-name descname"><span class="pre">trace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concrete_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/_symbolic_trace.html#Tracer.trace"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/_symbolic_trace.py#L703"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Tracer.trace" title="Permalink to this definition">¶</a></dt>
<dd><p>跟踪 <code class="docutils literal "><span class="pre">root</span></code> 并返回相应的 FX <code class="docutils literal "><span class="pre">Graph</span></code> 表示。 <code class="docutils literal "><span class="pre">root</span></code> 可以是一个 <code class="docutils literal "><span class="pre">nn.Module</span></code> 实例或 Python 可调用对象。</p>
<p>注意，在这次调用之后， <code class="docutils literal "><span class="pre">self.root</span></code> 可能与传入此处的 <code class="docutils literal "><span class="pre">root</span></code> 不同。例如，当将自由函数传递给 <code class="docutils literal "><span class="pre">trace()</span></code> 时，我们将创建一个 <code class="docutils literal "><span class="pre">nn.Module</span></code> 实例作为根实例，并添加嵌入的常量。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>root (Union[Module, Callable]) – 可以是 <code class="docutils literal "><span class="pre">Module</span></code> 或要追踪的函数。此参数向后兼容性得到保证。</p></li>
<li><p>concrete_args (Optional[Dict[str, any]]) – 应视为非代理的具体参数。此参数为实验性，其向后兼容性不保证。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>代表传入的 <code class="docutils literal "><span class="pre">root</span></code> 的语义的 <code class="docutils literal "><span class="pre">Graph</span></code> 。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.fx.Graph" title="torch.fx.graph.Graph"><em>图</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 保证向后兼容。</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch.fx.Proxy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch.fx.</span></span><span class="sig-name descname"><span class="pre">Proxy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tracer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/proxy.html#Proxy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/proxy.py#L418"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Proxy" title="Permalink to this definition">¶</a></dt>
<dd><p> <code class="docutils literal "><span class="pre">Proxy</span></code> 对象是 <code class="docutils literal "><span class="pre">Node</span></code> 包装器，在符号跟踪期间通过程序流动并记录它们接触到的所有操作（ <code class="docutils literal "><span class="pre">torch</span></code> 函数调用、方法调用、运算符）到不断增长的 FX 图。</p>
<p>如果您正在进行图转换，您可以将自己的 <code class="docutils literal "><span class="pre">Proxy</span></code> 方法包装在原始的 <code class="docutils literal "><span class="pre">Node</span></code> 之上，这样您就可以使用重载的运算符向 <code class="docutils literal "><span class="pre">Graph</span></code> 添加额外的内容。</p>
<p>对象无法迭代。换句话说，如果在一个循环或作为 <code class="docutils literal "><span class="pre">Proxy</span></code> / <code class="docutils literal "><span class="pre">*args</span></code> / <code class="docutils literal "><span class="pre">**kwargs</span></code> 函数参数中使用 <code class="docutils literal "><span class="pre">Proxy</span></code> ，符号追踪器将抛出错误。</p>
<p>有两种主要的解决方案：1. 将不可追踪的逻辑提取到顶级函数中，并在其上使用 <code class="docutils literal "><span class="pre">fx.wrap</span></code> 。2. 如果控制流是静态的（即循环迭代次数基于某些超参数），则可以将代码保留在原始位置，并重构为类似以下内容：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">some_hyperparameter</span><span class="p">):</span>
    <span class="n">indexed_item</span> <span class="o">=</span> <span class="n">proxied_value</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>
<p>想要更详细地了解代理内部机制，请查看 torch/fx/README.md 中的“Proxy”部分。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch.fx.Interpreter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch.fx.</span></span><span class="sig-name descname"><span class="pre">Interpreter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">garbage_collect_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L27"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Interpreter" title="Permalink to this definition">¶</a></dt>
<dd><p>解释器逐节点执行 FX 图。这种模式对于许多事情都很有用，包括编写代码转换和分析过程。</p>
<p>可以覆盖解释器类中的方法来自定义执行行为。可覆盖方法的调用层次映射：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="n">run</span><span class="p">()</span>
    <span class="o">+--</span> <span class="n">run_node</span>
        <span class="o">+--</span> <span class="n">placeholder</span><span class="p">()</span>
        <span class="o">+--</span> <span class="n">get_attr</span><span class="p">()</span>
        <span class="o">+--</span> <span class="n">call_function</span><span class="p">()</span>
        <span class="o">+--</span> <span class="n">call_method</span><span class="p">()</span>
        <span class="o">+--</span> <span class="n">call_module</span><span class="p">()</span>
        <span class="o">+--</span> <span class="n">output</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">示例</p>
<p>假设我们想要交换所有 <code class="docutils literal "><span class="pre">torch.neg</span></code> 的实例与 <code class="docutils literal "><span class="pre">torch.sigmoid</span></code> ，反之亦然（包括它们的 <code class="docutils literal "><span class="pre">Tensor</span></code> 方法等效）。我们可以这样子类化解释器：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NegSigmSwapInterpreter</span><span class="p">(</span><span class="n">Interpreter</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">call_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">Target</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call_method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">Target</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">"neg"</span><span class="p">:</span>
            <span class="n">call_self</span><span class="p">,</span> <span class="o">*</span><span class="n">args_tail</span> <span class="o">=</span> <span class="n">args</span>
            <span class="k">return</span> <span class="n">call_self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="o">*</span><span class="n">args_tail</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call_method</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">fn</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">neg</span><span class="p">()</span>


<span class="n">gm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">NegSigmSwapInterpreter</span><span class="p">(</span><span class="n">gm</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>要执行的模块（torch.nn.Module）</p></li>
<li><p>garbage_collect_values（布尔值）- 是否在模块执行过程中删除其最后使用后的值。这确保了执行过程中的最佳内存使用。可以通过查看 <code class="docutils literal "><span class="pre">Interpreter.env</span></code> 属性来禁用此功能，以检查执行过程中的所有中间值。</p></li>
<li><p>graph（可选[Graph]）- 如果传入，解释器将使用提供的模块参数执行此图，而不是 module.graph，以满足对状态的任何请求。</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Interpreter.boxed_run">
<span class="sig-name descname"><span class="pre">boxed_run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args_list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.boxed_run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L200"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Interpreter.boxed_run" title="Permalink to this definition">¶</a></dt>
<dd><p>通过解释执行模块并返回结果。这使用“boxed”调用约定，其中传递一个参数列表，该列表将被解释器清除。这确保了输入张量能够及时释放。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Interpreter.call_function">
<span class="sig-name descname"><span class="pre">call_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.call_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L300"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Interpreter.call_function" title="Permalink to this definition">¶</a></dt>
<dd><p>执行一个 <code class="docutils literal "><span class="pre">call_function</span></code> 节点并返回结果。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>目标（目标）- 此节点的调用目标。有关语义详情，请参阅节点。</p></li>
<li><p>args（元组）- 此调用的位置参数元组。</p></li>
<li><p>kwargs（字典）- 此调用的关键字参数字典。</p></li>
</ul>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><em>任何</em></a></p>
</dd>
</dl>
<dl class="simple">
<dt>返回</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">Any: 函数调用的返回值</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Interpreter.call_method">
<span class="sig-name descname"><span class="pre">call_method</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.call_method"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L322"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Interpreter.call_method" title="Permalink to this definition">¶</a></dt>
<dd><p>执行一个 <code class="docutils literal "><span class="pre">call_method</span></code> 节点并返回结果。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>目标（目标）- 此节点的调用目标。有关语义详情，请参阅节点。</p></li>
<li><p>args（元组）- 此调用的位置参数元组。</p></li>
<li><p>kwargs（字典）- 此调用的关键字参数字典。</p></li>
</ul>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><em>任何</em></a></p>
</dd>
</dl>
<dl class="simple">
<dt>返回</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">Any: 方法调用的返回值</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Interpreter.call_module">
<span class="sig-name descname"><span class="pre">call_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.call_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L346"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Interpreter.call_module" title="Permalink to this definition">¶</a></dt>
<dd><p>执行一个 <code class="docutils literal "><span class="pre">call_module</span></code> 节点并返回结果。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>目标（目标）- 此节点的调用目标。有关语义详情，请参阅节点。</p></li>
<li><p>args（元组）- 此调用的位置参数元组。</p></li>
<li><p>kwargs（字典）- 此调用的关键字参数字典。</p></li>
</ul>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><em>任何</em></a></p>
</dd>
</dl>
<dl class="simple">
<dt>返回</font></font></font></dt><dd><p><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">Any: 模块调用返回的值</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Interpreter.fetch_args_kwargs_from_env">
<span class="sig-name descname"><span class="pre">fetch_args_kwargs_from_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.fetch_args_kwargs_from_env"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L413"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Interpreter.fetch_args_kwargs_from_env" title="Permalink to this definition">¶</a></dt>
<dd><p>从当前执行环境中获取节点 <code class="docutils literal "><span class="pre">n</span></code> 的 <code class="docutils literal "><span class="pre">args</span></code> 和 <code class="docutils literal "><span class="pre">kwargs</span></code> 的具体值。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>n (节点) – 需要获取 <code class="docutils literal "><span class="pre">args</span></code> 和 <code class="docutils literal "><span class="pre">kwargs</span></code> 的节点@2#。</p>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p> <code class="docutils literal "><span class="pre">args</span></code> 和 <code class="docutils literal "><span class="pre">kwargs</span></code> 的具体值为 <code class="docutils literal "><span class="pre">n</span></code> 。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[Tuple, Dict]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 保证向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Interpreter.fetch_attr">
<span class="sig-name descname"><span class="pre">fetch_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.fetch_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L392"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Interpreter.fetch_attr" title="Permalink to this definition">¶</a></dt>
<dd><p>从 <code class="docutils literal "><span class="pre">self.module</span></code> 的 <code class="docutils literal "><span class="pre">Module</span></code> 层次结构中获取属性。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>target (str) – 要获取的属性的完全限定名称</p>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>属性的值。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>任何</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Interpreter.get_attr">
<span class="sig-name descname"><span class="pre">get_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.get_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L279"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Interpreter.get_attr" title="Permalink to this definition">¶</a></dt>
<dd><p>执行一个 <code class="docutils literal "><span class="pre">get_attr</span></code> 节点。将从 <code class="docutils literal "><span class="pre">Module</span></code> 层级的 <code class="docutils literal "><span class="pre">self.module</span></code> 中检索属性值。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>目标（目标）- 此节点的调用目标。有关语义详情，请参阅节点。</p></li>
<li><p>args（元组）- 此调用位置参数的元组。</p></li>
<li><p>kwargs（字典）- 此调用关键字参数的字典。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>所检索到的属性值</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>任何</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 保证向下兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Interpreter.map_nodes_to_values">
将节点映射到值(args, n)[source][source] ¶</dt>
<dd><p>递归遍历 <code class="docutils literal "><span class="pre">args</span></code> 并在当前执行环境中查找每个 <code class="docutils literal "><span class="pre">Node</span></code> 的具体值。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>args（参数）- 用于查找具体值的内部数据结构。</p></li>
<li><p>n（节点）- <code class="docutils literal "><span class="pre">args</span></code> 所属的节点。这仅用于错误报告。</p></li>
</ul>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p>Optional[Union[ tuple[Union[ForwardRef('Argument'), ...], collections.abc.Sequence[ForwardRef('Argument')], collections.abc.Mapping[ str, ForwardRef('Argument')], slice, range, torch.fx.node.Node, str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, torch.SymInt, torch.SymBool, torch.SymFloat, NoneType], …], Sequence[Optional[Union[ tuple[ForwardRef('Argument'), …], Sequence[Argument], Mapping[ str, Argument], slice, range, Node, str, int, float, bool, complex, dtype, Tensor, device, memory_format, layout, OpOverload, SymInt, SymBool, SymFloat]]], Mapping[ str, Optional[Union[ tuple[ForwardRef('Argument'), …], Sequence[Argument], Mapping[ str, Argument], slice, range, Node, str, int, float, bool, complex, dtype, Tensor, device, memory_format, layout, OpOverload, SymInt, SymBool, SymFloat]]], slice, range, Node, str, int, float, bool, complex, dtype, Tensor, device, memory_format, layout, OpOverload, SymInt, SymBool, SymFloat]]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Interpreter.output">
<span class="sig-name descname"><span class="pre">output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L371"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Interpreter.output" title="Permalink to this definition">¶</a></dt>
<dd><p>执行一个 <code class="docutils literal "><span class="pre">output</span></code> 节点。这实际上只是检索由 <code class="docutils literal "><span class="pre">output</span></code> 节点引用的值并返回它。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>目标（目标）- 此节点的调用目标。有关语义详情，请参阅节点。</p></li>
<li><p>args（元组）- 此调用位置参数的元组。</p></li>
<li><p>kwargs（字典）- 此调用关键字参数的字典。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>输出节点引用的返回值</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>任何</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Interpreter.placeholder">
placeholder(target, args, kwargs)[源代码][源代码] ¶</dt>
<dd><p>执行一个 <code class="docutils literal "><span class="pre">placeholder</span></code> 节点。请注意，这是有状态的： <code class="docutils literal "><span class="pre">Interpreter</span></code> 维护一个对传递给 <code class="docutils literal "><span class="pre">run</span></code> 的参数的内部迭代器，此方法返回该迭代器的 next()。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>目标（Target）- 此节点的调用目标。有关语义的详细信息，请参阅 Node。</p></li>
<li><p>args（元组）- 此调用中位置参数的元组</p></li>
<li><p>kwargs（字典）- 此调用中关键字参数的字典</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>获取的参数值。</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>任何</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 保证向后兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Interpreter.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_io_processing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L121"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Interpreter.run" title="Permalink to this definition">¶</a></dt>
<dd><p>通过解释执行模块并返回结果。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>*args – 要运行的模块的参数，按位置顺序排列。</p></li>
<li><p>initial_env（可选[Dict[Node, Any]]）– 执行的可选起始环境。这是一个将 Node 映射到任何值的字典。这可以用来预先填充某些节点的结果，以便在解释器中进行部分评估。</p></li>
<li><p>enable_io_processing（bool）– 如果为 true，我们在使用之前首先使用图的 process_inputs 和 process_outputs 函数处理输入和输出。</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>执行模块返回的值</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>任何</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 保证向下兼容。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Interpreter.run_node">
运行节点(n)[source][source] ¶</dt>
<dd><p>在 <code class="docutils literal "><span class="pre">n</span></code> 运行特定节点并返回结果。根据 <code class="docutils literal "><span class="pre">node.op</span></code> 调用占位符、get_attr、call_function、call_method、call_module 或 output</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>n (节点) – 要执行的节点</p>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p>执行 <code class="docutils literal "><span class="pre">n</span></code> 的结果</p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>任何</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 保证向后兼容。</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch.fx.Transformer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch.fx.</span></span><span class="sig-name descname"><span class="pre">Transformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Transformer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L454"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Transformer" title="Permalink to this definition">¶</a></dt>
<dd><p> <code class="docutils literal "><span class="pre">Transformer</span></code> 是一种特殊的解释器，它产生一个新的 <code class="docutils literal "><span class="pre">Module</span></code> 。它公开了一个 <code class="docutils literal "><span class="pre">transform()</span></code> 方法，该方法返回转换后的 <code class="docutils literal "><span class="pre">Module</span></code> 。 <code class="docutils literal "><span class="pre">Transformer</span></code> 不需要任何参数即可运行，而 <code class="docutils literal "><span class="pre">Interpreter</span></code> 需要。 <code class="docutils literal "><span class="pre">Transformer</span></code> 完全以符号方式工作。</p>
<p class="rubric">示例</p>
<p>假设我们想要交换所有 <code class="docutils literal "><span class="pre">torch.neg</span></code> 的实例与 <code class="docutils literal "><span class="pre">torch.sigmoid</span></code> 以及它们的 <code class="docutils literal "><span class="pre">Tensor</span></code> 方法等效物（包括它们的 <code class="docutils literal "><span class="pre">Tensor</span></code> 方法等效物）。我们可以像这样子类化 <code class="docutils literal "><span class="pre">Transformer</span></code> ：</p>
<div class="highlight-default "><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NegSigmSwapXformer</span><span class="p">(</span><span class="n">Transformer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">call_function</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="s2">"Target"</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Argument</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call_method</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="s2">"Target"</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Argument</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">"neg"</span><span class="p">:</span>
            <span class="n">call_self</span><span class="p">,</span> <span class="o">*</span><span class="n">args_tail</span> <span class="o">=</span> <span class="n">args</span>
            <span class="k">return</span> <span class="n">call_self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="o">*</span><span class="n">args_tail</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call_method</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">fn</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">neg</span><span class="p">()</span>


<span class="n">gm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>

<span class="n">transformed</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">NegSigmSwapXformer</span><span class="p">(</span><span class="n">gm</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">()</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span><span class="n">transformed</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><p>模块（GraphModule）- 要转换的 <code class="docutils literal "><span class="pre">Module</span></code> </p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Transformer.call_function">
<span class="sig-name descname"><span class="pre">call_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Transformer.call_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L568"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Transformer.call_function" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><em>任何</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Transformer.call_module">
<span class="sig-name descname"><span class="pre">call_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Transformer.call_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L559"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Transformer.call_module" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><em>任何</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Transformer.get_attr">
<span class="sig-name descname"><span class="pre">get_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Transformer.get_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L540"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Transformer.get_attr" title="Permalink to this definition">¶</a></dt>
<dd><p>执行一个 <code class="docutils literal "><span class="pre">get_attr</span></code> 节点。在 <code class="docutils literal "><span class="pre">Transformer</span></code> 中，这被覆盖以在输出图中插入一个新的 <code class="docutils literal "><span class="pre">get_attr</span></code> 节点。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>目标（目标）- 此节点的调用目标。有关语义详情，请参阅节点</p></li>
<li><p>args（元组）- 此调用位置参数的元组</p></li>
<li><p>kwargs（字典）- 此调用关键字参数的字典</p></li>
</ul>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#torch.fx.Proxy" title="torch.fx.proxy.Proxy"><em>代理</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Transformer.placeholder">
placeholder(target, args, kwargs)[源码][源码] ¶</dt>
<dd><p>执行一个 <code class="docutils literal "><span class="pre">placeholder</span></code> 节点。在 <code class="docutils literal "><span class="pre">Transformer</span></code> 中，这被覆盖以向输出图插入一个新的 <code class="docutils literal "><span class="pre">placeholder</span></code> 。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>目标（Target）- 此节点的调用目标。有关语义的详细信息，请参阅节点。</p></li>
<li><p>args（元组）- 本调用中位置参数的元组</p></li>
<li><p>kwargs（字典）- 本调用中关键字参数的字典</p></li>
</ul>
</dd>
<dt class="field-even">返回类型<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#torch.fx.Proxy" title="torch.fx.proxy.Proxy"><em>代理</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>本 API 向后兼容性得到保证。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch.fx.Transformer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Transformer.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/interpreter.py#L575"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.Transformer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform <code class="docutils literal "><span class="pre">self.module</span></code> and return the transformed
<code class="docutils literal "><span class="pre">GraphModule</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>此 API 向后兼容性得到保证。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.fx.GraphModule" title="torch.fx.graph_module.GraphModule"><em>GraphModule</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torch.fx.replace_pattern">
<span class="sig-prename descclassname"><span class="pre">torch.fx.</span></span><span class="sig-name descname"><span class="pre">replace_pattern</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pattern</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replacement</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/subgraph_rewriter.html#replace_pattern"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="reference external" href="https://github.com/pytorch/pytorch/blob/134179474539648ba7dee1317959529fbd0e7f89/torch/fx/subgraph_rewriter.py#L94"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.fx.replace_pattern" title="Permalink to this definition">¶</a></dt>
<dd><p>匹配所有可能的非重叠操作符及其数据依赖集（ <code class="docutils literal "><span class="pre">pattern</span></code> ）在 GraphModule（ <code class="docutils literal "><span class="pre">gm</span></code> ）的图中，然后将这些匹配的子图替换为另一个子图（ <code class="docutils literal "><span class="pre">replacement</span></code> ）。</p>
<dl class="field-list simple">
<dt class="field-odd">参数<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>gm (GraphModule) – 包装图的 GraphModule 以进行操作</p></li>
<li><p>pattern (Union[Callable, GraphModule]) – 要在 <code class="docutils literal "><span class="pre">gm</span></code> 中匹配以进行替换的子图</p></li>
<li><p>替换（Union[Callable, GraphModule]）- 要替换 <code class="docutils literal "><span class="pre">pattern</span></code> 的子图</p></li>
</ul>
</dd>
<dt class="field-even">返回<span class="colon">:</span></dt>
<dd class="field-even"><p></p><p>代表原始图中与 <code class="docutils literal "><span class="pre">pattern</span></code> 匹配的地点的 <code class="docutils literal "><span class="pre">Match</span></code> 对象列表。如果没有匹配项，则列表为空。 <code class="docutils literal "><span class="pre">Match</span></code> 定义如下：</p>
<div class="highlight-python "><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Match</span><span class="p">(</span><span class="n">NamedTuple</span><span class="p">):</span>
    <span class="c1"># Node from which the match was found</span>
    <span class="n">anchor</span><span class="p">:</span> <span class="n">Node</span>
    <span class="c1"># Maps nodes in the pattern subgraph to nodes in the larger graph</span>
    <span class="n">nodes_map</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="n">Node</span><span class="p">]</span>
</pre></div>
</div>
<p></p>
</dd>
<dt class="field-odd">返回类型<span class="colon">:</span></dt>
<dd class="field-odd"><p>Match 列表</p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python "><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.fx</span> <span class="kn">import</span> <span class="n">symbolic_trace</span><span class="p">,</span> <span class="n">subgraph_rewriter</span>


<span class="k">class</span> <span class="nc">M</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">):</span>
        <span class="n">m1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">m2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">m1</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">m2</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">pattern</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">replacement</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">])</span>


<span class="n">traced_module</span> <span class="o">=</span> <span class="n">symbolic_trace</span><span class="p">(</span><span class="n">M</span><span class="p">())</span>

<span class="n">subgraph_rewriter</span><span class="o">.</span><span class="n">replace_pattern</span><span class="p">(</span><span class="n">traced_module</span><span class="p">,</span> <span class="n">pattern</span><span class="p">,</span> <span class="n">replacement</span><span class="p">)</span>
</pre></div>
</div>
<p>上述代码将首先在 <code class="docutils literal "><span class="pre">traced_module</span></code> 的 <code class="docutils literal "><span class="pre">forward</span></code> 方法中匹配 <code class="docutils literal "><span class="pre">pattern</span></code> 。模式匹配基于 use-def 关系，而不是节点名称。例如，如果您有 <code class="docutils literal "><span class="pre">pattern</span></code> 在 <code class="docutils literal "><span class="pre">p</span> <span class="pre">=</span> <span class="pre">torch.cat([a,</span> <span class="pre">b])</span></code> 中，则可以在原始 <code class="docutils literal "><span class="pre">forward</span></code> 函数中匹配 <code class="docutils literal "><span class="pre">m</span> <span class="pre">=</span> <span class="pre">torch.cat([a,</span> <span class="pre">b])</span></code> ，尽管变量名称不同（ <code class="docutils literal "><span class="pre">p</span></code> 与 <code class="docutils literal "><span class="pre">m</span></code> ）。</p>
<p> <code class="docutils literal "><span class="pre">return</span></code> 语句在 <code class="docutils literal "><span class="pre">pattern</span></code> 中仅根据其值进行匹配；它可能或可能不匹配到更大图中的 <code class="docutils literal "><span class="pre">return</span></code> 语句。换句话说，模式不必扩展到更大图的末尾。</p>
<p>当模式匹配时，它将从更大函数中移除，并由 <code class="docutils literal "><span class="pre">replacement</span></code> 替换。如果更大函数中有多个 <code class="docutils literal "><span class="pre">pattern</span></code> 匹配，则每个非重叠匹配都将被替换。在匹配重叠的情况下，重叠匹配集中找到的第一个匹配将被替换。（这里的“第一个”是指节点使用-定义关系的拓扑排序中的第一个。在大多数情况下，第一个节点是直接出现在 <code class="docutils literal "><span class="pre">self</span></code> 之后的参数，而最后一个节点是函数返回的内容。）</p>
<p>有一个重要的事情需要注意，那就是 <code class="docutils literal "><span class="pre">pattern</span></code> 可调用函数的参数必须在可调用函数本身中使用，而 <code class="docutils literal "><span class="pre">replacement</span></code> 可调用函数的参数必须匹配该模式。第一条规则是为什么在上面的代码块中， <code class="docutils literal "><span class="pre">forward</span></code> 函数有参数 <code class="docutils literal "><span class="pre">x,</span> <span class="pre">w1,</span> <span class="pre">w2</span></code> ，但 <code class="docutils literal "><span class="pre">pattern</span></code> 函数只有参数 <code class="docutils literal "><span class="pre">w1,</span> <span class="pre">w2</span></code> 。 <code class="docutils literal "><span class="pre">pattern</span></code> 没有使用 <code class="docutils literal "><span class="pre">x</span></code> ，因此不应将其指定为参数。作为第二条规则的例子，考虑替换</p>
<div class="highlight-python "><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pattern</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>替换为</p>
<div class="highlight-python "><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">replacement</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>在这种情况下， <code class="docutils literal "><span class="pre">replacement</span></code> 需要和 <code class="docutils literal "><span class="pre">pattern</span></code> 相同数量的参数（ <code class="docutils literal "><span class="pre">x</span></code> 和 <code class="docutils literal "><span class="pre">y</span></code> 都需要），即使参数 <code class="docutils literal "><span class="pre">y</span></code> 在 <code class="docutils literal "><span class="pre">replacement</span></code> 中没有被使用。</p>
<p>调用 <code class="docutils literal "><span class="pre">subgraph_rewriter.replace_pattern</span></code> 之后，生成的 Python 代码看起来像这样：</p>
<div class="highlight-python "><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">):</span>
    <span class="n">stack_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">])</span>
    <span class="n">sum_1</span> <span class="o">=</span> <span class="n">stack_1</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">stack_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">])</span>
    <span class="n">sum_2</span> <span class="o">=</span> <span class="n">stack_2</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">max_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">sum_1</span><span class="p">)</span>
    <span class="n">add_1</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">max_1</span>
    <span class="n">max_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">sum_2</span><span class="p">)</span>
    <span class="n">add_2</span> <span class="o">=</span> <span class="n">add_1</span> <span class="o">+</span> <span class="n">max_2</span>
    <span class="k">return</span> <span class="n">add_2</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>该 API 的向后兼容性得到保证。</p>
</div>
</dd></dl>

<span class="target" id="module-torch.fx.passes"></span><span class="target" id="module-torch.fx.passes.infra"></span><span class="target" id="module-torch.fx.passes.backends"></span><span class="target" id="module-torch.fx.passes.utils"></span><span class="target" id="module-torch.fx.passes.tests"></span><span class="target" id="module-torch.fx.experimental"></span><span class="target" id="module-torch.fx.experimental.unification"></span><span class="target" id="module-torch.fx.experimental.unification.multipledispatch"></span><span class="target" id="module-torch.fx.experimental.migrate_gradual_types"></span><span class="target" id="module-torch.fx.passes.dialect"></span><span class="target" id="module-torch.fx.passes.dialect.common"></span><span class="target" id="module-torch.fx.annotate"></span><span class="target" id="module-torch.fx.config"></span><span class="target" id="module-torch.fx.experimental.accelerator_partitioner"></span><span class="target" id="module-torch.fx.experimental.const_fold"></span><span class="target" id="module-torch.fx.experimental.debug"></span><span class="target" id="module-torch.fx.experimental.graph_gradual_typechecker"></span><span class="target" id="module-torch.fx.experimental.merge_matmul"></span><span class="target" id="module-torch.fx.experimental.meta_tracer"></span><span class="target" id="module-torch.fx.experimental.migrate_gradual_types.constraint"></span><span class="target" id="module-torch.fx.experimental.migrate_gradual_types.constraint_generator"></span><span class="target" id="module-torch.fx.experimental.migrate_gradual_types.constraint_transformation"></span><span class="target" id="module-torch.fx.experimental.migrate_gradual_types.operation"></span><span class="target" id="module-torch.fx.experimental.migrate_gradual_types.transform_to_z3"></span><span class="target" id="module-torch.fx.experimental.migrate_gradual_types.util"></span><span class="target" id="module-torch.fx.experimental.migrate_gradual_types.z3_types"></span><span class="target" id="module-torch.fx.experimental.normalize"></span><span class="target" id="module-torch.fx.experimental.optimization"></span><span class="target" id="module-torch.fx.experimental.partitioner_utils"></span><span class="target" id="module-torch.fx.experimental.recording"></span><span class="target" id="module-torch.fx.experimental.refinement_types"></span><span class="target" id="module-torch.fx.experimental.rewriter"></span><span class="target" id="module-torch.fx.experimental.schema_type_annotation"></span><span class="target" id="module-torch.fx.experimental.sym_node"></span><span class="target" id="module-torch.fx.experimental.unification.core"></span><span class="target" id="module-torch.fx.experimental.unification.dispatch"></span><span class="target" id="module-torch.fx.experimental.unification.match"></span><span class="target" id="module-torch.fx.experimental.unification.more"></span><span class="target" id="module-torch.fx.experimental.unification.multipledispatch.conflict"></span><span class="target" id="module-torch.fx.experimental.unification.multipledispatch.core"></span><span class="target" id="module-torch.fx.experimental.unification.multipledispatch.dispatcher"></span><span class="target" id="module-torch.fx.experimental.unification.multipledispatch.utils"></span><span class="target" id="module-torch.fx.experimental.unification.multipledispatch.variadic"></span><span class="target" id="module-torch.fx.experimental.unification.unification_tools"></span><span class="target" id="module-torch.fx.experimental.unification.utils"></span><span class="target" id="module-torch.fx.experimental.unification.variable"></span><span class="target" id="module-torch.fx.experimental.unify_refinements"></span><span class="target" id="module-torch.fx.experimental.validator"></span><span class="target" id="module-torch.fx.graph"></span><span class="target" id="module-torch.fx.graph_module"></span><span class="target" id="module-torch.fx.immutable_collections"></span><span class="target" id="module-torch.fx.interpreter"></span><span class="target" id="module-torch.fx.node"></span><span class="target" id="module-torch.fx.operator_schemas"></span><span class="target" id="module-torch.fx.passes.annotate_getitem_nodes"></span><span class="target" id="module-torch.fx.passes.backends.cudagraphs"></span><span class="target" id="module-torch.fx.passes.dialect.common.cse_pass"></span><span class="target" id="module-torch.fx.passes.fake_tensor_prop"></span><span class="target" id="module-torch.fx.passes.graph_drawer"></span><span class="target" id="module-torch.fx.passes.graph_manipulation"></span><span class="target" id="module-torch.fx.passes.graph_transform_observer"></span><span class="target" id="module-torch.fx.passes.infra.partitioner"></span><span class="target" id="module-torch.fx.passes.infra.pass_base"></span><span class="target" id="module-torch.fx.passes.infra.pass_manager"></span><span class="target" id="module-torch.fx.passes.net_min_base"></span><span class="target" id="module-torch.fx.passes.operator_support"></span><span class="target" id="module-torch.fx.passes.param_fetch"></span><span class="target" id="module-torch.fx.passes.pass_manager"></span><span class="target" id="module-torch.fx.passes.reinplace"></span><span class="target" id="module-torch.fx.passes.runtime_assert"></span><span class="target" id="module-torch.fx.passes.shape_prop"></span><span class="target" id="module-torch.fx.passes.split_module"></span><span class="target" id="module-torch.fx.passes.split_utils"></span><span class="target" id="module-torch.fx.passes.splitter_base"></span><span class="target" id="module-torch.fx.passes.tests.test_pass_manager"></span><span class="target" id="module-torch.fx.passes.tools_common"></span><span class="target" id="module-torch.fx.passes.utils.common"></span><span class="target" id="module-torch.fx.passes.utils.fuser_utils"></span><span class="target" id="module-torch.fx.passes.utils.matcher_utils"></span><span class="target" id="module-torch.fx.passes.utils.matcher_with_name_node_map_utils"></span><span class="target" id="module-torch.fx.passes.utils.source_matcher_utils"></span><span class="target" id="module-torch.fx.proxy"></span><span class="target" id="module-torch.fx.subgraph_rewriter"></span><span class="target" id="module-torch.fx.tensor_type"></span><span class="target" id="module-torch.fx.traceback"></span></section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        下一个 <img height="16" width="16" class="next-page" src="_static/images/chevron-right-orange.svg"> <img height="16" width="16" class="previous-page" src="_static/images/chevron-right-orange.svg"> 上一个
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>© 版权所有 PyTorch 贡献者。</p>
  </div>
    
      <div>使用 Sphinx 构建，主题由 Read the Docs 提供。</div>
     

</footer>

          </div>
<script>

var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torch.fx</a><ul>
<li><a class="reference internal" href="#module-torch.fx">概述</a></li>
<li><a class="reference internal" href="#writing-transformations">编写转换</a><ul>
<li><a class="reference internal" href="#a-quick-primer-on-graphs">图论快速入门</a></li>
<li><a class="reference internal" href="#graph-manipulation">图的操纵</a><ul>
<li><a class="reference internal" href="#direct-graph-manipulation">直接图操纵</a></li>
<li><a class="reference internal" href="#subgraph-rewriting-with-replace-pattern">使用 replace_pattern()进行子图重写</a></li>
<li><a class="reference internal" href="#graph-manipulation-examples">图操作示例</a></li>
</ul>
</li>
<li><a class="reference internal" href="#proxy-retracing">代理/重跟踪</a></li>
<li><a class="reference internal" href="#the-interpreter-pattern">解释器模式</a><ul>
<li><a class="reference internal" href="#examples-of-the-interpreter-pattern">解释器模式示例</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#debugging">调试</a><ul>
<li><a class="reference internal" href="#introduction">简介</a></li>
<li><a class="reference internal" href="#common-pitfalls-in-transform-authoring">转换创作中的常见陷阱</a></li>
<li><a class="reference internal" href="#checking-correctness-of-modules">检查模块的正确性</a></li>
<li><a class="reference internal" href="#debugging-the-generated-code">调试生成的代码</a><ul>
<li><a class="reference internal" href="#use-pdb">使用 <code class="docutils literal "><span class="pre">pdb</span></code> </a></li>
<li><a class="reference internal" href="#print-the-generated-code">打印生成的代码</a></li>
<li><a class="reference internal" href="#use-the-to-folder-function-from-graphmodule">使用来自 <code class="docutils literal "><span class="pre">GraphModule</span></code> 的 <code class="docutils literal "><span class="pre">to_folder</span></code> 函数</a></li>
</ul>
</li>
<li><a class="reference internal" href="#debugging-the-transformation">调试转换</a></li>
<li><a class="reference internal" href="#available-debuggers">可用的调试器</a></li>
</ul>
</li>
<li><a class="reference internal" href="#limitations-of-symbolic-tracing">符号追踪的局限性</a><ul>
<li><a class="reference internal" href="#dynamic-control-flow">动态控制流</a><ul>
<li><a class="reference internal" href="#static-control-flow">静态控制流</a></li>
</ul>
</li>
<li><a class="reference internal" href="#non-torch-functions">非 <code class="docutils literal "><span class="pre">torch</span></code> 函数</a></li>
<li><a class="reference internal" href="#customizing-tracing-with-the-tracer-class">使用 <code class="docutils literal "><span class="pre">Tracer</span></code> 类定制追踪</a><ul>
<li><a class="reference internal" href="#leaf-modules">叶子模块</a></li>
</ul>
</li>
<li><a class="reference internal" href="#miscellanea">杂项</a></li>
</ul>
</li>
<li><a class="reference internal" href="#api-reference">API 参考</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/clipboard.min.js"></script>
         <script src="_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script="" type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0">


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>文档</h2>
          <p>PyTorch 开发者文档全面访问</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">查看文档</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>教程</h2>
          <p>获取初学者和高级开发者的深入教程</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">查看教程</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>资源</h2>
          <p>查找开发资源并获得您的疑问解答</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">查看资源</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">开始使用</a></li>
            <li><a href="https://pytorch.org/features">功能</a></li>
            <li><a href="https://pytorch.org/ecosystem">生态系统</a></li>
            <li><a href="https://pytorch.org/blog/">博客</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">贡献</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">资源</a></li>
            <li><a href="https://pytorch.org/tutorials">教程</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">文档</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">讨论</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">GitHub 问题和任务</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">品牌指南</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">保持更新</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">推特</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">领英</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch 播客</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">苹果</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">谷歌</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">亚马逊</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">条款</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">隐私</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© 版权所有 Linux 基金会。PyTorch 基金会是 Linux 基金会的一个项目。有关本网站的使用条款、商标政策以及其他适用于 PyTorch 基金会的政策，请参阅 www.linuxfoundation.org/policies/。PyTorch 基金会支持 PyTorch 开源项目，该项目已被确立为 LF Projects, LLC 的 PyTorch 项目系列。有关适用于 PyTorch 项目系列 LF Projects, LLC 的政策，请参阅 www.lfprojects.org/policies/。</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">为分析流量并优化您的体验，我们在本网站上提供 cookies。通过点击或导航，您同意允许我们使用 cookies。作为本站点的当前维护者，Facebook 的 Cookies 政策适用。了解更多信息，包括可用的控制选项：Cookies 政策。</p>
    <img class="close-button" src="_static/images/pytorch-x.svg" width="16" height="16">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>学习</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">开始学习</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">教程</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">学习基础知识</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch 菜谱</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">PyTorch 入门 - YouTube 系列</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>生态系统</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">工具</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">社区</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">论坛</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">开发者资源</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">贡献者奖项 - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">关于 PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch 文档</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>文档</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch 领域</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>博客 &amp; 新闻</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch 博客</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">社区博客</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">视频</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">社区故事</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">活动</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">通讯</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>关于</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch 基金会</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">治理委员会</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">云信用计划</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">技术顾问委员会</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">员工</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">联系我们</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>

</body></html>