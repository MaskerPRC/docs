<!DOCTYPE html>
<html lang="zh_CN">
<head>
  <meta charset="UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.cuda.memory — PyTorch main documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/cuda/memory.html">
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css">
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css">
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css">
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css">
  <link rel="stylesheet" href="../../../_static/katex-math.css" type="text/css">
  <link rel="stylesheet" href="../../../_static/sphinx-dropdown.css" type="text/css">
  <link rel="stylesheet" href="../../../_static/panels-bootstrap.min.css" type="text/css">
  <link rel="stylesheet" href="../../../_static/css/jit.css" type="text/css">
  <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css">
    <link rel="index" title="Index" href="../../../genindex.html">
    <link rel="search" title="Search" href="../../../search.html">

<!--
  Search engines should not index the main version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head><body class="pytorch-body"><div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">学习</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class="dropdown-title">开始使用</span>
                  <p>在本地运行 PyTorch 或快速开始使用支持的云平台之一</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">教程</span><p></p>
                  <p>PyTorch 教程中有什么新内容</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">学习基础知识</span><p></p>
                  <p>熟悉 PyTorch 的概念和模块</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch 烹饪技巧</span><p></p>
                  <p>精简型、可直接部署的 PyTorch 代码示例</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">PyTorch 入门 - YouTube 系列</span><p></p>
                  <p>通过我们引人入胜的 YouTube 教程系列掌握 PyTorch 基础知识</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">生态系统</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">工具</span><p></p>
                  <p>了解 PyTorch 生态系统中的工具和框架</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">社区</span>
                  <p>加入 PyTorch 开发者社区，贡献、学习并获得问题解答</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">论坛</span>
                  <p>讨论 PyTorch 代码、问题、安装、研究的地方</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">开发者资源</span>
                  <p>查找资源并解答问题</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">贡献者奖项 - 2024</span><p></p>
                  <p>本届 PyTorch 会议揭晓获奖者</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">关于 PyTorch Edge</span><p></p>
                  <p>为边缘设备构建创新和隐私感知的 AI 体验</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span><p></p>
                  <p>针对移动和边缘设备实现设备端推理能力的端到端解决方案</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch 文档</span><p></p>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">文档</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span><p></p>
                  <p>探索文档以获取如何使用 PyTorch 的全面指南</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch 领域</span><p></p>
                  <p>阅读 PyTorch 领域的文档以了解更多关于特定领域的库</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">博客与新闻</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch 博客</span><p></p>
                  <p>跟上最新的技术新闻和动态</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">社区博客</span><p></p>
                  <p>PyTorch 生态系统故事</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">视频</span><p></p>
                  <p>了解最新的 PyTorch 教程、新内容等</p>
                </a><a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">社区故事</span><p></p>
                  <p>了解我们的社区如何使用 PyTorch 解决真实、日常的机器学习问题</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">活动</span><p></p>
                  <p>查找活动、网络研讨会和播客</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">通讯</span><p></p>
                  <p>保持最新更新</p>
                </a>
            </div>
          </div></li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">关于</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch 基金会</span><p></p>
                  <p>了解更多关于 PyTorch 基金会的信息</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">管理委员会</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">云信用计划</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">技术顾问委员会</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">员工</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">联系我们</span><p></p>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">成为会员</a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>



   

    

    <div class="table-of-contents-link-wrapper">
      <span>目录</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="https://pytorch.org/docs/versions.html">主页 (2.7.0+cpu ) ▼</a>
    </div>
    <div id="searchBox">
    <div class="searchbox" id="googleSearchBox">
      <script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
      <div class="gcse-search"></div>
    </div>
    <div id="sphinxSearchBox" style="display: none;">
      <div role="search">
        <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
          <input type="text" name="q" placeholder="Search Docs">
          <input type="hidden" name="check_keywords" value="yes">
          <input type="hidden" name="area" value="default">
        </form>
      </div>
    </div>
  </div>
  <form id="searchForm">
    <label style="margin-bottom: 1rem">
      <input type="radio" name="searchType" value="google" checked="">Google 搜索</label>
    <label style="margin-bottom: 1rem">
      <input type="radio" name="searchType" value="sphinx">经典搜索</label>
  </form>

  <script>
     document.addEventListener('DOMContentLoaded', function() {
      const searchForm = document.getElementById('searchForm');
      const googleSearchBox = document.getElementById('googleSearchBox');
      const sphinxSearchBox = document.getElementById('sphinxSearchBox');
      // Function to toggle search box visibility
      function toggleSearchBox(searchType) {
        googleSearchBox.style.display = searchType === 'google' ? 'block' : 'none';
        sphinxSearchBox.style.display = searchType === 'sphinx' ? 'block' : 'none';
      }
      // Determine the default search type
      let defaultSearchType;
      const currentUrl = window.location.href;
      if (currentUrl.startsWith('https://pytorch.org/docs/stable')) {
        // For the stable documentation, default to Google
        defaultSearchType = localStorage.getItem('searchType') || 'google';
      } else {
        // For any other version, including docs-preview, default to Sphinx
        defaultSearchType = 'sphinx';
      }
      // Set the default search type
      document.querySelector(`input[name="searchType"][value="${defaultSearchType}"]`).checked = true;
      toggleSearchBox(defaultSearchType);
      // Event listener for changes in search type
      searchForm.addEventListener('change', function(event) {
        const selectedSearchType = event.target.value;
        localStorage.setItem('searchType', selectedSearchType);
        toggleSearchBox(selectedSearchType);
      });
      // Set placeholder text for Google search box
      window.onload = function() {
        var placeholderText = "Search Docs";
        var googleSearchboxText = document.querySelector("#gsc-i-id1");
        if (googleSearchboxText) {
          googleSearchboxText.placeholder = placeholderText;
          googleSearchboxText.style.fontFamily = 'FreightSans';
          googleSearchboxText.style.fontSize = "1.2rem";
          googleSearchboxText.style.color = '#262626';
        }
      };
    });
  </script>

          </div>

          

<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/_modules/torch/cuda/memory.html">您正在查看不稳定开发者预览文档。请点击此处查看最新稳定版本的文档。</a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">社区</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../community/build_ci_governance.html">PyTorch 治理 | 构建 + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community/contribution_guide.html">PyTorch 贡献指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community/design.html">PyTorch 设计哲学</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community/governance.html">PyTorch 治理 | 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community/persons_of_interest.html">PyTorch 治理 | 维护者</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">开发者笔记</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/amp_examples.html">自动混合精度示例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/autograd.html">Autograd 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/broadcasting.html">广播语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/cpu_threading_torchscript_inference.html">CPU 多线程和 TorchScript 推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/cuda.html">CUDA 语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/custom_operators.html">PyTorch 自定义算子页面</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/ddp.html">分布式数据并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/extending.html">扩展 PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/extending.func.html">扩展 torch.func 与 autograd.Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/faq.html">常见问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/fsdp.html">FSDP 笔记</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/get_start_xpu.html">在 Intel GPU 上入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/gradcheck.html">毕业审核机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/hip.html">HIP (ROCm) 语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/large_scale_deployments.html">大规模部署功能</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/libtorch_stable_abi.html">LibTorch 稳定 ABI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/modules.html">模块</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/mps.html">MPS 后端</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/multiprocessing.html">多进程最佳实践</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/numerical_accuracy.html">数值精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/randomness.html">可重复性</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/serialization.html">序列化语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/windows.html">Windows 常见问题解答</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">语言绑定</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensor_attributes.html">Tensor 属性</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensor_view.html">张量视图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../accelerator.html">torch 加速器</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cpu.html">torch.cpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../torch_cuda_memory.html">理解 CUDA 内存使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../torch_cuda_memory.html#generating-a-snapshot">生成快照</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../torch_cuda_memory.html#using-the-visualizer">使用可视化器</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../torch_cuda_memory.html#snapshot-api-reference">快照 API 参考</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mps.html">torch.mps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../xpu.html">torch.xpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mtia.html">torch.mtia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mtia.memory.html">torch.mtia.memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../meta.html">元设备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../export.html">torch.export</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.tensor.html">torch.distributed.tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.fsdp.fully_shard.html">torch.distributed.fsdp.fully_shard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.pipelining.html">torch.distributed.pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../torch.compiler.html">torch.compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../func.html">torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fx.experimental.html">torch.fx.experimental</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../signal.html">torch.signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nn.attention.html">torch.nn.attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../complex_numbers.html">复数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ddp_comm_hooks.html">DDP 通信钩子</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quantization.html">量化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rpc.html">分布式 RPC 框架</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../masked.html">torch.masked</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../size.html">torch.Size</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../storage.html">torch 存储</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">torch.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deterministic.html">torch.utils.deterministic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../module_tracker.html">torch.utils.module_tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../type_info.html">类型信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../named_tensor.html">命名张量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../name_inference.html">命名张量操作覆盖率</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../future_mod.html">torch.__future__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">torch._logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../torch_environment_variables.html">火炬环境变量</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">图书馆</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">火炬推荐</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/xla/">PyTorch 在 XLA 设备上</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/ao">torchao</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        文档 &gt;</li>

        
          <li>模块代码 &gt;</li>
        
          <li><a href="../../torch.html">torch</a> &gt;</li>
        
          <li><a href="../cuda.html">torch.cuda</a> &gt;</li>
        
      <li>torch.cuda.memory</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">快捷键</div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>torch.cuda.memory 的源代码</font></font></font></h1><div class="highlight"><pre><span></span><span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># mypy: 允许未类型化定义</span>
<span class="sa">r</span><span class="sd">"此软件包增加了对 CUDA 实现的设备内存管理的支持。"</span>

<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">集合</span>
<span class="kn">导入</span> <span class="nn">contextlib</span>
<span class="kn">导入</span> <span class="nn">ctypes</span>
<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">酸菜</span>
<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">系统</span>
<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">警告</span>
<span class="kn">来自</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">检查</font></font></font></span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">签名</span>
<span class="kn">来自</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">打字</font></font></font></span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n">Any</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">直接</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">联合</span>
<span class="kn">来自</font></font></font></span> <span class="nn">typing_extensions</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">已弃用</span>

<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</span>
<span class="kn">来自</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="n">_C</span>
<span class="kn">来自</font></font></font></span> <span class="nn">torch._utils</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="n">_dummy_type</span>
<span class="kn">来自</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">torch 的类型</font></font></font></span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span>

<span class="kn">来自</font></font></font></span> <span class="nn">.</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="p">(</span>
    <span class="n">_get_amdsmi_device_index</span><span class="p">,</span>
    <span class="n">获取设备索引</span><span class="p">,</span>
    <span class="n">获取 nvml 设备索引</span><span class="p">,</span>
    <span class="n">_lazy_init</span><span class="p">,</span>
    <span class="n">已初始化</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">来自</font></font></font></span> <span class="nn">._memory_viz</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">内存</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">内存</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">段落</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_段落</span>


<span class="n">全部</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"缓存分配器分配"</span><span class="p">,</span>
    <span class="s2">"缓存分配器删除"</span><span class="p">,</span>
    <span class="s2">"缓存分配器启用"</span><span class="p">,</span>
    <span class="s2">get_per_process_memory_fraction</span><span class="p">,</span>
    <span class="s2">"设置每个进程内存分数"</span><span class="p">,</span>
    <span class="s2">清空缓存</span><span class="p">,</span>
    <span class="s2">内存统计</span><span class="p">,</span>
    <span class="s2">内存统计嵌套字典</span><span class="p">,</span>
    <span class="s2">"重置累计内存统计"</span><span class="p">,</span>
    <span class="s2">"重置峰值内存统计"</span><span class="p">,</span>
    <span class="s2">"重置最大分配内存"</span><span class="p">,</span>
    <span class="s2">"重置最大缓存内存"</span><span class="p">,</span>
    <span class="s2">"host_memory_stats"</span><span class="p">,</span>
    <span class="s2">"host_memory_stats_as_nested_dict"</span><span class="p">,</span>
    <span class="s2">"重置累积的主机内存统计信息"</span><span class="p">,</span>
    <span class="s2">"重置峰值主机内存统计"</span><span class="p">,</span>
    <span class="s2">"内存分配"</span><span class="p">,</span>
    <span class="s2">"最大分配内存"</span><span class="p">,</span>
    <span class="s2">"内存保留"</span><span class="p">,</span>
    <span class="s2">"max_memory_reserved"</span><span class="p">,</span>
    <span class="s2">"内存缓存"</span><span class="p">,</span>
    <span class="s2">"max_memory_cached"</span><span class="p">,</span>
    <span class="s2">"内存快照"</span><span class="p">,</span>
    <span class="s2">内存摘要</span><span class="p">,</span>
    <span class="s2">"列出 GPU 进程"</span><span class="p">,</span>
    <span class="s2">"mem_get_info"</span><span class="p">,</span>
    <span class="s2">获取分配器后端</span><span class="p">,</span>
    <span class="s2">CUDA 可插拔分配器</span><span class="p">,</span>
    <span class="s2">更改当前分配器</span><span class="p">,</span>
    <span class="s2">"内存池"</span><span class="p">,</span>
    <span class="s2">"内存池上下文"</span><span class="p">,</span>
    <span class="s2">"使用内存池"</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">如果</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">不是</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="p">,</span> <span class="s2">"_cuda_CUDAAllocator"</span><span class="p">):</span>
    <span class="c1">定义虚拟基类</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="vm">字典</span><span class="p">[</span><span class="s2">"_cuda_CUDAAllocator"</span><span class="p">]</span> <span class="o">=</span> <span class="n">_dummy_type</span><span class="p">(</span><span class="s2">"_cuda_CUDAAllocator"</span><span class="p">)</span>


<span class="k">如果</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">不是</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</font></font></font></span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_内存池</span><span class="p">):</span>
    <span class="c1">定义虚拟基类</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="vm">字典</font></font></font></span><span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_内存池</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="n">_dummy_type</span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_内存池</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="vm">字典</font></font></font></span><span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_内存池上下文</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="n">_dummy_type</span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_内存池上下文</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="vm">字典</span><span class="p">[</span><span class="s2">"_cuda_beginAllocateToPool"</span><span class="p">]</span> <span class="o">=</span> <span class="n">_dummy_type</span><span class="p">(</span>
        <span class="s2">"_cuda_beginAllocateToPool"</span>
    <span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="vm">字典</span><span class="p">[</span><span class="s2">"_cuda_endAllocateCurrentStreamToPool"</span><span class="p">]</span> <span class="o">=</span> <span class="n">_dummy_type</span><span class="p">(</span>
        <span class="s2">"_cuda_endAllocateCurrentStreamToPool"</span>
    <span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="vm">字典</font></font></font></span><span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_cuda_releasePool</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="n">_dummy_type</span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_cuda_releasePool</span><span class="p">)</span>

<span class="kn">来自</font></font></font></span> <span class="nn">torch._C</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="p">(</span>  <span class="c1"># noqa: F401</span>
    <span class="n">_cuda_beginAllocateToPool</span><span class="p">,</span>
    <span class="n">_cuda_CUDA 分配器</span><span class="p">,</span>
    <span class="n">_cuda_endAllocateCurrentStreamToPool</span><span class="p">,</span>
    <span class="n">_cuda_releasePool</span><span class="p">,</span>
    <span class="n">_MemPool</span><span class="p">,</span>
    <span class="n">_MemPoolContext</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">_host 分配器</span><span class="p">():</span>
    <span class="n">_lazy_init</span><span class="p">()</span>
    <span class="k">返回</font></font></font></span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_cuda_cudaHost 分配器</span><span class="p">()</span>


<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">_free 互斥锁</span><span class="p">():</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_cuda 锁互斥锁</span><span class="p">()</span>
    <span class="k">尝试</span><span class="p">:</span>
        <span class="k">产生</span>
    <span class="k">最后</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_cuda_unlock_mutex</span><span class="p">()</span>


<div class="viewcode-block" id="caching_allocator_alloc"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def 缓存分配器分配(size, device: 联合[Device, int] = None, stream=None):
r"""使用 CUDA 内存分配器进行内存分配。

为指定设备和流分配内存，
函数旨在与其他系统进行互操作性使用
框架。分配的内存通过
:func:`~torch.cuda.caching_allocator_delete`.

参数:
大小（int 类型）：要分配的字节数。
设备（torch.device 或 int，可选）：选定的设备。如果是
``None``，则使用默认的 CUDA 设备。
流（torch.cuda.Stream 或 int，可选）：选定的流。如果是 ``None``，则
选择的设备默认流被使用。

.. 注意::
更多关于 GPU 内存管理的详细信息，请参阅 :ref:`cuda-memory-management`。
管理。
"""
如果设备为空：
设备 = torch.cuda.current_device()
设备 = _get_device_index(设备)
如果 stream 为 None：
stream = torch.cuda.current_stream(device)
如果 stream 是 torch.cuda.streams.Stream 的实例：
stream = stream.cuda_stream
如果 stream 不是 int 类型：
raise TypeError(
"stream 参数类型无效，必须是"
"`torch.cuda.Stream`或表示指针的 int 类型"
"指向现有流"
        )
使用 torch.cuda.device(device):
返回 torch._C._cuda_cudaCachingAllocator_raw_alloc(size, stream)</font></font></font></div>


<div class="viewcode-block" id="caching_allocator_delete"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def 缓存分配器删除(mem_ptr):
r"""使用 CUDA 内存分配器分配的内存删除。

使用 :func:`~torch.cuda.caching_allocator_alloc` 分配的内存。
在这里释放。关联的设备和流在内部跟踪。
分配器。

Args:
mem_ptr (int): 分配器要释放的内存地址。

.. 注意::
查看更多关于 GPU 内存管理的详细信息：:ref:`cuda-memory-management`
管理信息。
"""
torch._C._cuda_cudaCachingAllocator_raw_delete(mem_ptr)</font></font></font></div>


<div class="viewcode-block" id="caching_allocator_enable"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def caching_allocator_enable(value: bool = True) -&gt; None:
r"""启用或禁用 CUDA 内存分配器。默认开启。"""
if is_initialized():
torch._C._cuda_cudaCachingAllocator_enable(value)</font></font></font></div>


<div class="viewcode-block" id="set_per_process_memory_fraction"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def set_per_process_memory_fraction(
分数，device: Union[Device, int] = None
) -&gt; None:
r"""为进程设置内存分数。

分数用于限制缓存分配器在 CUDA 设备上分配的内存。
允许的值等于总可见内存乘以分数。
如果尝试在一个进程中分配超过允许的值，将在分配器中引发内存错误。
在分配器中引发内存错误。

Args:
分数(float): 范围：0~1。允许的内存等于总内存 * 分数。
设备 (torch.device 或 int, 可选): 选择设备。如果它是
``None``，则使用默认的 CUDA 设备。
.. 注意::
通常情况下，可用总内存小于总容量。
"""
_lazy_init()
如果设备为空：
设备 = torch.cuda.current_device()
设备 = _get_device_index(设备)
如果分数不是浮点数：
抛出 TypeError 异常("分数参数类型无效，必须是`float`类型")
如果分数小于 0 或大于 1：
抛出 ValueError 异常(f"无效的分数值：{fraction}。允许的范围：0~1")

torch._C._cuda_setMemoryFraction(fraction, device)</font></font></font></div>


<div class="viewcode-block" id="get_per_process_memory_fraction"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def get_per_process_memory_fraction(device: Union[torch.device, int] = None) -&gt; float:
r"""获取进程的内存分数。

Args:
device (torch.device 或 int，可选)：选定的设备。如果它是
使用默认的 CUDA 设备。
返回：
内存分数，范围在 0~1 之间。允许使用的内存等于总内存 * 分数。
"""
_lazy_init()
if 设备为 None:
设备 = torch.cuda.current_device()
设备 = _get_device_index(设备)
return torch._C._cuda_getMemoryFraction(device)</font></font></font></div>


<div class="viewcode-block" id="empty_cache"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def empty_cache() -&gt; None:
r"""释放当前由缓存分配器持有的所有未占用缓存内存，以便这些内存可以被其他 GPU 应用程序使用，并在`nvidia-smi`中可见。
r"""释放当前由缓存分配器持有的所有未占用缓存内存，以便这些内存可以被其他 GPU 应用程序使用，并在`nvidia-smi`中可见。
r"""释放当前由缓存分配器持有的所有未占用缓存内存，以便这些内存可以被其他 GPU 应用程序使用，并在`nvidia-smi`中可见。

.. 注意::
`~torch.cuda.empty_cache()` 并不会增加 PyTorch 可用的 GPU 内存量。然而，在某些情况下，它可能有助于减少 GPU 内存碎片。有关信息，请参阅 :ref:`cuda-memory-management`。
然而，它可能有助于减少 GPU 内存碎片。有关信息，请参阅 :ref:`cuda-memory-management`。
。有关信息，请参阅 :ref:`cuda-memory-management`。
更多关于 GPU 内存管理的详细信息。
"""
如果 is_initialized()返回 True：
torch._C._cuda_emptyCache()</font></font></font></div>


<div class="viewcode-block" id="memory_stats"><a class="viewcode-back" href="../../../generated/torch.cuda.memory_stats.html#torch.cuda.memory_stats">[文档]</font></font></font></a><span class="k">def</span> <span class="nf"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">内存统计</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">联合</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字典</font></font></font></span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">返回给定设备的 CUDA 内存分配器统计信息的字典。</span>

<span class="sd">该函数的返回值是一个包含统计信息的字典，</span>
<span class="sd">非负整数。</span>

<span class="sd">核心统计：</span>

<span class="sd">    - ``"allocated.{all,large_pool,small_pool}.{current,peak,allocated,freed}"``:</span>
<span class="sd">内存分配器接收到的分配请求的数量。</span>
<span class="sd">    - ``"allocated_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}"``:</span>
<span class="sd">分配的内存量。</span>
<span class="sd">    - ``"segment.{all,large_pool,small_pool}.{current,peak,allocated,freed}"``:</span>
<span class="sd">从 `cudaMalloc()` 保留的段数。</span>
<span class="sd">    - ``"reserved_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}"``:</span>
<span class="sd">预留内存量。</span>
<span class="sd">    - ``"active.{all,large_pool,small_pool}.{current,peak,allocated,freed}"``:</span>
<span class="sd">活跃内存块的数量。</span>
<span class="sd">    - ``"active_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}"``:</span>
<span class="sd">活跃内存的总量。</span>
<span class="sd">inactive_split.{all,large_pool,small_pool}.{current,peak,allocated,freed}</span>
<span class="sd">无效且不可释放的内存块数量。</span>
<span class="sd">inactive_split_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}</span>
<span class="sd">无效且不可释放的内存量。</span>

<span class="sd">对于这些核心统计，值如下分解。</span>

<span class="sd">池类型：</span>

<span class="sd">- ``all``: 所有内存池的合并统计。</span>
<span class="sd">- ``large_pool``: 大分配池的统计信息</span>
<span class="sd">（截至 2019 年 10 月，对于大小≥1MB 的分配）。</span>
<span class="sd">- ``small_pool``: 小分配池的统计信息</span>
<span class="sd">截至 2019 年 10 月，对于小于 1MB 的分配。</span>

<span class="sd">指标类型：</span>

<span class="sd">- ``current``: 当前此指标的值。</span>
<span class="sd">- ``peak``: 此指标的最大值。</span>
<span class="sd">- ``allocated``: 此指标的历史总增长量。</span>
<span class="sd">- ``freed``: 此指标的历史总减少量。</span>

<span class="sd">除了核心统计信息外，我们还提供了一些简单的计数器：</span>
<span class="sd">    counters:</span>

<span class="sd">- ``"num_alloc_retries"``: 失败的 ``cudaMalloc`` 调用次数</span>
<span class="sd">导致缓存刷新并重试。</span>
<span class="sd">- ``"num_ooms"``: 抛出的内存不足错误数量。</span>
<span class="sd">- ``"num_sync_all_streams"``: 调用 ``synchronize_and_free_events`` 事件的次数。</span>
<span class="sd">- ``"num_device_alloc"``: CUDA 分配调用次数。这包括 cuMemMap 和 cudaMalloc。</span>
<span class="sd">cuMemMap 和 cudaMalloc。</span>
<span class="sd">- ``"num_device_free"``: CUDA 空闲调用次数。这包括 cuMemUnmap</span>
<span class="sd">并且 cudaFree。</span>

<span class="sd">缓存分配器可以通过 ENV 配置，以不分割大于 a 的块</span>
<span class="sd">定义大小（参见 Cuda 语义文档中的内存管理部分）。</span>
<span class="sd">这有助于避免内存碎片化，但可能会影响性能</span>
<span class="sd">额外的输出有助于调整和评估影响</span>

<span class="sd">- ``"max_split_size"``: 大于此大小的块将不会分割。</span>
<span class="sd">    - ``"oversize_allocations.{current,peak,allocated,freed}"``:</span>
<span class="sd">内存分配器接收到的超大小分配请求的数量。</span>
<span class="sd">    - ``"oversize_segments.{current,peak,allocated,freed}"``:</span>
<span class="sd">cudaMalloc() 保留的过大段落数量。</span>

<span class="sd">缓存分配器可以通过 ENV 配置以四舍五入内存分配</span>
<span class="sd">为了减少碎片化。有时舍入带来的开销可能比</span>
<span class="sd">帮助减少的碎片化。以下统计数据可以用来检查</span>
<span class="sd">四舍五入添加了过多的开销：</span>

<span class="sd">    - ``"requested_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}"``:</span>
<span class="sd">客户端代码请求的内存，与 allocated_bytes 进行比较，以检查</span>
<span class="sd">分配四舍五入添加了过多的开销。</span>

<span class="sd">参数：</span>
<span class="sd">设备（torch.device 或 int，可选）：选定的设备。返回当前设备打印信息，由 :func:`~torch.cuda.current_device` 提供，</span>
<span class="sd">当前设备的统计信息，由:func:`~torch.cuda.current_device`提供，</span>
<span class="sd">如果 :attr:`device` 为 ``None``（默认）。</span>

<span class="sd">.. 注意::</span>
<span class="sd">查看 :ref:`cuda-memory-management` 以获取更多关于 GPU 内存管理的详细信息。</span>
<span class="sd">内存管理。</span>

<span class="sd">.. 注意::</span>
<span class="sd">使用：ref:`后端：cudaMallocAsync`, 一些统计信息可能没有意义，并且总是报告为零。</span>
<span class="sd">没有意义，并且总是报告为零。</span>
<span class="sd">"沉浸式翻译"</span>
    <span class="n">结果</font></font></font></span> <span class="o">=</span> <span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本为空，请提供需要翻译的文本</span>

    <span class="k">def</span> <span class="nf">_递归添加到结果</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</span><span class="p">):</span>
        <span class="k">如果</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</font></font></font></span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字典</span><span class="p">):</span>
            <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">前缀</span> <span class="o">+=</span> <span class="s2">"."</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">项目</span><span class="p">():</span>
                <span class="n">_递归添加到结果</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="n">结果</font></font></font></span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</span><span class="p">))</span>

    <span class="n">统计</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">内存统计嵌套字典</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">)</span>
    <span class="n">_递归添加到结果</font></font></font></span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本翻译为简体中文为：""</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">统计</span><span class="p">)</span>
    <span class="n">结果</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">排序</span><span class="p">()</span>

    <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">集合</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有序字典</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">结果</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">内存统计嵌套字典</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">联合</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字典</font></font></font></span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">返回 `torch.cuda.memory_stats` 的结果，以嵌套字典形式。</span>
    <span class="k">如果</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">不是</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">已初始化</span><span class="p">():</span>
        <span class="k">返回</span> <span class="p">{}</span>
    <span class="n">设备</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取设备索引</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选的</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</span><span class="p">)</span>
    <span class="k">返回</font></font></font></span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_cuda_memoryStats</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">重置累积内存统计</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">联合</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">重置由 CUDA 内存分配器跟踪的“累计”（历史）统计信息。</span>

<span class="sd">详细信息请参阅 :func:`~torch.cuda.memory_stats`。累计统计信息对应于</span>
<span class="sd">每个单独的统计字典中的“已分配”和“已释放”键，以及</span>
<span class="sd">`"num_alloc_retries"` 和 `"num_ooms"`。</span>

<span class="sd">参数：</span>
<span class="sd">设备（torch.device 或 int，可选）：选定的设备。返回当前设备打印信息，由 :func:`~torch.cuda.current_device` 提供，</span>
<span class="sd">当前设备的统计信息，由 :func:`~torch.cuda.current_device` 提供，</span>
<span class="sd">如果 :attr:`device` 为 ``None``（默认）。</span>

<span class="sd">.. 注意::</span>
<span class="sd">查看 :ref:`cuda-memory-management` 以获取更多关于 GPU 内存管理的详细信息。</span>
<span class="sd">内存管理。</span>
<span class="sd">"沉浸式翻译"</span>
    <span class="n">设备</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取设备索引</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选的</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</span><span class="p">)</span>
    <span class="k">返回</font></font></font></span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_cuda_resetAccumulatedMemoryStats</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">)</span>


<div class="viewcode-block" id="reset_peak_memory_stats"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def reset_peak_memory_stats(device: Union[Device, int] = None) -&gt; None:
重置 CUDA 内存分配器跟踪的"峰值"统计信息。

详细信息请参阅 :func:`~torch.cuda.memory_stats`。峰值统计信息对应于每个单独的统计字典中的"峰值"键。
`"峰值"`键对应于每个单独的统计字典。

参数：
设备（torch.device 或 int，可选）：选定的设备。返回
当前设备的统计信息，由:func:`~torch.cuda.current_device`给出，
如果:attr:`device`为`None`（默认）。

.. note::
查看更多关于 GPU 内存管理的详细信息：:ref:`cuda-memory-management`
管理信息。
"""
device = _get_device_index(device, optional=True)
return torch._C._cuda_resetPeakMemoryStats(device)</font></font></font></div>


<div class="viewcode-block" id="host_memory_stats"><a class="viewcode-back" href="../../../generated/torch.cuda.host_memory_stats.html#torch.cuda.host_memory_stats">[文档]</font></font></font></a><span class="k">def</span> <span class="nf">host_memory_stats</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字典</font></font></font></span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">返回给定设备的 CUDA 内存分配器统计信息的字典。</span>

<span class="sd">该函数的返回值是一个包含统计信息的字典，</span>
<span class="sd">非负整数。</span>

<span class="sd">核心统计：</span>

<span class="sd">     - ``"allocated.{current,peak,allocated,freed}"``:</span>
<span class="sd">内存分配器接收到的分配请求的数量。</span>
<span class="sd">``"allocated_bytes.{current,peak,allocated,freed}"``:</span>
<span class="sd">分配的内存量。</span>
<span class="sd">``"segment.{current,peak,allocated,freed}"``:</span>
<span class="sd">从 `cudaMalloc()` 保留的段数。</span>
<span class="sd">``"reserved_bytes.{current,peak,allocated,freed}"``:</span>
<span class="sd">预留内存量。</span>

<span class="sd">对于这些核心统计，值如下分解。</span>

<span class="sd">指标类型：</span>

<span class="sd">- ``current``: 当前此指标的值。</span>
<span class="sd">- ``peak``: 此指标的最大值。</span>
<span class="sd">- ``allocated``: 此指标的历史总增长量。</span>
<span class="sd">- ``freed``: 此指标的历史总减少量。</span>

<span class="sd">除了核心统计信息外，我们还提供了一些简单的计数器：</span>
<span class="sd">     counters:</span>

<span class="sd">- ``"num_host_alloc"``: CUDA 分配调用的数量。这包括 cudaHostAlloc 和 cudaHostRegister。</span>
<span class="sd">两种情况。</span>
<span class="sd">``"num_host_free"``: CUDA 空闲调用次数。这包括 cudaHostFree 和 cudaHostUnregister。</span>
<span class="sd">以及 cudaHostUnregister。</span>

<span class="sd">最后，我们还提供了一些简单的计时计数器：</span>

<span class="sd">``"host_alloc_time.{total,max,min,count,avg}"``:</span>
<span class="sd">通过 CUDA 调用进行的分配请求的时间。</span>
<span class="sd">     - ``"host_free_time.{total,max,min,count,avg}"``:</span>
<span class="sd">通过 CUDA 调用进行的释放请求的时间。</span>

<span class="sd">对于这些时间统计，值如下分解。</span>

<span class="sd">指标类型：</span>

<span class="sd">- ``total``: 总耗时。</span>
<span class="sd">- ``max``: 每次调用的最大值。</span>
<span class="sd">- ``min``: 每次调用的最小值。</span>
<span class="sd">- ``count``: 调用次数。</span>
<span class="sd">- ``avg``: 每次调用平均时间。</span>
<span class="sd">"沉浸式翻译"</span>
    <span class="n">结果</font></font></font></span> <span class="o">=</span> <span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本为空，请提供需要翻译的文本</span>

    <span class="k">def</span> <span class="nf">_递归添加到结果</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</span><span class="p">):</span>
        <span class="k">如果</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</font></font></font></span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字典</span><span class="p">):</span>
            <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">前缀</span> <span class="o">+=</span> <span class="s2">"."</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">项目</span><span class="p">():</span>
                <span class="n">_递归添加到结果</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="n">结果</font></font></font></span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</span><span class="p">))</span>

    <span class="n">统计</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">主机内存统计作为嵌套字典</span><span class="p">()</span>
    <span class="n">_递归添加到结果</font></font></font></span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本翻译为简体中文为：""</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">统计</span><span class="p">)</span>
    <span class="n">结果</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">排序</span><span class="p">()</span>

    <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">集合</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有序字典</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">结果</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">主机内存统计作为嵌套字典</font></font></font></span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字典</font></font></font></span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">返回 :func:`~torch.cuda.host_memory_stats` 的结果，以嵌套字典形式。</span>
    <span class="k">如果</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">不是</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">已初始化</span><span class="p">():</span>
        <span class="k">返回</span> <span class="p">{}</span>
    <span class="k">返回</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_cuda_hostMemoryStats</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">重置累积的主机内存统计信息</font></font></font></span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">重置由主机内存分配器跟踪的“累积”（历史）统计信息。</span>

<span class="sd">请参阅 :func:`~torch.cuda.host_memory_stats` 以获取详细信息。累积统计信息对应于每个统计字典中的 `"allocated"` 和 `"freed"` 键。</span>
<span class="sd">的 `"allocated"` 和 `"freed"` 键。</span>
<span class="sd">"沉浸式翻译"</span>
    <span class="k">返回</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_cuda_resetAccumulatedHostMemoryStats</span><span class="p">()</span>


<div class="viewcode-block" id="reset_peak_host_memory_stats"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def reset_peak_host_memory_stats() -&gt; None:
重置主机内存分配器跟踪的“峰值”统计信息。

详细信息请参阅 :func:`~torch.cuda.host_memory_stats`。峰值统计信息对应于每个单独的统计字典中的“峰值”键。
`"峰值"`键对应于每个单独的统计字典。
"""
return torch._C._cuda_resetPeakHostMemoryStats()</font></font></font></div>


<div class="viewcode-block" id="reset_max_memory_allocated"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def reset_max_memory_allocated(device: Union[Device, int] = None) -&gt; None:
r"""重置跟踪给定设备张量占用的最大 GPU 内存的起始点。

详细信息请参阅 :func:`~torch.cuda.max_memory_allocated`。

参数:
设备（torch.device 或 int，可选）：选定的设备。返回
当前设备的统计信息，由:func:`~torch.cuda.current_device`给出，
如果:attr:`device`为`None`（默认）。

..警告::
现在这个函数现在调用 :func:`~torch.cuda.reset_peak_memory_stats`，用于重置
/all/ 的峰值内存统计。

.. 注意::
更多关于 GPU 内存管理的详细信息，请参阅 :ref:`cuda-memory-management`。
管理层。
"""
warnings.warn(
"torch.cuda.reset_max_memory_allocated 现在调用 torch.cuda.reset_peak_memory_stats, "
"重置所有峰值内存统计信息。"
FutureWarning
    )
返回重置峰值内存统计信息(device=device)</font></font></font></div>


<div class="viewcode-block" id="reset_max_memory_cached"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def reset_max_memory_cached(device: Union[Device, int] = None) -&gt; None:
r"""重置跟踪给定设备缓存分配器管理的最大 GPU 内存的起始点。

详细信息请参阅 :func:`~torch.cuda.max_memory_cached`。

参数:
设备（torch.device 或 int，可选）：选定的设备。返回
当前设备的统计信息，由:func:`~torch.cuda.current_device`给出，
如果:attr:`device`为`None`（默认）。

.. warning::
现在这个函数现在调用 :func:`~torch.cuda.reset_peak_memory_stats`，用于重置
/all/ 的峰值内存统计。

.. 注意::
更多关于 GPU 内存管理的详细信息，请参阅 :ref:`cuda-memory-management`。
管理层。
"""
warnings.warn(
"torch.cuda.reset_max_memory_cached 现在调用 torch.cuda.reset_peak_memory_stats, "
"重置所有峰值内存统计信息。"
FutureWarning
    )
返回重置峰值内存统计信息(device=device)</font></font></font></div>


<div class="viewcode-block" id="memory_allocated"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[docs]def memory_allocated(device: Union[Device, int] = None) -&gt; int:
返回给定设备上张量占用的当前 GPU 内存字节数。

参数:
device (torch.device 或 int，可选)：选定的设备。返回
当前设备的统计信息，由 :func:`~torch.cuda.current_device` 提供，
如果 :attr:`device` 为 ``None``（默认）。

.. 注意::
这可能小于 `nvidia-smi` 显示的数值，因为一些
空闲内存可以被缓存分配器保留，并且需要创建在 GPU 上。有关 GPU 内存管理的详细信息，请参阅：:ref:`cuda-memory-management`。
需要创建在 GPU 上。有关 GPU 内存管理的详细信息，请参阅：:ref:`cuda-memory-management`。
GPU 内存管理的详细信息。
"""
return memory_stats(device=device).get("allocated_bytes.all.current", 0)</font></font></font></div>


<div class="viewcode-block" id="max_memory_allocated"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def max_memory_allocated(device: Union[Device, int] = None) -&gt; int:
返回给定设备中张量占用的最大 GPU 内存量（以字节为单位）。

默认情况下，这返回自开始以来的峰值分配内存。
该程序可以使用：func:`~torch.cuda.reset_peak_memory_stats` 来重置
追踪此指标的开始点。例如，这两个函数可以测量训练循环中每个迭代的峰值分配内存使用量。
这些函数可以测量训练循环中每个迭代的峰值分配内存使用量。
在训练循环中。

Args:
设备（torch.device 或 int，可选）：选定的设备。返回
当前设备的统计信息，由 :func:`~torch.cuda.current_device` 提供，
如果 :attr:`device` 为 ``None``（默认）。

.. 注意::
更多关于 GPU 内存管理的详细信息，请参阅 :ref:`cuda-memory-management`。
内存管理。
"""
return memory_stats(device=device).get("allocated_bytes.all.peak", 0)</font></font></font></div>


<div class="viewcode-block" id="memory_reserved"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def memory_reserved(device: Union[Device, int] = None) -&gt; int:
返回当前设备缓存分配器管理的 GPU 内存字节数。

Args:
设备（torch.device 或 int，可选）：选定的设备。返回
当前设备的统计信息，由:func:`~torch.cuda.current_device`给出，
如果:attr:`device`为`None`（默认）。

.. note::
查看 :ref:`cuda-memory-management` 了解更多关于 GPU 内存管理的详细信息
管理。
"""
返回 memory_stats(device=device).get("reserved_bytes.all.current", 0)</font></font></font></div>


<div class="viewcode-block" id="max_memory_reserved"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def max_memory_reserved(device: Union[Device, int] = None) -&gt; int:
r"""返回给定设备由缓存分配器管理的最大 GPU 内存（以字节为单位）。

默认情况下，这返回程序开始以来的峰值缓存内存。
可以使用 :func:`~torch.cuda.reset_peak_memory_stats` 来重置
跟踪此指标的开始点。例如，这两个函数
可以测量训练循环中每次迭代的峰值缓存内存量。
循环。

参数：
设备（torch.device 或 int，可选）：选定的设备。返回
当前设备的统计信息，由:func:`~torch.cuda.current_device`给出，
如果:attr:`device`为`None`（默认）。

.. note::
查看 :ref:`cuda-memory-management` 了解更多关于 GPU 内存管理的详细信息
管理。
"""
返回 memory_stats(device=device).get("reserved_bytes.all.peak", 0)</font></font></font></div>


<div class="viewcode-block" id="memory_cached"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]@已弃用(
`torch.cuda.memory_cached` 已更名为 `torch.cuda.memory_reserved`
category=未来警告，
)
def memory_cached(device: Union[Device, int] = None) -&gt; int:
已弃用；请参阅 :func:`~torch.cuda.memory_reserved`。
return memory_reserved(device=device)</font></font></font></div>


<div class="viewcode-block" id="max_memory_cached"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]@deprecated(
"torch.cuda.max_memory_cached 已更名为 torch.cuda.max_memory_reserved"
category=FutureWarning
)
def max_memory_cached(device: Union[Device, int] = None) -&gt; int:
已弃用；请参阅 :func:`~torch.cuda.max_memory_reserved`。
返回指定设备的最大内存保留量</font></font></font></div>


<div class="viewcode-block" id="memory_snapshot"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def memory_snapshot():
返回所有设备上 CUDA 内存分配器状态的快照。

解释此函数的输出需要熟悉内存分配器内部机制
更多关于 GPU 内存管理的详细信息，请参阅 :ref:`cuda-memory-management`

.. 注意::
请参阅 :ref:`cuda-memory-management` 了解更多详情
管理学。
"""
返回 `torch._C._cuda_memorySnapshot()` 的 `"segments"`。</font></font></font></div>


<div class="viewcode-block" id="memory_summary"><a class="viewcode-back" href="../../../generated/torch.cuda.memory_summary.html#torch.cuda.memory_summary">[文档]</font></font></font></a><span class="k">def</span> <span class="nf"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">内存摘要</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">联合</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩略语</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔值</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">返回给定设备的当前内存分配器统计信息的可读打印输出。</span>

<span class="sd">这可以在训练期间定期显示，或者在处理内存不足异常时。</span>
<span class="sd">处理内存不足异常。</span>

<span class="sd">参数：</span>
<span class="sd">设备（torch.device 或 int，可选）：选定的设备。返回当前设备打印信息，由 :func:`~torch.cuda.current_device` 提供，</span>
<span class="sd">当前设备打印信息，由 :func:`~torch.cuda.current_device` 提供，</span>
<span class="sd">如果 :attr:`device` 为 ``None``（默认）。</span>
<span class="sd">简略（bool，可选）：是否返回简略摘要</span>
<span class="sd">（默认：False）。</span>

<span class="sd">.. 注意::</span>
<span class="sd">查看 :ref:`cuda-memory-management` 以获取更多关于 GPU 内存管理的详细信息。</span>
<span class="sd">内存管理。</span>
<span class="sd">"沉浸式翻译"</span>
    <span class="n">设备</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取设备索引</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选的</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</span><span class="p">)</span>
    <span class="n">统计</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">内存统计</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">格式大小</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀_sz</span><span class="p">):</span>
        <span class="n">前缀</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"B  "</span><span class="p">,</span> <span class="s2">"KiB"</span><span class="p">,</span> <span class="s2">"MiB"</span><span class="p">,</span> <span class="s2">"GiB"</span><span class="p">,</span> <span class="s2">"TiB"</span><span class="p">,</span> <span class="s2">"PiB"</span><span class="p">]</span>
        <span class="n">前缀</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">新前缀</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span><span class="p">[</span><span class="mi">1</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]</span>
            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀缩写</span> <span class="o">&lt;</span> <span class="mi">768</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">:</span>
                <span class="k">断开</span>
            <span class="n">前缀</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">新前缀</span>
            <span class="n">sz</span> <span class="o">//=</span> <span class="mi">1024</span>
            <span class="n">前缀缩写</span> <span class="o">/=</span> <span class="mi">1024</span>
        <span class="k">返回</font></font></font></span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">大小</font></font></font></span><span class="si">:</span><span class="s2">6d</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</span><span class="si">}</span><span class="s2">"</span>

    <span class="k">def</span> <span class="nf">格式计数</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">计数</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">偏好计数</span><span class="p">):</span>
        <span class="n">前缀</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本为空，请提供需要翻译的文本</span><span class="p">,</span> <span class="s2">"K"</span><span class="p">,</span> <span class="s2">"M"</span><span class="p">]</span>
        <span class="n">前缀</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">新前缀</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span><span class="p">[</span><span class="mi">1</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]</span>
            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">偏计数</span> <span class="o">&lt;</span> <span class="mi">750</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">:</span>
                <span class="k">断开</span>
            <span class="n">前缀</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">新前缀</span>
            <span class="n">计数</span> <span class="o">//=</span> <span class="mi">1000</span>
            <span class="n">偏计数</span> <span class="o">/=</span> <span class="mi">1000</span>
        <span class="k">返回</font></font></font></span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">计数</font></font></font></span><span class="si">:</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">7 天</font></font></font></span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</span><span class="si">}</span><span class="s2"> "</span>

    <span class="n">显示的指标</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">分配的字节</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分配的内存</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式大小</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"活跃字节数"</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"活动内存"</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式大小</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"请求字节数"</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"请求的内存"</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式大小</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"预留字节数"</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"GPU 预留内存"</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式大小</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">无效分割字节数</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">不可发布内存</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式大小</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">分配</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分配项</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式计数</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">活动</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"活跃分配"</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式计数</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"段"</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"GPU 预留段"</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式计数</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"无效分割"</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"不可发布分配"</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式计数</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="n">行</font></font></font></span> <span class="o">=</span> <span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本为空，请提供需要翻译的文本</span>
    <span class="n">行</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">75</span><span class="p">)</span>
    <span class="n">行</font></font></font></span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">" </span><span class="si">{_:16}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">PyTorch CUDA 内存摘要，设备 ID</font></font></font></span><span class="si"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">{设备:&lt;17d&gt;}</span><span class="s2"> "</span><span class="p">)</span>
    <span class="n">行</font></font></font></span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"—"</span> <span class="o">*</span> <span class="mi">75</span><span class="p">)</span>
    <span class="n">行</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="s2">"  </span><span class="si">{_:9}</span><span class="s2">CUDA OOMs：</font></font></font></span><span class="si"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">{num_ooms:&lt;12d&gt;}</font></font></font></span><span class="s2"> | </span><span class="si">{_:6}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">cudaMalloc 重试：</span><span class="si">{num_alloc_retries:&lt;8d}</span><span class="s2">  "</span>
    <span class="p">)</span>
    <span class="n">行</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">75</span><span class="p">)</span>
    <span class="n">行</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="s2">"        指标         | 当前使用  | 峰值使用 | 总分配  | 总释放  "</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">metric_key</span><span class="p">,</span> <span class="n">指标名称</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式化器</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">要显示的指标</span><span class="p">:</span>
        <span class="n">行</font></font></font></span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"—"</span> <span class="o">*</span> <span class="mi">75</span><span class="p">)</span>
        <span class="n">子指标</font></font></font></span> <span class="o">=</span> <span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">[</font></font></font></span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">所有</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">指标名称</span><span class="p">)]</span>
        <span class="k">如果</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">不是</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩略语</span><span class="p">:</span>
            <span class="n">子指标</font></font></font></span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"大池"</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"      来自大池"</span><span class="p">))</span>
            <span class="n">子指标</font></font></font></span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">小池</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">来自小池</span><span class="p">))</span>

        <span class="n">当前偏值</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">顶点优先值</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分配优先值</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">释放优先值</span> <span class="o">=</span> <span class="p">(</span>
            <span class="kc">无</span><span class="p">,</span>
            <span class="kc">无</span><span class="p">,</span>
            <span class="kc">无</span><span class="p">,</span>
            <span class="kc">无</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">子度量键</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">子度量名称</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">子指标</span><span class="p">:</span>
            <span class="n">前缀</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">指标键</font></font></font></span> <span class="o">+</span> <span class="s2">"."</span> <span class="o">+</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">子度量键</span> <span class="o">+</span> <span class="s2">"."</span>

            <span class="n">当前</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">统计</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span> <span class="o">+</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"当前"</span><span class="p">]</span>
            <span class="n">峰值</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">统计</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span> <span class="o">+</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"峰值"</span><span class="p">]</span>
            <span class="n">分配的</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">统计</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span> <span class="o">+</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"分配的"</span><span class="p">]</span>
            <span class="n">释放的</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">统计</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span> <span class="o">+</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"释放的"</span><span class="p">]</span>

            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">当前偏值</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
                <span class="n">当前偏值</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">当前</span>
                <span class="n">顶峰优先值</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">峰值</span>
                <span class="n">分配优先值</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分配的</span>
                <span class="n">释放优先值</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">释放的</span>

            <span class="n">行</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">子度量名称</font></font></font></span><span class="si">:</span><span class="s2">&lt;21</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式化器</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">当前</font></font></font></span><span class="p">,</span><span class="w"> </span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">当前偏值</font></font></font></span><span class="p">)</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式化器</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">山峰</font></font></font></span><span class="p">,</span><span class="w"> </span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">顶点优先值</span><span class="p">)</span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">|
    （此处文本为空，无需翻译）</font></font></font></span>
                <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">格式化器</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分配</font></font></font></span><span class="p">,</span><span class="w"> </span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分配优先值</font></font></font></span><span class="p">)</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式化器</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">释放</font></font></font></span><span class="p">,</span><span class="w"> </span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">自由偏好值</span><span class="p">)</span><span class="si">}</span><span class="s2"> "</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="n">显示的指标</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">超大分配</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">超大分配</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式计数</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">超大段</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">超大 GPU 段</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式计数</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="k">for</span> <span class="n">metric_key</span><span class="p">,</span> <span class="n">指标名称</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式化器</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">要显示的指标</span><span class="p">:</span>
        <span class="n">行</font></font></font></span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"—"</span> <span class="o">*</span> <span class="mi">75</span><span class="p">)</span>

        <span class="n">前缀</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">指标键</span> <span class="o">+</span> <span class="s2">"."</span>

        <span class="n">当前</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">统计</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span> <span class="o">+</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"当前"</span><span class="p">]</span>
        <span class="n">峰值</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">统计</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span> <span class="o">+</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"峰值"</span><span class="p">]</span>
        <span class="n">分配的</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">统计</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span> <span class="o">+</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"分配的"</span><span class="p">]</span>
        <span class="n">释放的</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">统计</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前缀</font></font></font></span> <span class="o">+</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"释放的"</span><span class="p">]</span>

        <span class="n">行</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">指标名称</font></font></font></span><span class="si">:</span><span class="s2">&lt;21</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式化器</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">当前</font></font></font></span><span class="p">,</span><span class="w"> </span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">当前</font></font></font></span><span class="p">)</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式化器</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">山峰</font></font></font></span><span class="p">,</span><span class="w"> </span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">山峰</span><span class="p">)</span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">|
    （此处文本为空，无需翻译）</font></font></font></span>
            <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">格式化器</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分配</font></font></font></span><span class="p">,</span><span class="w"> </span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分配</font></font></font></span><span class="p">)</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式化器</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">释放</font></font></font></span><span class="p">,</span><span class="w"> </span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">释放</span><span class="p">)</span><span class="si">}</span><span class="s2"> "</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">行</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">75</span><span class="p">)</span>

    <span class="n">fmt_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">“_”</font></font></font></span><span class="p">:</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本翻译为简体中文为：""</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"设备"</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">}</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">统计</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">项目</span><span class="p">():</span>
        <span class="n">fmt_dict</span><span class="p">[</span><span class="n">k</span><span class="o">.</span><span class="n">替换</font></font></font></span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">“。”</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">破折号</span><span class="p">)]</span> <span class="o">=</span> <span class="n">v</span>
    <span class="k">返回</font></font></font></span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">竖线</font></font></font></span> <span class="o">+</span> <span class="s2">"|</span><span class="se"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本翻译为简体中文为：\n</font></font></font></span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"|</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">连接</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">行</font></font></font></span><span class="p">)</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式</font></font></font></span><span class="p">(</span><span class="o">**</span><span class="n">fmt_dict</span><span class="p">)</span> <span class="o">+</span> <span class="s2">"|</span><span class="se"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本翻译为简体中文为：\n</span><span class="s2">"</span></div>


<div class="viewcode-block" id="list_gpu_processes"><a class="viewcode-back" href="../../../generated/torch.cuda.list_gpu_processes.html#torch.cuda.list_gpu_processes">[文档]</font></font></font></a><span class="k">def</span> <span class="nf">list_gpu_processes</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">联合</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">返回给定设备上运行进程及其 GPU 内存使用的可读打印输出。</span>

<span class="sd">这可以在训练期间定期显示，或者在处理内存不足异常时。</span>
<span class="sd">处理内存不足异常。</span>

<span class="sd">参数：</span>
<span class="sd">设备（torch.device 或 int，可选）：选定的设备。返回当前设备打印信息，由 :func:`~torch.cuda.current_device` 提供，</span>
<span class="sd">当前设备打印信息，由 :func:`~torch.cuda.current_device` 提供，</span>
<span class="sd">如果 :attr:`device` 为 ``None``（默认）。</span>
<span class="sd">"沉浸式翻译"</span>
    <span class="k">如果</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">不是</font></font></font></span> <span class="n">torch</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">版本</span><span class="o">.</span><span class="n">hip</span><span class="p">:</span>
        <span class="k">尝试</span><span class="p">:</span>
            <span class="kn">导入</span> <span class="nn">pynvml</span>  <span class="c1"># type: ignore[import]</span>
        <span class="k">除了</font></font></font></span> <span class="ne"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块未找到错误</span><span class="p">:</span>
            <span class="k">返回</font></font></font></span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"未找到 pynvml 模块，请安装 pynvml"</span>
        <span class="kn">来自</font></font></font></span> <span class="nn">pynvml</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="n">NVMLError_DriverNotLoaded</span>

        <span class="k">尝试</span><span class="p">:</span>
            <span class="n">pynvml</span><span class="o">.</span><span class="n">nvmlInit</span><span class="p">()</span>
        <span class="k">除了</span> <span class="n">NVMLError_DriverNotLoaded</span><span class="p">:</span>
            <span class="k">返回</font></font></font></span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"无法加载 cuda 驱动程序，cuda 是否已启用？"</span>

        <span class="n">设备</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取 nvml 设备索引</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">)</span>
        <span class="n">handle</span> <span class="o">=</span> <span class="n">pynvml</span><span class="o">.</span><span class="n">通过索引获取 nvml 设备句柄</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">)</span>
        <span class="n">进程</font></font></font></span> <span class="o">=</span> <span class="n">pynvml</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取 nvml 设备正在运行的进程</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">处理</span><span class="p">)</span>
    <span class="k">否则</span><span class="p">:</span>
        <span class="k">尝试</span><span class="p">:</span>
            <span class="kn">导入</span> <span class="nn">amdsmi</span>  <span class="c1"># type: ignore[import]</span>
        <span class="k">除了</font></font></font></span> <span class="ne"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块未找到错误</span><span class="p">:</span>
            <span class="k">返回</font></font></font></span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"未找到 amdsmi 模块，请安装 amdsmi"</span>
        <span class="k">尝试</span><span class="p">:</span>
            <span class="n">amdsmi</span><span class="o">.</span><span class="n">amdsmi 初始化</font></font></font></span><span class="p">()</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 类型：忽略[已定义]</span>
        <span class="k">除了</font></font></font></span> <span class="n">amdsmi</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">AmdSmiException 异常</font></font></font></span><span class="p">:</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 类型：忽略[已定义]</span>
            <span class="k">返回</font></font></font></span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"无法加载 amdsmi 驱动，是否已安装 ROCm？"</span>

        <span class="n">设备</font></font></font></span> <span class="o">=</span> <span class="n">_get_amdsmi_device_index</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">)</span>

        <span class="k">尝试</span><span class="p">:</span>
            <span class="n">handle</span> <span class="o">=</span> <span class="n">amdsmi</span><span class="o">.</span><span class="n">amdsmi_get_processor_handles</span><span class="p">()[</span><span class="n">设备</font></font></font></span><span class="p">]</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 类型：忽略[已定义]</span>
            <span class="n">进程</font></font></font></span> <span class="o">=</span> <span class="n">amdsmi</span><span class="o">.</span><span class="n">amdsmi_get_gpu_process_list</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">处理</font></font></font></span><span class="p">)</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 类型：忽略[已定义]</span>
        <span class="k">除了</font></font></font></span> <span class="n">amdsmi</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">AmdSmiException 异常</font></font></font></span><span class="p">:</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 类型：忽略[已定义]</span>
            <span class="k">返回</font></font></font></span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"amdsmi 无法列出其他用户的进程"</span>

    <span class="n">行</font></font></font></span> <span class="o">=</span> <span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本为空，请提供需要翻译的文本</span>
    <span class="n">行</font></font></font></span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"GPU: "</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">行</font></font></font></span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">没有进程正在运行</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程</span><span class="p">:</span>
        <span class="k">如果</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">不是</font></font></font></span> <span class="n">torch</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">版本</span><span class="o">.</span><span class="n">hip</span><span class="p">:</span>
            <span class="n">内存</font></font></font></span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">使用的 GPU 内存</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">)</span>
            <span class="n">进程 ID</font></font></font></span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程 ID</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="k">尝试</span><span class="p">:</span>
                <span class="n">proc_info</span> <span class="o">=</span> <span class="n">amdsmi</span><span class="o">.</span><span class="n">amdsmi_get_gpu_process_info</span><span class="p">(</span><span class="n">处理</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>  <span class="c1"># type: ignore[possibly-undefined]</span>
            <span class="k">除了</font></font></font></span> <span class="ne"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">属性错误</span><span class="p">:</span>
                <span class="c1"># https://github.com/ROCm/amdsmi/commit/c551c3caedbd903ba828e7fdffa5b56d475a15e7</span>
                <span class="c1"># 是一个向后不兼容的更改，从 amdsmi 中移除了 amdsmi_get_gpu_process_info API</span>
                <span class="n">proc_info</span> <span class="o">=</span> <span class="n">p</span>
            <span class="n">内存</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程信息</font></font></font></span><span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">内存使用情况</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]
[</font></font></font></span><span class="s2">显存内存</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">)</span>
            <span class="n">进程 ID</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程信息</font></font></font></span><span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"进程 ID"</span><span class="p">]</span>
        <span class="n">行</font></font></font></span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"进程"</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程 ID</font></font></font></span><span class="si">:</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">&gt;10 天</font></font></font></span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">使用</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">内存</font></font></font></span><span class="si">:</span><span class="s2">&gt;12.3f</span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">MB GPU 内存</span><span class="p">)</span>
    <span class="k">返回</font></font></font></span> <span class="s2">"</span><span class="se"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本翻译为简体中文为：\n</font></font></font></span><span class="s2">"</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">连接</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">行</span><span class="p">)</span></div>


<div class="viewcode-block" id="mem_get_info"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def mem_get_info(device: Union[Device, int] = None) -&gt; tuple[int, int]:
r"""返回指定设备使用 cudaMemGetInfo 获取的全局空闲和总 GPU 内存。

Args:
device (torch.device 或 int 或 str, 可选): 选择设备。返回
当前设备的统计信息，由 :func:`~torch.cuda.current_device` 提供，
如果 :attr:`device` 为 ``None``（默认）或未指定设备索引。

.. note::
更多信息请参阅 :ref:`cuda-memory-management`。
硬件内存管理的详细信息。
"""
如果设备为 None：
设备 = torch.cuda.current_device()
# optional=True 允许使用 `device = torch.device('cuda')`，但此时 device.index 为 None
device = _get_device_index(device, optional=True)
返回 torch.cuda.cudart().cudaMemGetInfo(device)</font></font></font></div>


<span class="k">def</span> <span class="nf">_record_memory_history_legacy</span><span class="p">(</span>
    <span class="n">启用</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">记录上下文</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</span><span class="p">,</span>
    <span class="n">跟踪分配最大条目数</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">跟踪分配记录上下文</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">,</span>
    <span class="n">设备</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">联合</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
    <span class="n">record_context_cpp</span><span class="o">=</span><span class="kc">错误</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">_C</span><span class="o">.</span><span class="n">_cuda_record_memory_history_legacy</span><span class="p">(</span>
        <span class="n">启用</span><span class="p">,</span>
        <span class="n">记录上下文</span><span class="p">,</span>
        <span class="n">跟踪分配最大条目数</span><span class="p">,</span>
        <span class="n">跟踪分配记录上下文</span><span class="p">,</span>
        <span class="n">记录上下文_cpp</span><span class="p">,</span>
    <span class="p">)</span>


<div class="viewcode-block" id="_record_memory_history"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def _record_memory_history(
enabled: Literal[None, "state", "all"] = "all", *args, **kwargs
) -&gt; None:
启用与内存相关的堆栈跟踪记录
分配，因此您可以知道任何内存块是由谁分配的
:func:`torch.cuda.memory._snapshot()`.

此外，还保留每个当前分配和释放的堆栈跟踪
这也将启用记录所有分配/释放事件的记录。

使用 :func:`torch.cuda.memory._snapshot()` 来检索此信息，
以及 `_memory_viz.py` 中的工具来可视化快照。

Python 跟踪收集速度快（每个跟踪 2us），因此您可以考虑
在生产任务中启用此功能，如果您预计将来需要调试
内存问题。

C++ 跟踪收集也非常快（约 50 纳秒/帧），对于许多典型程序来说
每个跟踪大约为 2 微秒，但可能会根据堆栈深度而变化。

Args:
enabled (Literal[None, "state", "all"], optional):
`None`，禁用记录内存历史。
`"state"`，保留当前分配内存的信息。
`"all"`，另外还要记录所有分配/释放调用历史。
默认为 "all"。
context (Literal[None, "state", "alloc", "all"], 可选):
`None`，不记录任何跟踪信息。
`"状态"`，记录当前分配内存的回溯信息。
`"alloc"`，此外还保留 alloc 调用的回溯信息。
`"all"`，此外还保留 free 调用的回溯信息。
默认为 `"all"`。
stacks (Literal["python", "all"], 可选):
`"python"`，包括 Python、TorchScript 和 inductor 调试信息中的帧
`"all"`，此外还包括 C++ 帧信息
默认为 "all"。
最大条目数（int，可选）：保留最多 `max_entries`
记录历史中记录的分配/释放事件。
"""
如果 enabled 是布尔类型：
return _record_memory_history_legacy(enabled, *args, **kwargs)
else:
return _record_memory_history_impl(enabled, *args, **kwargs)</font></font></font></div>


<span class="k">def</span> <span class="nf">_记录内存历史实现</span><span class="p">(</span>
    <span class="n">启用</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">所有</span><span class="p">,</span>
    <span class="n">上下文</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">所有</span><span class="p">,</span>
    <span class="n">栈</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">所有</span><span class="p">,</span>
    <span class="n">最大条目数</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">整型</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">系统模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">最大尺寸</span><span class="p">,</span>
    <span class="n">设备</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">联合</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">_C</span><span class="o">.</span><span class="n">_cuda 记录内存历史</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">启用</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">上下文</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">栈</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">最大条目数</span><span class="p">)</span>


<span class="n">_记录内存历史</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">__签名__</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">签名</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_记录内存历史实现</font></font></font></span><span class="p">)</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 类型：忽略[已定义]</span>


<div class="viewcode-block" id="_snapshot"><a class="viewcode-back" href="../../../torch_cuda_memory.html#torch.cuda._snapshot">[文档]</font></font></font></a><span class="k">def</span> <span class="nf"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">快照</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">联合</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">):</span>
<span class="w">    </span><span class="sd">在调用时保存 CUDA 内存状态的快照。</span>

<span class="sd">状态以字典的形式表示，其结构如下。</span>

<span class="sd">.. 代码块 :: python</span>

<span class="sd">        class Snapshot(TypedDict):</span>
<span class="sd">            segments : List[Segment]</span>
<span class="sd">            device_traces: List[List[TraceEntry]]</span>

<span class="sd">        class Segment(TypedDict):</span>
<span class="sd"># Segments 是来自 cudaMalloc 调用的内存。</span>
<span class="sd"># 预留内存的大小是所有 Segments 的总和。</span>
<span class="sd"># Segments 被缓存并重复用于未来的分配。</span>
<span class="sd">如果重用小于段，则段将被拆分为多个块。</span>
<span class="sd">如果是空的，则将段拆分为多个块。</span>
<span class="sd">empty_cache() 释放完全不活跃的段。</span>
<span class="sd">address: 整数</span>
<span class="sd">total_size: 整数 # 分段 cudaMalloc 的尺寸</span>
<span class="sd">stream: 整数</span>
<span class="sd">segment_type: 文字常量['small', 'large'] # 'large' (&gt;1MB)</span>
<span class="sd">allocated_size: 整数 # 使用中的内存大小</span>
<span class="sd">active_size: 整数 # 使用中或处于 active_awaiting_free 状态的内存大小</span>
<span class="sd">            blocks : List[Block]</span>

<span class="sd">        class Block(TypedDict):</span>
<span class="sd"># 从分配器返回的内存块，或</span>
<span class="sd">当前缓存但未激活。</span>
<span class="sd">            size: int</span>
<span class="sd">请求大小：整数 # malloc 期间请求的大小，可能小于</span>
<span class="sd"># 由于四舍五入导致的大小</span>
<span class="sd">address: 整数</span>
<span class="sd">state: Literal['active_allocated', # 用于张量</span>
<span class="sd">'active_awaiting_free', # 等待另一个流完成使用</span>
<span class="sd"># 然后，它将变为空闲</span>
<span class="sd">'无效的，] # 可供重用'</span>
<span class="sd">'frames: List[Frame] # 从发生分配的堆栈跟踪'</span>

<span class="sd">'class Frame(TypedDict):'</span>
<span class="sd">'filename: str'</span>
<span class="sd">行：整型</span>
<span class="sd">名称：字符串</span>

<span class="sd">类 TraceEntry(TypedDict):</span>
<span class="sd">当 `torch.cuda.memory._record_memory_history()` 被启用时，</span>
<span class="sd">记录每个快照将包含 TraceEntry 对象</span>
<span class="sd">分配器所采取的操作。</span>
<span class="sd">操作: Literal[</span>
<span class="sd">'alloc' 内存分配</span>
<span class="sd">'free_requested' # 请求释放内存</span>
<span class="sd">'free_completed' # 请求释放的内存已</span>
<span class="sd">'' # 可用于未来的分配调用</span>
<span class="sd">'segment_alloc' # 缓存分配器请求 cudaMalloc 更多内存</span>
<span class="sd"># 添加到其缓存中作为一个段</span>
<span class="sd">'segment_free' # 缓存分配器调用 cudaFree 来归还内存</span>
<span class="sd"># 为了 cuda 可能尝试释放内存以</span>
<span class="sd"># 分配更多段或因为调用了 empty_caches</span>
<span class="sd">内存不足，分配器抛出了 OOM 异常。'size'是</span>
<span class="sd">请求的字节数未成功</span>
<span class="sd">快照 # 分配器生成了一个内存快照</span>
<span class="sd">有助于关联之前拍摄的</span>
<span class="sd"># 拍照包含此跟踪</span>
<span class="sd">            ]</span>
<span class="sd">addr: int # 不适用于内存溢出</span>
<span class="sd">            frames: List[Frame]</span>
<span class="sd">            size: int</span>
<span class="sd">stream: 整数</span>
<span class="sd">device_free: 整数 # 仅在 OOM 时存在，表示内存</span>
<span class="sd"># cuda 仍然报告为空闲的内存</span>

<span class="sd">返回：</span>
<span class="sd">快照字典对象</span>
<span class="sd">"沉浸式翻译"</span>
    <span class="k">返回</span> <span class="n">_C</span><span class="o">.</span><span class="n">_cuda_memorySnapshot</span><span class="p">()</span></div>


<div class="viewcode-block" id="_dump_snapshot"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def _dump_snapshot(filename="dump_snapshot.pickle"):
"""
将 `torch.memory._snapshot()` 字典的序列化版本保存到文件中。

该文件可以通过 pytorch.org/memory_viz 上的交互式快照查看器打开

Args:
文件名（str，可选）：要创建的文件名。默认为"dump_snapshot.pickle"。
"""
s = _snapshot()
with open(filename, "wb") as f:
pickle.dump(s, f)</font></font></font></div>


<span class="k">def</span> <span class="nf">_save_segment_usage</span><span class="p">(</span><span class="n">文件名</font></font></font></span><span class="o">=</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">output.svg</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">快照</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">):</span>
    <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">快照</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
        <span class="n">快照</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">快照</span><span class="p">()</span>
    <span class="k">与</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">打开</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">文件名</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">w</font></font></font></span><span class="p">)</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">写</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">段落</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">快照</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">保存内存使用情况</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">文件名</font></font></font></span><span class="o">=</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">output.svg</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">快照</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">):</span>
    <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">快照</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
        <span class="n">快照</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">快照</span><span class="p">()</span>
    <span class="k">与</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">打开</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">文件名</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">w</font></font></font></span><span class="p">)</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">写</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">内存</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">快照</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">设置分配器设置</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">环境</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">返回</font></font></font></span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_cuda_cudaCachingAllocator_set_allocator_settings</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">环境</span><span class="p">)</span>


<div class="viewcode-block" id="get_allocator_backend"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def get_allocator_backend() -&gt; str:
返回一个描述由设置的活动分配器后端的字符串
``PYTORCH_CUDA_ALLOC_CONF``. 目前可用的后端有
``native``（PyTorch 的本地缓存分配器）和 `cudaMallocAsync`
（CUDA 的内置异步分配器）。

.. 注意::
请参阅 :ref:`cuda-memory-management` 了解选择分配器后端的详细信息。
"""
返回 torch._C._cuda_getAllocatorBackend()</font></font></font></div>


<span class="k">类</span> <span class="nc">_CUDAAllocator</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">内部 CUDA 内存分配器的包装器。</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">分配器</font></font></font></span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_cuda_CUDA 分配器</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_分配器</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分配器</span>

    <span class="k">def</span> <span class="nf">分配器</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">返回</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_分配器</span>


<div class="viewcode-block" id="CUDAPluggableAllocator"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]类 CUDAPluggableAllocator(_CUDAAllocator):
r"""从.so 文件加载的 CUDA 内存分配器。"""

r"""def __init__(self, path_to_so_file: str, alloc_fn_name: str, free_fn_name: str):"""
r"""内存分配器编译在.so 文件中，并使用 ctypes 动态加载。"""

使用 :func:`torch.memory.cuda.change_current_allocator` 函数更改活动分配器。

Args:
path_to_so_file(str): 文件系统中的路径，指向包含分配器函数的 `.so` 文件
的分配器函数
alloc_fn_name(str): 执行内存分配的函数名称
在 so 文件中。签名必须是：
void* alloc_fn_name(ssize_t size, int device, cudaStream_t stream);
free_fn_name(str): 执行内存释放的函数名称
在 so 文件中。签名必须是：
void free_fn_name(void* ptr, size_t size, cudaStream_t stream);

..警告::
目前仅支持在 Unix 操作系统上

.. 注意::
有关创建和使用自定义分配器的详细信息，请参阅 :ref:`cuda-memory-management`
"""
allocator = ctypes.CDLL(path_to_so_file)
alloc_fn = ctypes.cast(getattr(allocator, alloc_fn_name), ctypes.c_void_p).value
free_fn = ctypes.cast(getattr(allocator, free_fn_name), ctypes.c_void_p).value
assert alloc_fn is not None
assert free_fn is not None
self._allocator = torch._C._cuda_customAllocator(alloc_fn, free_fn)</font></font></font></div>


<div class="viewcode-block" id="change_current_allocator"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]def change_current_allocator(allocator: _CUDAAllocator) -&gt; None:
将当前使用的内存分配器更改为提供的分配器。

如果当前分配器已经被使用/初始化，此函数将报错。


Args:
分配器（torch.cuda.memory._CUDAAllocator）：要设置为活动状态的分配器。
.. 注意::
有关创建和使用自定义分配器的详细信息，请参阅 :ref:`cuda-memory-management`。
"""
torch._C._cuda_changeCurrentAllocator(allocator.allocator())</font></font></font></div>


<span class="k">def</span> <span class="nf">获取当前分配器</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">_CUDAAllocator</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">返回当前正在使用的分配器。</span>

<span class="sd">.. 注意::</span>
<span class="sd">请参阅：ref：`cuda-memory-management`以获取有关创建和使用自定义分配器的详细信息</span>
<span class="sd">"沉浸式翻译"</span>
    <span class="k">返回</span> <span class="n">_CUDAAllocator</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_cuda_getAllocator</span><span class="p">())</span>


<div class="viewcode-block" id="MemPoolContext"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]类 MemPoolContext(_MemPoolContext):
r"""MemPoolContext 存储当前活动池并保存之前的
池。删除时将使上一个池变为活动状态。

Args:
pool(torch.cuda.MemPool)：要激活的 MemPool 对象，以便
分配路由到此池。

"""

def __init__(self, 池: _MemPool):
调用父类构造函数(pool)

</font></font></font><div class="viewcode-block" id="MemPoolContext.active_pool"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]    @staticmethod
def active_pool() -&gt; Optional[_MemPool]:
r"""返回活动 MemPool"""
return _MemPoolContext.active_pool()</font></font></font></div></div>


<div class="viewcode-block" id="MemPool"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]class MemPool(_MemPool):
内存池代表缓存分配器中的内存池。当前，
这只是 CUDACachingAllocator 中维护的池对象 ID。

参数:
allocator(torch._C._cuda_CUDAAllocator, 可选): 一个
torch._C._cuda_CUDAAllocator 对象，可用于
定义如何在池中分配内存。如果：attr:`分配器`
是 `None`（默认），内存分配遵循默认/
当前 CUDACachingAllocator 的配置。

"""
"""

def __init__(self, allocator: Optional[_cuda_CUDAAllocator] = None):
super().__init__(allocator, True)

    @property
def id(self) -&gt; tuple[int, int]:
r"""返回此池的 ID，以两个整数的元组形式。"""
return super().id

    @property
def allocator(self) -&gt; Optional[_cuda_CUDAAllocator]:
r"""返回 MemPool 路由分配的分配器。"""
return super().allocator

</font></font></font><div class="viewcode-block" id="MemPool.use_count"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]    def use_count(self) -&gt; int:
返回此池的引用计数。
返回 super().use_count() 的值</font></font></font></div>

<div class="viewcode-block" id="MemPool.snapshot"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]    def 快照(self):
r"""返回所有设备上 CUDA 内存分配器池状态的快照。
理解此函数的输出需要熟悉相关内容。

Interpreting the output of this function requires familiarity with the
内存分配器内部机制。

.. 注意::
更多关于 GPU 内存管理的详细信息，请参阅 :ref:`cuda-memory-management`。
内存管理。
"""
尝试：
ctx = MemPoolContext(self)
snapshot = torch.cuda.memory_snapshot()
finally:
删除 ctx
返回快照</font></font></font></div></div>


<div class="viewcode-block" id="use_mem_pool"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]@contextlib.contextmanager
def use_mem_pool(pool: MemPool, device: Union[Device, int] = None):
"""一个上下文管理器，用于将分配路由到指定的池。

Args:
pool(torch.cuda.MemPool): 要激活的 MemPool 对象，以便
将分配路由到此池。
设备（torch.device 或 int，可选）：选定的设备。使用 MemPool 在当前设备上，由 :func:`~torch.cuda.current_device` 给出，
如果 :attr:`device` 是 ``None``（默认）。
如果 :attr:`device` 是 ``None``（默认）。

"""
ctx = MemPoolContext(pool)
device_index = (
torch.cuda.current_device() if device is None else _get_device_index(device)
    )
_cuda_beginAllocateToPool(device_index, pool.id)
try:
yield
finally:
_cuda_endAllocateCurrentStreamToPool(device_index, pool.id)
_cuda_releasePool(device_index, pool.id)
del ctx</font></font></font></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>© 版权所有 PyTorch 贡献者。</p>
  </div>
    
      <div>使用 Sphinx 构建，并使用 Read the Docs 提供的主题。</div>
     

</footer>

          </div>
<script>

var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/clipboard.min.js"></script>
         <script src="../../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script="" type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0">


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>文档</h2>
          <p>查看 PyTorch 的全面开发者文档</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">查看文档</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>教程</h2>
          <p>深入了解初学者和高级开发者的教程</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">查看教程</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>资源</h2>
          <p>查找开发资源，获取您的疑问解答</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">查看资源</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">开始使用</a></li>
            <li><a href="https://pytorch.org/features">功能</a></li>
            <li><a href="https://pytorch.org/ecosystem">生态系统</a></li>
            <li><a href="https://pytorch.org/blog/">博客</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">贡献</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">资源</a></li>
            <li><a href="https://pytorch.org/tutorials">教程</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">文档</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">讨论</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github 问题</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">品牌指南</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">保持更新</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">推特</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">领英</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch 播客</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">苹果</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">谷歌</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">亚马逊</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">条款</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">隐私</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© 版权所有 Linux 基金会。PyTorch 基金会是 Linux 基金会的一个项目。有关 PyTorch 基金会的网站使用条款、商标政策以及其他适用政策，请参阅 www.linuxfoundation.org/policies/。PyTorch 基金会支持 PyTorch 开源项目，该项目已被确立为 LF Projects, LLC 的 PyTorch 项目系列。有关适用于 PyTorch 项目系列 LF Projects, LLC 的政策，请参阅 www.lfprojects.org/policies/。</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">为了分析流量并优化您的体验，我们在本网站上使用 cookies。通过点击或导航，您同意允许我们使用 cookies。作为本网站的当前维护者，适用 Facebook 的 Cookies 政策。了解更多信息，包括关于可用控制的信息：Cookies 政策。</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg" width="16" height="16">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>学习</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">开始使用</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">教程</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">学习基础知识</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch 食谱</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">PyTorch 入门 - YouTube 系列</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>生态系统</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">工具</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">社区</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">论坛</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">开发者资源</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">贡献者奖项 - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">关于 PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch 文档</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>文档</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch 领域</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>博客 &amp; 新闻</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch 博客</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">社区博客</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">视频</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">社区故事</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">活动</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">通讯</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>关于</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch 基金会</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">管理委员会</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">云信用计划</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">技术咨询委员会</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">员工</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">联系我们</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>

</body></html>