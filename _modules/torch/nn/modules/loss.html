<!DOCTYPE html>
<html lang="zh_CN">
<head>
  <meta charset="UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.nn.modules.loss — PyTorch main documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html">
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css">
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/sphinx-dropdown.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/panels-bootstrap.min.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/css/jit.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css">
    <link rel="index" title="Index" href="../../../../genindex.html">
    <link rel="search" title="Search" href="../../../../search.html">

<!--
  Search engines should not index the main version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head><body class="pytorch-body"><div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">学习</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class="dropdown-title">开始使用</span>
                  <p>在本地运行 PyTorch 或快速开始使用支持的云平台之一</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">教程</span><p></p>
                  <p>PyTorch 教程中有什么新内容</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">学习基础知识</span><p></p>
                  <p>熟悉 PyTorch 的概念和模块</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch 食谱</span><p></p>
                  <p>小而全，即用即部署的 PyTorch 代码示例</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">PyTorch 入门 - YouTube 系列教程</span><p></p>
                  <p>通过我们引人入胜的 YouTube 教程系列掌握 PyTorch 基础知识</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">生态系统</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">工具</span><p></p>
                  <p>了解 PyTorch 生态系统中的工具和框架</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">社区</span>
                  <p>加入 PyTorch 开发者社区，贡献、学习并获得问题解答</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">论坛</span>
                  <p>讨论 PyTorch 代码、问题、安装、研究的地方</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">开发者资源</span>
                  <p>查找资源并获得问题解答</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">贡献者奖项 - 2024</span><p></p>
                  <p>本年 PyTorch 会议揭晓获奖者</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">边缘</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">关于 PyTorch Edge</span><p></p>
                  <p>为边缘设备构建创新且注重隐私的 AI 体验</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span><p></p>
                  <p>针对移动和边缘设备实现端到端推理能力的解决方案</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch 文档</span><p></p>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">文档</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span><p></p>
                  <p>查阅文档以获取全面指导，了解如何使用 PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch 领域</span><p></p>
                  <p>阅读 PyTorch 领域文档，了解更多关于特定领域库的信息</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">博客与新闻</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch 博客</span><p></p>
                  <p>跟上最新的技术新闻和动态</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">社区博客</span><p></p>
                  <p>PyTorch 生态系统中的故事</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">视频</span><p></p>
                  <p>了解最新的 PyTorch 教程、新内容等</p>
                </a><a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">社区故事</span><p></p>
                  <p>了解我们的社区如何使用 PyTorch 解决真实、日常的机器学习问题</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">活动</span><p></p>
                  <p>查找活动、网络研讨会和播客</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">通讯</span><p></p>
                  <p>跟踪最新更新</p>
                </a>
            </div>
          </div></li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">关于</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch 基金会</span><p></p>
                  <p>了解更多关于 PyTorch 基金会的信息</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">管理委员会</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">云信用计划</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">技术顾问委员会</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">员工</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">联系我们</span><p></p>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">成为会员</a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>



   

    

    <div class="table-of-contents-link-wrapper">
      <span>目录</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="https://pytorch.org/docs/versions.html">主页 (2.7.0+cpu ) ▼</a>
    </div>
    <div id="searchBox">
    <div class="searchbox" id="googleSearchBox">
      <script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
      <div class="gcse-search"></div>
    </div>
    <div id="sphinxSearchBox" style="display: none;">
      <div role="search">
        <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
          <input type="text" name="q" placeholder="Search Docs">
          <input type="hidden" name="check_keywords" value="yes">
          <input type="hidden" name="area" value="default">
        </form>
      </div>
    </div>
  </div>
  <form id="searchForm">
    <label style="margin-bottom: 1rem">
      <input type="radio" name="searchType" value="google" checked="">Google 搜索</label>
    <label style="margin-bottom: 1rem">
      <input type="radio" name="searchType" value="sphinx">经典搜索</label>
  </form>

  <script>
     document.addEventListener('DOMContentLoaded', function() {
      const searchForm = document.getElementById('searchForm');
      const googleSearchBox = document.getElementById('googleSearchBox');
      const sphinxSearchBox = document.getElementById('sphinxSearchBox');
      // Function to toggle search box visibility
      function toggleSearchBox(searchType) {
        googleSearchBox.style.display = searchType === 'google' ? 'block' : 'none';
        sphinxSearchBox.style.display = searchType === 'sphinx' ? 'block' : 'none';
      }
      // Determine the default search type
      let defaultSearchType;
      const currentUrl = window.location.href;
      if (currentUrl.startsWith('https://pytorch.org/docs/stable')) {
        // For the stable documentation, default to Google
        defaultSearchType = localStorage.getItem('searchType') || 'google';
      } else {
        // For any other version, including docs-preview, default to Sphinx
        defaultSearchType = 'sphinx';
      }
      // Set the default search type
      document.querySelector(`input[name="searchType"][value="${defaultSearchType}"]`).checked = true;
      toggleSearchBox(defaultSearchType);
      // Event listener for changes in search type
      searchForm.addEventListener('change', function(event) {
        const selectedSearchType = event.target.value;
        localStorage.setItem('searchType', selectedSearchType);
        toggleSearchBox(selectedSearchType);
      });
      // Set placeholder text for Google search box
      window.onload = function() {
        var placeholderText = "Search Docs";
        var googleSearchboxText = document.querySelector("#gsc-i-id1");
        if (googleSearchboxText) {
          googleSearchboxText.placeholder = placeholderText;
          googleSearchboxText.style.fontFamily = 'FreightSans';
          googleSearchboxText.style.fontSize = "1.2rem";
          googleSearchboxText.style.color = '#262626';
        }
      };
    });
  </script>

          </div>

          

<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html">您正在查看不稳定开发者预览文档。请点击此处查看最新稳定版本的文档。</a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">社区</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/build_ci_governance.html">PyTorch 治理 | 构建 + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/contribution_guide.html">PyTorch 贡献指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/design.html">PyTorch 设计哲学</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/governance.html">PyTorch 治理 | 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/persons_of_interest.html">PyTorch 治理 | 维护者</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">开发者笔记</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/amp_examples.html">自动混合精度示例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/autograd.html">Autograd 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/broadcasting.html">广播语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cpu_threading_torchscript_inference.html">CPU 多线程和 TorchScript 推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cuda.html">CUDA 语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/custom_operators.html">PyTorch 自定义算子页面</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/ddp.html">分布式数据并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/extending.html">扩展 PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/extending.func.html">使用 autograd.Function 扩展 torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/faq.html">常见问题解答</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/fsdp.html">FSDP 笔记</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/get_start_xpu.html">在 Intel GPU 上入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/gradcheck.html">Gradcheck 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/hip.html">HIP (ROCm)语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/large_scale_deployments.html">大规模部署功能</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/libtorch_stable_abi.html">LibTorch 稳定 ABI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/modules.html">模块</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/mps.html">MPS 后端</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/multiprocessing.html">多进程最佳实践</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/numerical_accuracy.html">数值精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/randomness.html">可重复性</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/serialization.html">序列化语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/windows.html">Windows 常见问题解答</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">语言绑定</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_attributes.html">索引属性</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_view.html">张量视图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../accelerator.html">torch.accelerator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpu.html">torch.cpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_cuda_memory.html">理解 CUDA 内存使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_cuda_memory.html#generating-a-snapshot">生成快照</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_cuda_memory.html#using-the-visualizer">使用可视化工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_cuda_memory.html#snapshot-api-reference">摄像头 API 参考</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mps.html">torch.mps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../xpu.html">torch.xpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mtia.html">torch.mtia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mtia.memory.html">torch.mtia.memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../meta.html">元设备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../export.html">torch.export</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.tensor.html">torch.distributed.tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.fsdp.fully_shard.html">torch.distributed.fsdp.fully_shard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.pipelining.html">torch.distributed.pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.compiler.html">torch.compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../func.html">torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fx.experimental.html">torch.fx.experimental</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../signal.html">torch.signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.attention.html">torch.nn.attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../complex_numbers.html">复数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ddp_comm_hooks.html">DDP 通信钩子</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../quantization.html">量化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rpc.html">分布式 RPC 框架</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../masked.html">torch.masked</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../size.html">torch.Size</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils.html">torch.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deterministic.html">torch.utils.deterministic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../module_tracker.html">torch.utils.module_tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../type_info.html">类型信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../named_tensor.html">命名张量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../name_inference.html">命名张量操作覆盖率</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../future_mod.html">torch.__future__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../logging.html">torch._logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_environment_variables.html">Torch 环境变量</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">库</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">火炬推荐</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/ao">torchao</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        文档 &gt;</li>

        
          <li>模块代码 &gt;</li>
        
          <li><a href="../../../torch.html">torch</a> &gt;</li>
        
      <li>torch.nn.modules.loss</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">快捷键</div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>torch.nn.modules.loss 的源代码</font></font></font></h1><div class="highlight"><pre><span></span><span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># mypy: 允许未类型化定义</span>
<span class="kn">来自</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">打字</font></font></font></span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可调用</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">联合</span>
<span class="kn">来自</font></font></font></span> <span class="nn">typing_extensions</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">已弃用</span>

<span class="kn">来自</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span>
<span class="kn">来自</font></font></font></span> <span class="nn">torch.nn</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_减少</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">作为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">功能性</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">作为</span> <span class="n">F</span>

<span class="kn">来自</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">.距离</font></font></font></span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">成对距离</span>
<span class="kn">来自</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">.模块</font></font></font></span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"L1 损失"</span><span class="p">,</span>
    <span class="s2">"负对数似然损失"</span><span class="p">,</span>
    <span class="s2">"NLLLoss2d"</span><span class="p">,</span>
    <span class="s2">"PoissonNLLLoss"</span><span class="p">,</span>
    <span class="s2">"GaussianNLLLoss"</span><span class="p">,</span>
    <span class="s2">"KLDivLoss"</span><span class="p">,</span>
    <span class="s2">"MSELoss"</span><span class="p">,</span>
    <span class="s2">"BCELoss"</span><span class="p">,</span>
    <span class="s2">"BCEWithLogitsLoss"</span><span class="p">,</span>
    <span class="s2">"HingeEmbeddingLoss"</span><span class="p">,</span>
    <span class="s2">"MultiLabelMarginLoss"</span><span class="p">,</span>
    <span class="s2">"SmoothL1Loss"</span><span class="p">,</span>
    <span class="s2">"HuberLoss"</span><span class="p">,</span>
    <span class="s2">"SoftMarginLoss"</span><span class="p">,</span>
    <span class="s2">"交叉熵损失"</span><span class="p">,</span>
    <span class="s2">"多标签软间隔损失"</span><span class="p">,</span>
    <span class="s2">"余弦嵌入损失"</span><span class="p">,</span>
    <span class="s2">"边界排序损失"</span><span class="p">,</span>
    <span class="s2">"MultiMarginLoss"</span><span class="p">,</span>
    <span class="s2">"TripletMarginLoss"</span><span class="p">,</span>
    <span class="s2">"TripletMarginWithDistanceLoss"</span><span class="p">,</span>
    <span class="s2">"CTCLoss"</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">类</font></font></font></span> <span class="nc">_Loss</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">):</span>
    <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</span>

    <span class="k">def</span> <span class="fm">初始化</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</span><span class="p">()</span>
        <span class="k">如果</font></font></font></span> <span class="n">size_average</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">或</font></font></font></span> <span class="n">reduce</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_减少</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">旧版获取字符串</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</span><span class="p">)</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">减少</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</span>


<span class="k">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_加权 Loss</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">重量</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">注册缓冲区</font></font></font></span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">权重</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">重量</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">]</span>


<div class="viewcode-block" id="L1Loss"><a class="viewcode-back" href="../../../../generated/torch.nn.L1Loss.html#torch.nn.L1Loss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</span> <span class="nc">L1Loss</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">创建一个测量输入 :math:`x` 和目标 :math:`y` 中每个元素之间平均绝对误差 (MAE) 的准则。</span>
<span class="sd">未归一化的损失（即 :attr:`reduction` 设置为 ``'none'``）可以描述为：</span>

<span class="sd">未归一化（即：将：attr:`reduction` 设置为 ``'none'``）的损失可以描述为：</span>

<span class="sd">    .. math::</span>
<span class="sd">\ell(x, y) = L = \{l_1,\dots,l_N\}^\top,</span>
<span class="sd">l_n = |x_n - y_n|,</span>

<span class="sd">其中 :math:`N` 是批大小。如果 :attr:`reduction` 不是 ``'none'``</span>
<span class="sd">（默认 ``'mean'``），则：</span>

<span class="sd">    .. math::</span>
<span class="sd">        \ell(x, y) =</span>
<span class="sd">        \begin{cases}</span>
<span class="sd">\operatorname{mean}(L), &amp; \text{如果 reduction} = \text{`mean';}\\</span>
<span class="sd">\operatorname{sum}(L),  &amp; \text{如果 reduction} = \text{`sum'.}</span>
<span class="sd">        \end{cases}</span>

<span class="sd">math:`x` 和 :math:`y` 是任意形状的张量，其总形状为</span>
<span class="sd">每个元素有 :math:`N` 个。</span>

<span class="sd">求和操作仍然对所有元素进行操作，并除以 :math:`N`。</span>

<span class="sd">如果设置 `reduction = 'sum'`，则可以避免除以 :math:`N`。</span>

<span class="sd">支持实值和复值输入。</span>

<span class="sd">    Args:</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(*)`，其中 :math:`*` 表示任意维数。</span>
<span class="sd">- 目标：:math:`(*)`，与输入具有相同的形状。</span>
<span class="sd">- 输出：标量。如果 :attr:`reduction` 是 ``'none'``，则</span>
<span class="sd">(*), 与输入具有相同形状。</span>

<span class="sd">示例：</span>

<span class="sd">&gt;&gt;&gt; 损失 = nn.L1Loss()</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.randn(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; output = loss(input, target)</span>
<span class="sd">        &gt;&gt;&gt; output.backward()</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">初始化</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">l1_loss：L1 损失</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span></div>


<div class="viewcode-block" id="NLLLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc">NLLLoss</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_加权 Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">负对数似然损失。它用于训练分类</span>
<span class="sd">`C`类的问题。</span>

<span class="sd">如果提供，可选参数 :attr:`weight` 应该是一个分配给每个类别的 1D 张量。</span>
<span class="sd">这在训练集不平衡时尤其有用。</span>
<span class="sd">不平衡的训练集。</span>

<span class="sd">通过正向调用提供的 `input` 应包含每个类别的对数概率。`input` 必须是一个大小为 `(minibatch, C)` 或 `(minibatch, C, d_1, d_2, ..., d_K)` 的张量</span>
<span class="sd">其中 :math:`K \geq 1` 对于 `K` 维情况。后者对于具有多个维度的输入很有用</span>
<span class="sd">math:`(minibatch, C)` 或 :math:`(minibatch, C, d_1, d_2, ..., d_K)`</span>
<span class="sd">的情况。其中 :math:`K \geq 1` 对于 `K` 维情况。后者对于具有多个维度的输入很有用</span>
<span class="sd">高维输入，例如为 2D 图像计算每个像素的 NLL 损失。</span>

<span class="sd">在神经网络中获取对数概率很容易，只需在网络的最后一层添加一个`LogSoftmax`层。</span>
<span class="sd">如果您不想添加额外的层，可以使用`CrossEntropyLoss`。</span>
<span class="sd">您可以选择使用`CrossEntropyLoss`，如果您不希望添加额外的层。</span>
<span class="sd">层。</span>

<span class="sd">此损失函数期望的目标 `target` 应该是一个范围在 :math:`[0, C-1]` 之间的类别索引</span>
<span class="sd">其中 `C = 类别数量`; 如果指定了 `ignore_index`，此损失函数也接受</span>
<span class="sd">此类别索引（此索引不一定在类别范围内）。</span>

<span class="sd">未归一化（即：将：attr:`reduction` 设置为 ``'none'``）的损失可以描述为：</span>

<span class="sd">    .. math::</span>
<span class="sd">\ell(x, y) = L = \{l_1,\dots,l_N\}^\top,</span>
<span class="sd">        l_n = - w_{y_n} x_{n,y_n}, \quad</span>
<span class="sd">        w_{c} = \text{weight}[c] \cdot \mathbb{1}\{c \not= \text{ignore\_index}\},</span>

<span class="sd">当 :math:`x` 是输入，:math:`y` 是目标，:math:`w` 是权重时，</span>
<span class="sd">math:`N` 是批量大小。如果 :attr:`reduction` 不是 ``'none'``</span>
<span class="sd">（默认 ``'mean'``），则</span>

<span class="sd">    .. math::</span>
<span class="sd">        \ell(x, y) = \begin{cases}</span>
<span class="sd">            \sum_{n=1}^N \frac{1}{\sum_{n=1}^N w_{y_n}} l_n, &amp;</span>
<span class="sd">            \text{if reduction} = \text{`mean';}\\</span>
<span class="sd">\sum_{n=1}^N l_n, &amp;</span>
<span class="sd">\text{if reduction} = \text{`sum'}.</span>
<span class="sd">        \end{cases}</span>

<span class="sd">    Args:</span>
<span class="sd">权重（Tensor，可选）：为每个类别提供的手动缩放权重。如果提供，必须是一个大小为 `C` 的 Tensor。</span>
<span class="sd">类。如果提供，它必须是一个大小为 `C` 的张量。否则，它就是</span>
<span class="sd">被视为全为 1。</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 `reduce` 属性为 `False`。默认值：`None`</span>
<span class="sd">忽略索引（int，可选）：指定一个要忽略的目标值</span>
<span class="sd">并且不贡献于输入梯度。</span>
<span class="sd">当 :attr:`size_average` 为 ``True`` 时，损失会在非忽略的目标上平均。</span>
<span class="sd">非忽略的目标上。</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">而不是批元素，并忽略 :attr:`size_average`。默认：``None``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'`` | ``'mean'`` | ``'sum'``。``'none'``：不进行降维</span>
<span class="sd">应用于，``'mean'``：取输出值的加权平均值</span>
<span class="sd">'sum'：输出将被求和。注意：:attr:`size_average`</span>
<span class="sd">`and :attr:`reduce` 正在弃用中，并且`</span>
<span class="sd">同时，指定这两个参数中的任何一个都将覆盖</span>
<span class="sd">attr:`reduction`。默认值：``'mean'``</span>

<span class="sd">形状::</span>
<span class="sd">- 输入：:math:`(N, C)` 或 :math:`(C)`，其中 `C = 类别数量`，`N = 批处理大小`，或</span>
<span class="sd">(N, C, d₁, d₂, ..., dₖ) 其中 K ≥ 1</span>
<span class="sd">在 `K` 维度损失的情况下。</span>
<span class="sd">- 目标：N 或 ( )，其中每个值是</span>
<span class="sd">0 ≤ targets[i] ≤ C-1，或者</span>
<span class="sd">(N, d₁, d₂, ..., dₖ) 其中 K ≥ 1 的情况下</span>
<span class="sd">K 维损失。</span>
<span class="sd">- 输出：如果 :attr:`reduction` 是 ``'none'``，形状 :math:`(N)` 或</span>
<span class="sd">math:`(N, d_1, d_2, ..., d_K)`，其中 :math:`K \geq 1` 为 K 维损失的情况。</span>
<span class="sd">否则，为标量。</span>

<span class="sd">示例：</span>

<span class="sd">        &gt;&gt;&gt; log_softmax = nn.LogSoftmax(dim=1)</span>
<span class="sd">        &gt;&gt;&gt; loss_fn = nn.NLLLoss()</span>
<span class="sd">&gt;&gt;&gt; # 输入到 NLLLoss 的大小为 N x C = 3 x 5</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)</span>
<span class="sd">&gt;&gt;&gt; # 目标中的每个元素值必须满足 0 &lt;= value &lt; C</span>
<span class="sd">        &gt;&gt;&gt; target = torch.tensor([1, 0, 4])</span>
<span class="sd">        &gt;&gt;&gt; loss = loss_fn(log_softmax(input), target)</span>
<span class="sd">        &gt;&gt;&gt; loss.backward()</span>
<span class="sd">...</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 2D 损失示例（例如，用于图像输入）</span>
<span class="sd">        &gt;&gt;&gt; N, C = 5, 4</span>
<span class="sd">        &gt;&gt;&gt; loss_fn = nn.NLLLoss()</span>
<span class="sd">        &gt;&gt;&gt; data = torch.randn(N, 16, 10, 10)</span>
<span class="sd">        &gt;&gt;&gt; conv = nn.Conv2d(16, C, (3, 3))</span>
<span class="sd">        &gt;&gt;&gt; log_softmax = nn.LogSoftmax(dim=1)</span>
<span class="sd">&gt;&gt;&gt; # 输出 conv 前向的结果形状为 [N, C, 8, 8]</span>
<span class="sd">        &gt;&gt;&gt; output = log_softmax(conv(data))</span>
<span class="sd">&gt;&gt;&gt; # 目标中的每个元素值必须满足 0 &lt;= value &lt; C</span>
<span class="sd">        &gt;&gt;&gt; target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)</span>
<span class="sd">&gt;&gt;&gt; # NLLLoss 的输入大小为 N x C x 高度（8）x 宽度（8）</span>
<span class="sd">        &gt;&gt;&gt; loss = loss_fn(output, target)</span>
<span class="sd">        &gt;&gt;&gt; loss.backward()</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"忽略索引"</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>
    <span class="n">忽略索引</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">整型</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">重量</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">忽略索引</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">整型</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_index</span> <span class="o">=</span> <span class="n">ignore_index</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span>
            <span class="nb">输入</span><span class="p">,</span>
            <span class="n">目标</span><span class="p">,</span>
            <span class="n">重量</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</span><span class="p">,</span>
            <span class="n">忽略索引</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">忽略索引</span><span class="p">,</span>
            <span class="n">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">,</span>
        <span class="p">)</span></div>


<span class="nd">@deprecated</span><span class="p">(</span>
    <span class="s2">"NLLLoss2d 已弃用。"</span>
    <span class="s2">"请使用 `NLLLoss` 作为直接替换，并查看 "</span>
    <span class="s2">"https://pytorch.org/docs/main/nn.html#torch.nn.NLLLoss 以获取更多详细信息。"</span><span class="p">,</span>
    <span class="n">分类</font></font></font></span><span class="o">=</span><span class="ne"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">未来警告</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">类</span> <span class="nc">NLLLoss2d</span><span class="p">(</span><span class="n">NLLLoss</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">重量</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">忽略索引</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">整型</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">忽略索引</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>


<div class="viewcode-block" id="PoissonNLLLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.PoissonNLLLoss.html#torch.nn.PoissonNLLLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</span> <span class="nc">PoissonNLLLoss</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">带有泊松分布的目标的负对数似然损失。</span>

<span class="sd">损失可以描述为：</span>

<span class="sd">    .. math::</span>
<span class="sd">\text{目标} \sim \mathrm{Poisson}(\text{输入})</span>

<span class="sd">损失函数（输入，目标）= 输入 - 目标 * log(输入)</span>
<span class="sd">+ log(target!)</span>

<span class="sd">最后一项可以省略或用斯特林公式近似。</span>
<span class="sd">近似用于大于 1 的目标值。对于小于或等于 1 的目标</span>
<span class="sd">添加 1 个零到损失中。</span>

<span class="sd">    Args:</span>
<span class="sd">log_input (bool, 可选): 如果为 ``True``，则损失计算为</span>
<span class="sd">math:`\exp(\text{input}) - \text{target}*\text{input}`，如果为 ``False``，则损失为</span>
<span class="sd">math:`\text{input} - \text{target}*\log(\text{input}+\text{eps})`。</span>
<span class="sd">full (bool, 可选): 是否计算完整损失，即添加</span>
<span class="sd">斯特林近似项</span>

<span class="sd">            .. math::</span>
<span class="sd">\text{目标}*\log(\text{目标}) - \text{目标} + 0.5 * \log(2\pi\text{目标}).</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">eps (float, 可选): 避免评估 :math:`\log(0)` 的小值</span>
<span class="sd">`log_input = False`。默认值：1e-8</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>

<span class="sd">示例：</span>

<span class="sd">&gt;&gt;&gt; 损失函数 = nn.PoissonNLLLoss()</span>
<span class="sd">        &gt;&gt;&gt; log_input = torch.randn(5, 2, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.randn(5, 2)</span>
<span class="sd">        &gt;&gt;&gt; output = loss(log_input, target)</span>
<span class="sd">        &gt;&gt;&gt; output.backward()</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(*)`，其中 :math:`*` 表示任意维数。</span>
<span class="sd">- 目标：:math:`(*)`，与输入具有相同的形状。</span>
<span class="sd">- 输出：默认为标量。如果 :attr:`reduction` 是 ``'none'``，则 :math:`(*)`，</span>
<span class="sd">输入相同的形状。</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2">"log_input"</span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">全部</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">eps</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>
    <span class="n">日志输入</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔类型</span>
    <span class="n">full</span><span class="p">:</span> <span class="nb">布尔类型</span>
    <span class="n">eps</span><span class="p">:</span> <span class="nb">浮点数</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">日志输入</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔类型</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">full</span><span class="p">:</span> <span class="nb">布尔类型</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">浮点数</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">日志输入</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">日志输入</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">完整</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">完整</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">日志输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">泊松 NLL 损失</span><span class="p">(</span>
            <span class="n">日志输入</span><span class="p">,</span>
            <span class="n">目标</span><span class="p">,</span>
            <span class="n">日志输入</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">日志输入</span><span class="p">,</span>
            <span class="n">full</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span>
            <span class="n">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="GaussianNLLLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.GaussianNLLLoss.html#torch.nn.GaussianNLLLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">高斯负对数似然损失</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">高斯负对数似然损失。</span>

<span class="sd">目标被视为高斯分布的样本处理</span>
<span class="sd">神经网络预测的预期和偏差。对于</span>
<span class="sd">目标张量建模为具有高斯分布的张量</span>
<span class="sd">输入期望 ``input`` 和正方差张量 ``var`` 的损失为：</span>

<span class="sd">    .. math::</span>
<span class="sd">\text{loss} = \frac{1}{2}\left(\log\left(\text{max}\left(\text{var}, \text{eps}\right)\right) + \frac{\left(\text{input} - \text{target}\right)^2}{\text{max}\left(\text{var}, \text{eps}\right)}\right) + \text{const.}</span>
<span class="sd">\ \text{eps}用于稳定性。默认情况下，常数项为</span>
<span class="sd">        {\text{max}\left(\text{var}, \ \text{eps}\right)}\right) + \text{const.}</span>

<span class="sd">其中 :attr:`eps` 用于稳定性。默认情况下，常数项为</span>
<span class="sd">损失函数被省略，除非 `:attr:`full` 为 `True`。如果 `var` 不相同</span>
<span class="sd">大小作为“输入”（由于同方差假设），它必须具有最终维度</span>
<span class="sd">1 或具有一个维度更少（其他尺寸相同）以进行正确广播。</span>

<span class="sd">    Args:</span>
<span class="sd">完整（布尔值，可选）：在损失中包含常数项</span>
<span class="sd">计算。默认：``False``。</span>
<span class="sd">eps（浮点数，可选）：用于限制 ``var`` 的值（见下文说明），</span>
<span class="sd">稳定性。默认：1e-6。</span>
<span class="sd">reduction（字符串，可选）：指定要应用到的</span>
<span class="sd">`none` | `mean` | `sum`。`none`：不进行降维</span>
<span class="sd">将被应用，`mean`：输出是所有批次成员损失的均值</span>
<span class="sd">，`sum`：输出是所有批次成员损失的总和。</span>
<span class="sd">默认：`mean`。</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(N, *)` 或 :math:`(*)`，其中 :math:`*` 表示任意数量的附加</span>
<span class="sd">尺寸</span>
<span class="sd">- 目标：:math:`(N, *)` 或 :math:`(*)`，与输入形状相同，或与输入形状相同</span>
<span class="sd">但其中一个维度等于 1（以允许广播）</span>
<span class="sd">- 变量：:math:`(N, *)` 或 :math:`(*)`，与输入形状相同，或与输入形状相同但</span>
<span class="sd">维度为 1，或者与输入具有相同形状但少一个维度（以允许广播），或者是一个标量值</span>
<span class="sd">- 输出：如果：attr:`reduction` 是 ``'mean'``（默认）或 ``'sum'``，则为标量。如果：attr:`reduction` 是 ``'none'``，则为 (N, *) 形状</span>
<span class="sd">- 输出：如果：attr:`reduction` 是 ``'mean'``（默认）或 ``'sum'``，则为标量。如果：attr:`reduction` 是 ``'none'``，则为 (N, *) 形状</span>
<span class="sd">- 输出：如果：attr:`reduction` 是 ``'mean'``（默认）或 ``'sum'``，则为标量。如果：attr:`reduction` 是 ``'none'``，则为 (N, *) 形状</span>
<span class="sd">输入的形状</span>

<span class="sd">示例：</span>
<span class="sd">        &gt;&gt;&gt; loss = nn.GaussianNLLLoss()</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(5, 2, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.randn(5, 2)</span>
<span class="sd">&gt;&gt;&gt; var = torch.ones(5, 2, requires_grad=True)  # 异方差性</span>
<span class="sd">        &gt;&gt;&gt; output = loss(input, target, var)</span>
<span class="sd">        &gt;&gt;&gt; output.backward()</span>

<span class="sd">        &gt;&gt;&gt; loss = nn.GaussianNLLLoss()</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(5, 2, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.randn(5, 2)</span>
<span class="sd">&gt;&gt;&gt; var = torch.ones(5, 1, requires_grad=True)  # 均匀分布</span>
<span class="sd">        &gt;&gt;&gt; output = loss(input, target, var)</span>
<span class="sd">        &gt;&gt;&gt; output.backward()</span>

<span class="sd">注意：</span>
<span class="sd">        The clamping of ``var`` is ignored with respect to autograd, and so the</span>
<span class="sd">渐变不受其影响。</span>

<span class="sd">参考文献：</span>
<span class="sd">Nix, D. A. 和 Weigend, A. S.，“估计目标概率分布的均值和方差”，1994 年 IEEE 国际会议论文集</span>
<span class="sd">目标概率分布的均值和方差估计，1994 年 IEEE 国际会议论文集</span>
<span class="sd">神经网络会议（ICNN'94），奥兰多，佛罗里达州，美国，1994 年，第 55-60 页</span>
<span class="sd">第 1 卷，doi: 10.1109/ICNN.1994.374138.</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">全部</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">eps</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>
    <span class="n">full</span><span class="p">:</span> <span class="nb">布尔类型</span>
    <span class="n">eps</span><span class="p">:</span> <span class="nb">浮点数</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">full</span><span class="p">:</span> <span class="nb">布尔类型</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</font></font></font></span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</font></font></font></span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">完整</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">完整</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>

    <span class="k">def</span> <span class="nf">前向</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="nb">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">变量</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">联盟</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">高斯负对数似然损失</span><span class="p">(</span>
            <span class="nb">输入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">变量</font></font></font></span><span class="p">,</span> <span class="n">full</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="KLDivLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.KLDivLoss.html#torch.nn.KLDivLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">Kullback-Leibler 散度损失</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">“Kullback-Leibler 散度损失。”</span>

<span class="sd">对于形状相同的张量 :math:`y_{\text{pred}},\ y_{\text{true}}`，</span>
<span class="sd">其中 :math:`y_{\text{pred}}` 是 :attr:`输入`，:math:`y_{\text{true}}` 是 :attr:`目标`，</span>
<span class="sd">我们定义 **点 wise KL 散度** 为</span>

<span class="sd">    .. math::</span>

<span class="sd">        L(y_{\text{pred}},\ y_{\text{true}})</span>
<span class="sd">            = y_{\text{true}} \cdot \log \frac{y_{\text{true}}}{y_{\text{pred}}}</span>
<span class="sd">            = y_{\text{true}} \cdot (\log y_{\text{true}} - \log y_{\text{pred}})</span>

<span class="sd">为了避免在计算此数量时出现下溢问题，此损失函数期望在对数空间中的：attr:`input`。：attr:`target` 参数也可以提供</span>
<span class="sd">attr:`input` 在对数空间中。参数：attr:`target` 也可以提供</span>
<span class="sd">如果 :attr:`log_target` 等于 True，则记录空间。</span>

<span class="sd">总结来说，这个函数大致等同于计算。</span>

<span class="sd">.. 代码块 :: python</span>

<span class="sd">如果不使用 log_target：# 默认</span>
<span class="sd">            loss_pointwise = target * (target.log() - input)</span>
<span class="sd">否则:</span>
<span class="sd">            loss_pointwise = target.exp() * (target - input)</span>

<span class="sd">然后根据参数 :attr:`reduction` 减少这个结果</span>

<span class="sd">.. 代码块 :: python</span>

<span class="sd">if reduction == "mean":  # 默认</span>
<span class="sd">            loss = loss_pointwise.mean()</span>
<span class="sd">elif reduction == "batchmean":  # 数学上正确</span>
<span class="sd">            loss = loss_pointwise.sum() / input.size(0)</span>
<span class="sd">        elif reduction == "sum":</span>
<span class="sd">            loss = loss_pointwise.sum()</span>
<span class="sd">        else:  # reduction == "none"</span>
<span class="sd">            loss = loss_pointwise</span>

<span class="sd">.. 注意::</span>
<span class="sd">与 PyTorch 中的其他所有损失函数一样，此函数期望第一个参数，</span>
<span class="sd">attr:`input`，为模型的输出（例如神经网络）</span>
<span class="sd">并且第二个，:attr:`target`，表示数据集中的观测值。</span>
<span class="sd">这与标准数学符号 :math:`KL(P\ ||\ Q)` 不同，</span>
<span class="sd">其中 :math:`P` 表示观测值的分布，:math:`Q` 表示模型。</span>

<span class="sd">.. 警告::</span>
<span class="sd">attr:`reduction`\ `= "mean"` 并不返回真正的 KL 散度值，请使用</span>
<span class="sd">`:attr:`reduction` = "batchmean"` 与数学定义一致。</span>

<span class="sd">    Args:</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为 `False`，则损失将分别对每个小批量求和。当 :attr:`reduce` 为 `False` 时忽略。默认：`True`</span>
<span class="sd">当 :attr:`reduce` 为 `False` 时忽略。默认：`True`</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为`False`时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：`True`</span>
<span class="sd">减少（str，可选）：指定应用于输出的减少方式。默认："mean"</span>
<span class="sd">log_target（布尔值，可选）：指定`target`是否为对数空间。默认：`False`</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(*)`，其中 :math:`*` 表示任意维数。</span>
<span class="sd">- 目标：:math:`(*)`，与输入具有相同的形状。</span>
<span class="sd">- 默认情况下为标量输出。如果 :attr:`reduction` 为 `'none'`，则 :math:`(*)`，</span>
<span class="sd">- 与输入具有相同的形状。</span>

<span class="sd">示例：</span>
<span class="sd">- &gt;&gt;&gt; kl_loss = nn.KLDivLoss(reduction="batchmean")</span>
<span class="sd">&gt;&gt;&gt; # 输入应为对数空间中的分布</span>
<span class="sd">        &gt;&gt;&gt; input = F.log_softmax(torch.randn(3, 5, requires_grad=True), dim=1)</span>
<span class="sd">&gt;&gt;&gt; # 从数据集中采样一批分布。通常这会来自数据集</span>
<span class="sd">        &gt;&gt;&gt; target = F.softmax(torch.rand(3, 5), dim=1)</span>
<span class="sd">        &gt;&gt;&gt; output = kl_loss(input, target)</span>

<span class="sd">        &gt;&gt;&gt; kl_loss = nn.KLDivLoss(reduction="batchmean", log_target=True)</span>
<span class="sd">        &gt;&gt;&gt; log_target = F.log_softmax(torch.rand(3, 5), dim=1)</span>
<span class="sd">        &gt;&gt;&gt; output = kl_loss(input, log_target)</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
        <span class="n">日志目标</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔类型</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">对数目标</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对数目标</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</span> <span class="n">F</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span>
            <span class="nb">输入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">日志目标</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对数目标</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="MSELoss"><a class="viewcode-back" href="../../../../generated/torch.nn.MSELoss.html#torch.nn.MSELoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</span> <span class="nc">MSELoss</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">创建一个衡量输入 :math:`x` 和目标 :math:`y` 中每个元素之间均方误差（平方 L2 范数）的准则。</span>
<span class="sd">未归一化的损失（即：:attr:`reduction` 设置为 ``'none'``）可以描述为：</span>

<span class="sd">未归一化（即：将：attr:`reduction` 设置为 ``'none'``）的损失可以描述为：</span>

<span class="sd">    .. math::</span>
<span class="sd">\ell(x, y) = L = \{l_1,\dots,l_N\}^\top,</span>
<span class="sd">l_n = (x_n - y_n)^2,</span>

<span class="sd">其中 :math:`N` 是批大小。如果 :attr:`reduction` 不是 ``'none'``</span>
<span class="sd">（默认 ``'mean'``），则：</span>

<span class="sd">    .. math::</span>
<span class="sd">        \ell(x, y) =</span>
<span class="sd">        \begin{cases}</span>
<span class="sd">\operatorname{mean}(L), &amp;  \text{如果 reduction} = \text{`mean';}\\</span>
<span class="sd">\operatorname{sum}(L)，&amp;  \text{如果} \text{reduction} = \text{`sum'}.</span>
<span class="sd">        \end{cases}</span>

<span class="sd">math:`x` 和 :math:`y` 是任意形状的张量，其总形状为</span>
<span class="sd">每个元素有 :math:`N` 个。</span>

<span class="sd">均值操作仍然对所有元素进行操作，并除以 :math:`N`。</span>

<span class="sd">如果设置 `reduction = 'sum'`，则可以避免除以 :math:`N`。</span>

<span class="sd">    Args:</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(*)`，其中 :math:`*` 表示任意维数。</span>
<span class="sd">- 目标：:math:`(*)`，与输入具有相同的形状。</span>

<span class="sd">示例：</span>

<span class="sd">&gt;&gt;&gt; 损失 = nn.MSELoss()</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.randn(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; output = loss(input, target)</span>
<span class="sd">        &gt;&gt;&gt; output.backward()</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">初始化</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span></div>


<div class="viewcode-block" id="BCELoss"><a class="viewcode-back" href="../../../../generated/torch.nn.BCELoss.html#torch.nn.BCELoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc">BCELoss</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_加权 Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">创建一个衡量目标与输入概率之间二元交叉熵的准则：</span>
<span class="sd">输入概率：</span>

<span class="sd">未归一化（即：将：attr:`reduction` 设置为 ``'none'``）的损失可以描述为：</span>

<span class="sd">    .. math::</span>
<span class="sd">\ell(x, y) = L = \{l_1,\dots,l_N\}^\top,</span>
<span class="sd">l_n = - w_n * [y_n * log x_n + (1 - y_n) * log (1 - x_n)],</span>

<span class="sd">其中 :math:`N` 是批大小。如果 :attr:`reduction` 不是 ``'none'``</span>
<span class="sd">（默认 ``'mean'``），则</span>

<span class="sd">    .. math::</span>
<span class="sd">        \ell(x, y) = \begin{cases}</span>
<span class="sd">\operatorname{mean}(L), &amp; \text{如果 reduction} = \text{`mean';}\\</span>
<span class="sd">\operatorname{sum}(L),  &amp; \text{如果 reduction} = \text{`sum'.}</span>
<span class="sd">        \end{cases}</span>

<span class="sd">这是用于测量重建误差，例如</span>
<span class="sd">一个自动编码器。注意，目标 :math:`y` 应该是数字</span>
<span class="sd">在 0 和 1 之间。</span>

<span class="sd">注意，如果 :math:`x_n` 是 0 或 1，上述损失方程中的一个对数项将是</span>
<span class="sd">在上述损失方程中，如果 :math:`x_n` 是 0 或 1，则其中一个对数项将是数学上未定义的。PyTorch 选择将其设置为</span>
<span class="sd">math:`log(0) = -∞`，因为 :math:`lim_{x→0} log(x) = -∞`。</span>
<span class="sd">然而，损失方程中的无穷项并不理想，原因有几个。</span>

<span class="sd">首先，如果 :math:`y_n = 0` 或 :math:`(1 - y_n) = 0`，那么我们就会</span>
<span class="sd">将 0 与无穷相乘。其次，如果我们有一个无穷大的损失值，那么</span>
<span class="sd">我们梯度中也会有一个无穷项，</span>
<span class="sd">\lim_{x\to 0} \frac{d}{dx} \log (x) = \infty。</span>
<span class="sd">这将使得 BCELoss 的反向传播相对于 \( x_n \) 非线性，</span>
<span class="sd">使用它进行诸如线性回归等操作将不会简单直接。</span>

<span class="sd">我们的解决方案是 BCELoss 将其对数函数输出限制为大于或等于 -100。这样，我们总能有一个有限的损失值和线性反向方法。</span>
<span class="sd">或者等于 -100。这样，我们总能有一个有限的损失值和线性反向方法。</span>
<span class="sd">的反向方法。</span>


<span class="sd">    Args:</span>
<span class="sd">权重（张量，可选）：分配给损失的手动缩放权重</span>
<span class="sd">每个批次元素的总量。如果提供，必须是大小为 `nbatch` 的张量。</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(*)`，其中 :math:`*` 表示任意维数。</span>
<span class="sd">- 目标：:math:`(*)`，与输入具有相同的形状。</span>
<span class="sd">- 输出：标量。如果 :attr:`reduction` 为 ``'none'``，则 :math:`(*)`，与输入相同。</span>
<span class="sd">输入形状。</span>

<span class="sd">示例：</span>

<span class="sd">        &gt;&gt;&gt; m = nn.Sigmoid()</span>
<span class="sd">&gt;&gt;&gt; 损失 = nn.BCELoss()</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(3, 2, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.rand(3, 2, requires_grad=False)</span>
<span class="sd">&gt;&gt;&gt; 输出 = 损失(m(input), target)</span>
<span class="sd">        &gt;&gt;&gt; output.backward()</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">重量</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">二元交叉熵</span><span class="p">(</span>
            <span class="nb">输入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="BCEWithLogitsLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</span> <span class="nc">BCEWithLogitsLoss</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">这个损失函数结合了一个 `Sigmoid` 层和 `BCELoss`，实现为一个单一</span>
<span class="sd">的类。这个版本比使用普通的 `Sigmoid` 后跟 `BCELoss` 更数值稳定，</span>
<span class="sd">因为通过将操作合并到一个层中，...</span>
<span class="sd">我们利用对数和指数技巧来保证数值稳定性。</span>

<span class="sd">未归一化（即：将：attr:`reduction` 设置为 ``'none'``）的损失可以描述为：</span>

<span class="sd">    .. math::</span>
<span class="sd">\ell(x, y) = L = \{l_1,\dots,l_N\}^\top,</span>
<span class="sd">l_n = - w_n \left[ y_n \cdot \log \sigma(x_n) \right]</span>
<span class="sd">+ (1 - y_n) * log(1 - σ(x_n)) ]</span>

<span class="sd">其中 :math:`N` 是批大小。如果 :attr:`reduction` 不是 ``'none'``</span>
<span class="sd">（默认 ``'mean'``），则</span>

<span class="sd">    .. math::</span>
<span class="sd">        \ell(x, y) = \begin{cases}</span>
<span class="sd">\operatorname{mean}(L), &amp; \text{如果 reduction} = \text{`mean';}\\</span>
<span class="sd">\operatorname{sum}(L),  &amp; \text{如果 reduction} = \text{`sum'.}</span>
<span class="sd">        \end{cases}</span>

<span class="sd">这是用于测量重建误差，例如</span>
<span class="sd">一个自编码器。注意，目标`t[i]`应该是数字</span>
<span class="sd">在 0 和 1 之间。</span>

<span class="sd">通过为正例添加权重，可以权衡召回率和精确度。</span>
<span class="sd">在多标签分类的情况下，损失可以描述为：</span>

<span class="sd">    .. math::</span>
<span class="sd">\ell_c(x, y) = L_c = \{l_{1,c},\dots,l_{N,c}\}^\top,</span>
<span class="sd">l_{n,c} = - w_{n,c} [p_c y_{n,c} · log σ(x_{n,c})]</span>
<span class="sd">+（1 - y_{n,c}）· log（1 - σ(x_{n,c}））]</span>

<span class="sd">其中 :math:`c` 是类别数（对于多标签二分类，:math:`c &gt; 1`）</span>
<span class="sd">对于单标签二分类，:math:`c = 1`</span>
<span class="sd">math:`n` 是批次中样本的数量</span>
<span class="sd">math:`p_c` 是类别 :math:`c` 正确答案的权重</span>

<span class="sd">math:`p_c &gt; 1` 会增加召回率，:math:`p_c &lt; 1` 会增加精确度</span>

<span class="sd">例如，如果一个数据集包含一个类别的 100 个正例和 300 个负例，</span>
<span class="sd">类的 ``pos_weight`` 应该等于 :math:`\frac{300}{100}=3`。</span>
<span class="sd">损失将作用于数据集包含 :math:`3\times 100=300` 个正例的情况。</span>

<span class="sd">示例：</span>

<span class="sd">&gt;&gt;&gt; target = torch.ones([10, 64], dtype=torch.float32)  # 64 个类别，批大小 = 10</span>
<span class="sd">&gt;&gt;&gt; output = torch.full([10, 64], 1.5)  # 一个预测（logit）</span>
<span class="sd">&gt;&gt;&gt; pos_weight = torch.ones([64])  # 所有权重都等于 1</span>
<span class="sd">        &gt;&gt;&gt; criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)</span>
<span class="sd">        &gt;&gt;&gt; criterion(output, target)  # -log(sigmoid(1.5))</span>
<span class="sd">        tensor(0.20...)</span>

<span class="sd">在上述示例中，`pos_weight` 张量的元素对应于 64 个不同的类别</span>
<span class="sd">在多标签二进制分类场景中，`pos_weight` 中的每个元素都旨在根据相应类别的正负样本之间的不平衡来调整损失函数</span>
<span class="sd">这种方法在类别不平衡程度不同的数据集中很有用，确保损失</span>
<span class="sd">这种方法在类别不平衡程度不同的数据集中很有用，确保损失函数能够反映正负样本的不平衡情况</span>
<span class="sd">准确计算了每个类别的分布。</span>

<span class="sd">    Args:</span>
<span class="sd">权重（张量，可选）：分配给损失的手动缩放权重</span>
<span class="sd">每个批次元素的总量。如果提供，必须是大小为 `nbatch` 的张量。</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>
<span class="sd">pos_weight (Tensor，可选): 正例的权重，将广播与目标一起使用。</span>
<span class="sd">必须是一个与类别维度的类别数量相等的张量。</span>
<span class="sd">请密切关注 PyTorch 的广播语义，以实现所需的效果。</span>
<span class="sd">操作。对于大小为[B, C, H, W]的目标（其中 B 是批量大小），将根据大小[B, C, H, W]应用不同的 pos_weight 到批量的每个元素或</span>
<span class="sd">[C, H, W]在整个批次中应用相同的 pos_weight。对于 2D 多类目标[C, H, W]，要沿所有空间维度应用相同的正权重，请使用：[C, 1, 1]。</span>
<span class="sd">沿所有空间维度应用相同的正权重。对于 2D 多类目标[C, H, W]，要沿所有空间维度应用相同的正权重，请使用：[C, 1, 1]。</span>
<span class="sd">在所有空间维度上对 2D 多分类目标 [C, H, W] 使用：[C, 1, 1]。</span>
<span class="sd">默认：`None`</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(*)`，其中 :math:`*` 表示任意维数。</span>
<span class="sd">- 目标：:math:`(*)`，与输入具有相同的形状。</span>
<span class="sd">- 输出：标量。如果 :attr:`reduction` 为 ``'none'``，则 :math:`(*)`，与输入相同。</span>
<span class="sd">输入形状。</span>

<span class="sd">示例：</span>

<span class="sd">&gt;&gt;&gt; 损失 = nn.BCEWithLogitsLoss()</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(3, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.empty(3).random_(2)</span>
<span class="sd">        &gt;&gt;&gt; output = loss(input, target)</span>
<span class="sd">        &gt;&gt;&gt; output.backward()</span>
<span class="sd">"源代码"</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">重量</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
        <span class="n">正向权重</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">注册缓冲区</font></font></font></span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">权重</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">注册缓冲区</font></font></font></span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"正则权重"</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">正向权重</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">重量</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">正向权重</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">二元交叉熵（对数）</span><span class="p">(</span>
            <span class="nb">输入</span><span class="p">,</span>
            <span class="n">目标</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">重量</span><span class="p">,</span>
            <span class="n">正向权重</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">正向权重</span><span class="p">,</span>
            <span class="n">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="HingeEmbeddingLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.HingeEmbeddingLoss.html#torch.nn.HingeEmbeddingLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</span> <span class="nc">HingeEmbeddingLoss</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">评估给定输入张量 :math:`x` 和标签张量 :math:`y` （包含 1 或 -1）的损失</span>
<span class="sd">。</span>
<span class="sd">这通常用于衡量两个输入是否相似或</span>
<span class="sd">不相同，例如使用 L1 成对距离作为：math:`x`，通常</span>
<span class="sd">用于学习非线性嵌入或半监督学习。</span>

<span class="sd">小批量中第 n 个样本的损失函数为</span>

<span class="sd">    .. math::</span>
<span class="sd">l_n =</span>
<span class="sd">            x_n, &amp; \text{if}\; y_n = 1,\\</span>
<span class="sd">            \max \{0, margin - x_n\}, &amp; \text{if}\; y_n = -1,</span>
<span class="sd">        \end{cases}</span>

<span class="sd">总损失函数是</span>

<span class="sd">    .. math::</span>
<span class="sd">        \ell(x, y) = \begin{cases}</span>
<span class="sd">\operatorname{mean}(L), &amp; \text{如果 reduction} = \text{`mean';}\\</span>
<span class="sd">\operatorname{sum}(L),  &amp; \text{如果 reduction} = \text{`sum'.}</span>
<span class="sd">        \end{cases}</span>

<span class="sd">其中 :math:`L = \{l_1,\dots,l_N\}^\top`.</span>

<span class="sd">    Args:</span>
<span class="sd">边界（float，可选）：具有默认值 `1`.</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(*)` 其中 :math:`*` 表示，任意数量的维度。求和操作</span>
<span class="sd">在所有元素上执行。</span>
<span class="sd">- 目标：:math:`(*)`，与输入形状相同</span>
<span class="sd">- 输出：标量。如果 :attr:`reduction` 为 ``'none'``，则与输入形状相同</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>
    <span class="n">边距</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">边距</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">边距</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">齐次嵌入损失</span><span class="p">(</span>
            <span class="nb">输入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="MultiLabelMarginLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.MultiLabelMarginLoss.html#torch.nn.MultiLabelMarginLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">多标签边界损失</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">创建一个优化输入 :math:`x`（一个 2D mini-batch `Tensor`）和输出 :math:`y`（它是一个 2D `Tensor`，包含目标类索引）之间多类别多分类的边界损失（基于边界的损失）的准则。</span>
<span class="sd">hinge 损失（基于边界的损失）</span>
<span class="sd">和输出 :math:`y`（它是一个 2D `Tensor`，包含目标类索引）。</span>
<span class="sd">对于每个小批量中的样本：</span>

<span class="sd">    .. math::</span>
<span class="sd">\text{损失}(x, y) = \sum_{ij}\frac{\max(0, 1 - (x[y[j]] - x[i]))}{\text{x.size}(0)}</span>

<span class="sd">其中 :math:`x \in \left\{0, \; \cdots , \; \text{x.size}(0) - 1\right\}`, \</span>
<span class="sd">math:`y \in \left\{0, \; \cdots , \; \text{y.size}(0) - 1\right\}`, \</span>
<span class="sd">\(0 \leq y[j] \leq \text{x.size}(0)-1\)，</span>
<span class="sd">且对于所有 \(i\) 和 \(j\)，有 \(i \neq y[j]\)。</span>

<span class="sd">\(y\) 和 \(x\) 必须具有相同的大小。</span>

<span class="sd">该标准仅考虑连续的非负目标块。</span>
<span class="sd">从前面开始。</span>

<span class="sd">这允许不同的样本具有不同数量的目标类别。</span>

<span class="sd">    Args:</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(C)` 或 :math:`(N, C)`，其中 `N` 是批大小，`C` 是类别数。</span>
<span class="sd">是类别数量。</span>
<span class="sd">- 目标：:math:`(C)` 或 :math:`(N, C)`，标签目标填充为 -1，确保与输入具有相同的形状。</span>
<span class="sd">- 输出：标量。如果 :attr:`reduction` 是 ``'none'``，则 :math:`(N)`。</span>

<span class="sd">示例：</span>

<span class="sd">&gt;&gt;&gt; 损失 = nn.MultiLabelMarginLoss()</span>
<span class="sd">        &gt;&gt;&gt; x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8]])</span>
<span class="sd">&gt;&gt;&gt; # 对于目标 y，仅考虑标签 3 和 0，不包括标签 -1 之后</span>
<span class="sd">        &gt;&gt;&gt; y = torch.LongTensor([[3, 0, -1, 1]])</span>
<span class="sd">        &gt;&gt;&gt; # 0.25 * ((1-(0.1-0.2)) + (1-(0.1-0.4)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))</span>
<span class="sd">        &gt;&gt;&gt; loss(x, y)</span>
<span class="sd">        tensor(0.85...)</span>

<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">初始化</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">多标签边际损失</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span></div>


<div class="viewcode-block" id="SmoothL1Loss"><a class="viewcode-back" href="../../../../generated/torch.nn.SmoothL1Loss.html#torch.nn.SmoothL1Loss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</span> <span class="nc">SmoothL1Loss</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""创建一个使用平方项的准则，如果绝对值</span>
<span class="sd">它对异常值不如 :class:`torch.nn.MSELoss` 敏感，在某些情况下</span>
<span class="sd">它对异常值不如 :class:`torch.nn.MSELoss` 敏感，在某些情况下</span>
<span class="sd">防止梯度爆炸（例如，参见 Ross Girshick 的论文《Fast R-CNN》_）。</span>

<span class="sd">对于大小为 :math:`N` 的一批数据，未归一化的损失可以描述为：</span>

<span class="sd">    .. math::</span>
<span class="sd">\ell(x, y) = L = {l_1, ..., l_N}^T</span>

<span class="sd">的</span>

<span class="sd">    .. math::</span>
<span class="sd">l_n =</span>
<span class="sd">0.5(x_n - y_n)^2 / β，&amp; 若 |x_n - y_n| &lt; β</span>
<span class="sd">|x_n - y_n| - 0.5 * β，&amp; 否则</span>
<span class="sd">        \end{cases}</span>

<span class="sd">如果 `reduction` 不是 `none`，则：</span>

<span class="sd">    .. math::</span>
<span class="sd">        \ell(x, y) =</span>
<span class="sd">        \begin{cases}</span>
<span class="sd">\operatorname{mean}(L), &amp;  \text{如果 reduction} = \text{`mean';}\\</span>
<span class="sd">\operatorname{sum}(L)，&amp;  \text{如果} \text{reduction} = \text{`sum'}.</span>
<span class="sd">        \end{cases}</span>

<span class="sd">.. 注意::</span>
<span class="sd">平滑 L1 损失可以看作是正好等于 :class:`L1Loss`，但将 :math:`|x - y| &lt; beta`</span>
<span class="sd">的部分替换为一个二次函数，使其在 :math:`|x - y| = beta` 时的斜率为 1。</span>
<span class="sd">二次段平滑了在 :math:`|x - y| = 0` 附近的 L1 损失。</span>

<span class="sd">.. 注意::</span>
<span class="sd">平滑 L1 损失与 :class:`HuberLoss` 密切相关</span>
<span class="sd">相当于：`huber(x, y) / beta`（注意平滑 L1 的 beta 超参数是）</span>
<span class="sd">也称为 Huber 的 delta。这导致以下差异：</span>

<span class="sd">* 当 beta -&gt; 0 时，Smooth L1 损失收敛到 :class:`L1Loss`，而 :class:`HuberLoss`</span>
<span class="sd">损失收敛到一个常数 0 损失。当 beta 为 0 时，Smooth L1 损失等同于 L1 损失。</span>
<span class="sd">* 当 beta -&gt; :math:`+∞`时，Smooth L1 损失收敛到一个常数 0 损失，而</span>
<span class="sd">class:`HuberLoss`收敛到 :class:`MSELoss`。</span>
<span class="sd">对于 Smooth L1 损失，随着 beta 的变化，损失函数的 L1 部分具有恒定的斜率为 1。</span>
<span class="sd">对于: class:`HuberLoss`，L1 部分的斜率为 beta。</span>

<span class="sd">    .. _`Fast R-CNN`: https://arxiv.org/abs/1504.08083</span>

<span class="sd">    Args:</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>
<span class="sd">beta (浮点数，可选)：指定在 L1 损失和 L2 损失之间切换的阈值。</span>
<span class="sd">该值必须为非负数。默认：1.0</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(*)`，其中 :math:`*` 表示任意维数。</span>
<span class="sd">- 目标：:math:`(*)`，与输入具有相同的形状。</span>
<span class="sd">- 输出：标量。如果 :attr:`reduction` 是 ``'none'``，则 :math:`(*)`，与输入具有相同的形状。</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">测试版</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">测试版</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">测试版</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平滑 L1 损失</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">测试版</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">测试版</span><span class="p">)</span></div>


<div class="viewcode-block" id="HuberLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.HuberLoss.html#torch.nn.HuberLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</span> <span class="nc">HuberLoss</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""创建一个使用平方项的准则，如果绝对值</span>
<span class="sd">函数使用平方项如果元素级误差低于 delta，否则使用 delta 缩放的 L1 项。</span>
<span class="sd">这种损失结合了`:class:`L1Loss`和`:class:`MSELoss`的优点；</span>
<span class="sd">delta-scaled L1 区域使损失对异常值比 :class:`MSELoss` 更不敏感</span>
<span class="sd">当 L2 区域在 0 附近对:class:`L1Loss`提供平滑性时。</span>
<span class="sd">Huber 损失  了解更多信息。</span>

<span class="sd">对于大小为 :math:`N` 的一批数据，未归一化的损失可以描述为：</span>

<span class="sd">    .. math::</span>
<span class="sd">\ell(x, y) = L = {l_1, ..., l_N}^T</span>

<span class="sd">的</span>

<span class="sd">    .. math::</span>
<span class="sd">l_n =</span>
<span class="sd">0.5 (x_n - y_n)^2, &amp; \text{如果 } |x_n - y_n| &lt; delta</span>
<span class="sd">delta * (|x_n - y_n| - 0.5 * delta), &amp; \text{否则 }</span>
<span class="sd">        \end{cases}</span>

<span class="sd">如果 `reduction` 不是 `none`，则：</span>

<span class="sd">    .. math::</span>
<span class="sd">        \ell(x, y) =</span>
<span class="sd">        \begin{cases}</span>
<span class="sd">\operatorname{mean}(L), &amp;  \text{如果 reduction} = \text{`mean';}\\</span>
<span class="sd">\operatorname{sum}(L)，&amp;  \text{如果} \text{reduction} = \text{`sum'}.</span>
<span class="sd">        \end{cases}</span>

<span class="sd">.. 注意::</span>
<span class="sd">当 delta 设置为 1 时，这个损失等同于 :class:`SmoothL1Loss`。</span>
<span class="sd">通常，这个损失与 :class:`SmoothL1Loss` 相差一个 delta（又称 beta）因子。</span>
<span class="sd">在 Smooth L1 中）。</span>
<span class="sd">请参阅：class:`SmoothL1Loss`以了解两个损失函数行为差异的进一步讨论。</span>
<span class="sd">两个损失函数之间的差异。</span>

<span class="sd">    Args:</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">输出元素，``'sum'``：输出将被求和。默认：``'mean'``。</span>
<span class="sd">delta（浮点数，可选）：指定在 delta 缩放 L1 和 L2 损失之间切换的阈值。</span>
<span class="sd">值必须是正数。默认值：1.0</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(*)`，其中 :math:`*` 表示任意维数。</span>
<span class="sd">- 目标：:math:`(*)`，与输入具有相同的形状。</span>
<span class="sd">- 输出：标量。如果 :attr:`reduction` 是 ``'none'``，则 :math:`(*)`，与输入具有相同的形状。</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">,</span> <span class="s2">"delta"</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">初始化</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">Δ</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</font></font></font></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delta</span> <span class="o">=</span> <span class="n">delta</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">胡伯损失</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">Δ</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">Δ</span><span class="p">)</span></div>


<div class="viewcode-block" id="SoftMarginLoss"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]class SoftMarginLoss(_Loss):
r"""创建一个优化输入张量 :math:`x` 和目标张量 :math:`y` 之间（包含 1 或 -1）的两类分类逻辑损失的准则
(containing 1 or -1).
(包含 1 或 -1)之间的逻辑损失的准则。

数学公式
损失函数为：\text{loss}(x, y) = \sum_i \frac{\log(1 + \exp(-y[i]*x[i]))}{\text{x.nelement}()}

参数：
size_average (布尔值，可选)：已弃用（参见 :attr:`reduction`）。默认情况下，
批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 :attr:`reduce` 为 ``False`` 时忽略。默认：``True``
对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，
如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 :attr:`reduce` 为 ``False`` 时忽略。
当 :attr:`reduce` 为 ``False`` 时忽略。默认：``True``
减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，
损失在每个小批量上的观测值被平均或求和
在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失
批量元素而不是，并忽略：attr:`size_average`。默认：``True``
reduction（字符串，可选）：指定应用于输出的缩减
``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: 不应用任何缩减，
'mean'：输出总和将除以数量
输出元素，``'sum'``：输出将被求和。注意：:attr:`size_average`
和：attr:`reduce` 正在弃用中，同时，
指定这两个参数中的任何一个都将覆盖：attr:`reduction`。默认值：``'mean'``

形状：
- 输入：:math:`(*)`，其中 :math:`*` 表示任意数量的维度。
- 目标：:math:`(*)`，与输入形状相同。
- 输出：标量。如果 :attr:`reduction` 是 ``'none'``，则 :math:`(*)`，与输入形状相同。
- 输入形状相同。

"""
__constants__ = ["reduction"]

def __init__(self, size_average=None, reduce=None, reduction: str = "mean") -&gt; None:
super().__init__(size_average, reduce, reduction)

def forward(self, input: Tensor, target: Tensor) -&gt; Tensor:
return F 软间隔损失(input, target, reduction=self.reduction)</font></font></font></div>


<div class="viewcode-block" id="CrossEntropyLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_加权 Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""此标准计算输入 logits 与目标之间的交叉熵损失</span>
<span class="sd">和目标。</span>

<span class="sd">当训练具有 `C` 个类别的分类问题时很有用。</span>
<span class="sd">如果提供，可选参数 :attr:`weight` 应该是一个 1D `Tensor`。</span>
<span class="sd">为每个类别分配权重。</span>
<span class="sd">这尤其适用于训练集不平衡的情况。</span>

<span class="sd">预期的 `input` 应包含每个类别的未归一化 logits（通常不需要是正数或求和为 1）。</span>
<span class="sd">`input` 必须是一个大小为 :math:`(C)` 的 Tensor，对于非批处理输入。</span>
<span class="sd">`input` 必须是一个大小为 :math:`(C)` 的 Tensor，对于非批处理输入。</span>
<span class="sd">`(minibatch, C)` 或 `(minibatch, C, d_1, d_2, ..., d_K)`，其中 `K ≥ 1` 对于 `K` 维度情况。最后一个对于高维输入很有用，例如计算 2D 图像的每个像素的交叉熵损失。</span>
<span class="sd">`target` 该标准期望的目标应包含以下内容：</span>
<span class="sd">作为一个例子，对于 2D 图像，每个像素的交叉熵损失计算很有用。</span>

<span class="sd">期望的目标 `target` 应包含以下内容：</span>

<span class="sd">- 类别索引范围：[0, C) 其中 C 是类别数；如果</span>
<span class="sd">`ignore_index` 被指定，此损失也接受此类索引（此索引</span>
<span class="sd">可能不一定在类范围内）。未缩减的（即带有：attr:`reduction`）</span>
<span class="sd">将此设置为 ''none'') 的损失可以描述为：</span>

<span class="sd">      .. math::</span>
<span class="sd">\ell(x, y) = L = \{l_1,\dots,l_N\}^\top,</span>
<span class="sd">          l_n = - w_{y_n} \log \frac{\exp(x_{n,y_n})}{\sum_{c=1}^C \exp(x_{n,c})}</span>
<span class="sd">          \cdot \mathbb{1}\{y_n \not= \text{ignore\_index}\}</span>

<span class="sd">其中 :math:`x` 是输入，:math:`y` 是目标，:math:`w` 是权重，</span>
<span class="sd">`C` 是类别数，而 `N` 覆盖了小批量维度。</span>
<span class="sd">对于 `K` 维度的情况，有 `d_1, ..., d_k`。</span>
<span class="sd">如果 `reduction` 不是 `'none'`（默认为 `'mean'`），则 ...</span>

<span class="sd">      .. math::</span>
<span class="sd">          \ell(x, y) = \begin{cases}</span>
<span class="sd">              \sum_{n=1}^N \frac{1}{\sum_{n=1}^N w_{y_n} \cdot \mathbb{1}\{y_n \not= \text{ignore\_index}\}} l_n, &amp;</span>
<span class="sd">               \text{if reduction} = \text{`mean';}\\</span>
<span class="sd">\sum_{n=1}^N l_n, &amp;</span>
<span class="sd">\text{if reduction} = \text{`sum'}.</span>
<span class="sd">            \end{cases}</span>

<span class="sd">请注意，此情况等价于应用 :class:`~torch.nn.LogSoftmax`</span>
<span class="sd">在一个输入后，接着是：:class:`~torch.nn.NLLLoss`。</span>

<span class="sd">每个类别的概率；当每个小批量项超过一个类别标签时很有用</span>
<span class="sd">需要，例如用于混合标签、标签平滑等。未归一化（即带有</span>
<span class="sd">attr:`reduction` 设置为 ``'none'``) 此情况的损失可以描述为：</span>

<span class="sd">      .. math::</span>
<span class="sd">\ell(x, y) = L = \{l_1,\dots,l_N\}^\top,</span>
<span class="sd">          l_n = - \sum_{c=1}^C w_c \log \frac{\exp(x_{n,c})}{\sum_{i=1}^C \exp(x_{n,i})} y_{n,c}</span>

<span class="sd">其中 :math:`x` 是输入，:math:`y` 是目标，:math:`w` 是权重，</span>
<span class="sd">`C` 是类别数，而 `N` 覆盖了小批量维度。</span>
<span class="sd">对于 `K` 维度的情况，有 `d_1, ..., d_k`。</span>
<span class="sd">如果 `reduction` 不是 `'none'`（默认为 `'mean'`），则 ...</span>

<span class="sd">      .. math::</span>
<span class="sd">          \ell(x, y) = \begin{cases}</span>
<span class="sd">              \frac{\sum_{n=1}^N l_n}{N}, &amp;</span>
<span class="sd">               \text{if reduction} = \text{`mean';}\\</span>
<span class="sd">\sum_{n=1}^N l_n, &amp;</span>
<span class="sd">\text{if reduction} = \text{`sum'}.</span>
<span class="sd">            \end{cases}</span>

<span class="sd">.. 注意::</span>
<span class="sd">当`target`包含类别索引时，此标准的性能通常更好，因为这允许进行优化计算。</span>
<span class="sd">考虑仅在单个类别标签对每个 minibatch 项过于限制时，仅提供`target`的类别概率。</span>
<span class="sd">权重（Tensor，可选）：为每个类别提供的手动缩放权重。</span>

<span class="sd">    Args:</span>
<span class="sd">权重（Tensor，可选）：为每个类别提供的手动缩放权重。</span>
<span class="sd">如果提供，必须是一个大小为 `C` 的浮点型 Tensor</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">忽略索引（int，可选）：指定一个要忽略的目标值</span>
<span class="sd">并且不贡献于输入梯度。当 :attr:`size_average` 为 ``True`` 时，</span>
<span class="sd">“True”，损失是针对非忽略目标平均的。注意，</span>
<span class="sd">attr:`ignore_index` 仅在目标包含类别索引时适用。</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'`` | ``'mean'`` | ``'sum'``。``'none'``：不进行降维</span>
<span class="sd">应用于，``'mean'``：取输出值的加权平均值</span>
<span class="sd">'sum'：输出将被求和。注意：:attr:`size_average`</span>
<span class="sd">`and :attr:`reduce` 正在弃用中，并且`</span>
<span class="sd">同时，指定这两个参数中的任何一个都将覆盖</span>
<span class="sd">attr:`reduction`。默认值：``'mean'``</span>
<span class="sd">标签平滑（浮点数，可选）：一个位于[0.0, 1.0]之间的浮点数。指定平滑量</span>
<span class="sd">在计算损失时的平滑度，其中 0.0 表示无平滑。目标</span>
<span class="sd">原始真实值和如描述的均匀分布混合在一起</span>
<span class="sd">《重新思考计算机视觉的 Inception 架构 》。默认值：:math:`0.0`。</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：形状 :math:`(C)`，:math:`(N, C)` 或 :math:`(N, C, d_1, d_2, ..., d_K)`，其中 :math:`K \geq 1`</span>
<span class="sd">在 `K` 维度损失的情况下。</span>
<span class="sd">- 目标：如果包含类别索引，形状为 :math:`()`, :math:`(N)` 或 :math:`(N, d_1, d_2, ..., d_K)`，其中</span>
<span class="sd">在 K 维损失的情况下，K 应大于等于 1，其中每个值应在[0, C)范围内。当使用类别索引时，目标数据类型必须为长整型。如果包含类别概率，则目标必须与输入形状相同，并且每个值应在[0, 1]范围内。这意味着目标</span>
<span class="sd">的目标数据类型必须为长整型。如果包含类别概率，则目标必须与输入形状相同，并且每个值应在[0, 1]范围内。这意味着目标</span>
<span class="sd">必须与输入形状相同，并且每个值应在[0, 1]范围内。这意味着目标</span>
<span class="sd">使用类概率时，数据类型必须为浮点数。</span>
<span class="sd">- 输出：如果 reduction 为'none'，形状为：math:`()`, :math:`(N)` 或 :math:`(N, d_1, d_2, ..., d_K)`，其中 :math:`K \geq 1`</span>
<span class="sd">在 K 维损失的情况下，取决于输入的形状。否则，为标量。</span>


<span class="sd">其中：</span>

<span class="sd">        .. math::</span>
<span class="sd">            \begin{aligned}</span>
<span class="sd">C ={} &amp; \text{类别数量} \\</span>
<span class="sd">N ={} &amp; \text{批量大小} \\</span>
<span class="sd">            \end{aligned}</span>

<span class="sd">示例：</span>

<span class="sd">&gt;&gt;&gt; # 示例：带有类别索引的目标</span>
<span class="sd">        &gt;&gt;&gt; loss = nn.CrossEntropyLoss()</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.empty(3, dtype=torch.long).random_(5)</span>
<span class="sd">        &gt;&gt;&gt; output = loss(input, target)</span>
<span class="sd">        &gt;&gt;&gt; output.backward()</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 示例：带有概率类的目标</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.randn(3, 5).softmax(dim=1)</span>
<span class="sd">        &gt;&gt;&gt; output = loss(input, target)</span>
<span class="sd">        &gt;&gt;&gt; output.backward()</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2">"ignore_index"</span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">,</span> <span class="s2">"label_smoothing"</span><span class="p">]</span>
    <span class="n">忽略索引</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">整型</span>
    <span class="n">标签平滑</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">重量</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">忽略索引</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">整型</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
        <span class="n">标签平滑</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_index</span> <span class="o">=</span> <span class="n">ignore_index</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_smoothing</span> <span class="o">=</span> <span class="n">标签平滑</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">交叉熵</span><span class="p">(</span>
            <span class="nb">输入</span><span class="p">,</span>
            <span class="n">目标</span><span class="p">,</span>
            <span class="n">重量</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</span><span class="p">,</span>
            <span class="n">忽略索引</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">忽略索引</span><span class="p">,</span>
            <span class="n">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">,</span>
            <span class="n">标签平滑</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">标签平滑</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="MultiLabelSoftMarginLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.MultiLabelSoftMarginLoss.html#torch.nn.MultiLabelSoftMarginLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">多标签软间隔损失</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_加权 Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">创建一个优化多标签一对一所有类的标准</span>
<span class="sd">基于最大熵的损失，在输入 :math:`x` 和目标 :math:`y` 之间</span>
<span class="sd">\( (N, C) \).</span>
<span class="sd">对于每个小批量中的样本：</span>

<span class="sd">    .. math::</span>
<span class="sd">损失函数 \( loss(x, y) = - \frac{1}{C} \sum_i y[i] \log\left((1 + \exp(-x[i]))^{-1}\right) \)</span>
<span class="sd">+ (1-y[i]) \log\left(\frac{\exp(-x[i])}{(1 + \exp(-x[i]))}\right)</span>

<span class="sd">当 :math:`i \in \left\{0, \; \cdots , \; \text{x.nElement}() - 1\right\}` 时，</span>
<span class="sd">math:`y[i] \in \left\{0, \; 1\right\}`。</span>

<span class="sd">    Args:</span>
<span class="sd">权重（Tensor，可选）：为每个类别提供的手动缩放权重。如果提供，必须是一个大小为 `C` 的 Tensor。</span>
<span class="sd">类。如果提供，它必须是一个大小为 `C` 的张量。否则，它就是</span>
<span class="sd">被视为全为 1。</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(N, C)` 其中 `N` 是批大小，`C` 是类别数。</span>
<span class="sd">- 目标：:math:`(N, C)`，标签目标必须与输入具有相同的形状。</span>
<span class="sd">- 输出：标量。如果 :attr:`reduction` 是 ``'none'``，则 :math:`(N)`。</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">重量</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">多标签软边际损失</span><span class="p">(</span>
            <span class="nb">输入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="CosineEmbeddingLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.CosineEmbeddingLoss.html#torch.nn.CosineEmbeddingLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">余弦嵌入损失</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""创建一个测量给定输入张量的损失的准则</span>
<span class="sd">\(x_1\), \(x_2\) 以及一个标签为 \(y\) 的 `Tensor`，其值为 1 或 -1。</span>
<span class="sd">使用 (\(y=1\)) 来最大化两个输入之间的余弦相似度，否则使用 (\(y=-1\))。</span>
<span class="sd">这通常用于学习非线性</span>
<span class="sd">嵌入或半监督学习。</span>

<span class="sd">每个样本的损失函数为：</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{loss}(x, y) =</span>
<span class="sd">        \begin{cases}</span>
<span class="sd">        1 - \cos(x_1, x_2), &amp; \text{if } y = 1 \\</span>
<span class="sd">        \max(0, \cos(x_1, x_2) - \text{margin}), &amp; \text{if } y = -1</span>
<span class="sd">        \end{cases}</span>

<span class="sd">    Args:</span>
<span class="sd">边距（浮点数，可选）：应为从 -1 到 1 的数字，</span>
<span class="sd">建议为 0 到 0.5。如果缺少 :attr:`边距`，则</span>
<span class="sd">默认值为 0。</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>

<span class="sd">形状：</span>
<span class="sd">- 输入 1：:math:`(N, D)` 或 :math:`(D)`，其中 `N` 是批量大小，`D` 是嵌入维度。</span>
<span class="sd">- 输入 2：:math:`(N, D)` 或 :math:`(D)`，与输入 1 形状相同。</span>
<span class="sd">- 目标：:math:`(N)` 或 :math:`()`.</span>
<span class="sd">如果 :attr:`reduction` 是 ``'none'``，则 :math:`(N)`，否则标量。</span>

<span class="sd">示例：</span>

<span class="sd">&gt;&gt;&gt; 损失 = nn.CosineEmbeddingLoss()</span>
<span class="sd">        &gt;&gt;&gt; input1 = torch.randn(3, 5, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; input2 = torch.randn(3, 5, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.ones(3)</span>
<span class="sd">        &gt;&gt;&gt; output = loss(input1, input2, target)</span>
<span class="sd">        &gt;&gt;&gt; output.backward()</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>
    <span class="n">边距</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">边距</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">边距</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入 1</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入 2</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">余弦嵌入损失</span><span class="p">(</span>
            <span class="n">输入 1</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入 2</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="MarginRankingLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.MarginRankingLoss.html#torch.nn.MarginRankingLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距排序损失</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">创建一个衡量给定损失的准则</span>
<span class="sd"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入：:math:`x1`, :math:`x2`, 两个 1D mini-batch 或 0D 张量

翻译：输入：:math:`x1`, :math:`x2`，两个 1D mini-batch 或 0D 张量</font></font></font></span>
<span class="sd">并且一个标签 1D mini-batch 或 0D `Tensor` :math:`y`（包含 1 或-1）。</span>

<span class="sd">如果 \( y = 1 \)，则假定第一个输入应该排名更高</span>
<span class="sd">(具有更大的值)比第二个输入大，反之亦然对于：\( y = -1 \)。</span>

<span class="sd">每个小批量中样本对的损失函数是：</span>

<span class="sd">    .. math::</span>
<span class="sd">损失函数为：\text{loss}(x1, x2, y) = \max(0, -y * (x1 - x2) + \text{margin})</span>

<span class="sd">    Args:</span>
<span class="sd">边距（浮点数，可选）：默认值为 :math:`0`。</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>

<span class="sd">形状：</span>
<span class="sd">- 输入 1：:math:`(N)` 或 :math:`()`，其中 `N` 是批大小。</span>
<span class="sd">- 输入 2：:math:`(N)` 或 :math:`()`, 与输入 1 形状相同。</span>
<span class="sd">- 目标：:math:`(N)` 或 :math:`()`, 与输入形状相同。</span>
<span class="sd">- 输出：标量。如果 :attr:`reduction` 为 ``'none'`` 且输入大小不是 :math:`()`, 则 :math:`(N)`。</span>

<span class="sd">示例：</span>

<span class="sd">&gt;&gt;&gt; 损失 = nn.MarginRankingLoss()</span>
<span class="sd">        &gt;&gt;&gt; input1 = torch.randn(3, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; input2 = torch.randn(3, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.randn(3).sign()</span>
<span class="sd">        &gt;&gt;&gt; output = loss(input1, input2, target)</span>
<span class="sd">        &gt;&gt;&gt; output.backward()</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>
    <span class="n">边距</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">边距</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">边距</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入 1</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入 2</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边缘排序损失</span><span class="p">(</span>
            <span class="n">输入 1</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入 2</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="MultiMarginLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.MultiMarginLoss.html#torch.nn.MultiMarginLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">多边距损失</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_加权 Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">创建一个优化多类分类的 Hinge 损失（基于边界的损失）的准则</span>
<span class="sd">在输入 :math:`x`（一个 2D 的小批量`Tensor`）和</span>
<span class="sd">输出：\(y\)（它是一个目标类别索引的 1D 张量，</span>
<span class="sd">\(0 \leq y \leq \text{x.size}(1)-1\)）：</span>

<span class="sd">对于每个 mini-batch 样本，以 1D 输入\(x\)和标量</span>
<span class="sd">输出\(y\)的损失为：</span>

<span class="sd">    .. math::</span>
<span class="sd">loss(x, y) = \frac{\sum_i \max(0, \text{margin} - x[y] + x[i])^p}{\text{x.size}(0)}</span>

<span class="sd">其中 :math:`i \in \left\{0, \; \cdots , \; \text{x.size}(0) - 1\right\}`</span>
<span class="sd">并且 :math:`i \neq y`。</span>

<span class="sd">可选地，您可以通过传递非等权重的类。</span>
<span class="sd">将一个 1D 的：attr:`权重`张量传入构造函数。</span>

<span class="sd">损失函数随后变为：</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{loss}(x, y) = \frac{\sum_i w[y] * \max(0, \text{margin} - x[y] + x[i])^p}{\text{x.size}(0)}</span>

<span class="sd">    Args:</span>
<span class="sd">p（整数，可选）：具有默认值：math:`1`。：math:`1`和：math:`2`</span>
<span class="sd">仅支持这些值。</span>
<span class="sd">边距（浮点数，可选）：默认值为 :math:`1`。</span>
<span class="sd">权重（Tensor，可选）：为每个类别提供的手动缩放权重。如果提供，必须是一个大小为 `C` 的 Tensor。</span>
<span class="sd">类。如果提供，它必须是一个大小为 `C` 的张量。否则，它就是</span>
<span class="sd">被视为全为 1。</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>

<span class="sd">形状：</span>
<span class="sd">- 输入：:math:`(N, C)` 或 :math:`(C)`，其中 :math:`N` 是批大小，:math:`C` 是类别数。</span>
<span class="sd">- 目标：:math:`(N)` 或 :math:`()`，其中每个值是 :math:`0 \leq \text{targets}[i] \leq C-1`。</span>
<span class="sd">- 输出：标量。如果 :attr:`reduction` 是 ``'none'``，则与目标形状相同。</span>

<span class="sd">示例：</span>

<span class="sd">&gt;&gt;&gt; 损失 = nn.MultiMarginLoss()</span>
<span class="sd">        &gt;&gt;&gt; x = torch.tensor([[0.1, 0.2, 0.4, 0.8]])</span>
<span class="sd">        &gt;&gt;&gt; y = torch.tensor([3])</span>
<span class="sd">        &gt;&gt;&gt; # 0.25 * ((1-(0.8-0.1)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))</span>
<span class="sd">        &gt;&gt;&gt; loss(x, y)</span>
<span class="sd">        tensor(0.32...)</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">p</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>
    <span class="n">边距</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span>
    <span class="n">p</span><span class="p">:</span> <span class="nb">整型</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">p</span><span class="p">:</span> <span class="nb">整型</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">边距</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">重量</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="k">如果</font></font></font></span> <span class="n">p</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</span> <span class="n">p</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">提升</font></font></font></span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"仅支持 p == 1 和 p == 2"</span><span class="p">)</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">权重</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">暗淡</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">提升</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"MultiMarginLoss：期望权重为 None 或 1D 张量，实际得到 D"</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">暗淡</font></font></font></span><span class="p">()</span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">而不是 D</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">边距</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">目标</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">多边际损失</span><span class="p">(</span>
            <span class="nb">输入</span><span class="p">,</span>
            <span class="n">目标</span><span class="p">,</span>
            <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span>
            <span class="n">边距</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</span><span class="p">,</span>
            <span class="n">重量</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重量</span><span class="p">,</span>
            <span class="n">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="TripletMarginLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.TripletMarginLoss.html#torch.nn.TripletMarginLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">三元组边缘损失</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">创建一个根据输入测量三元组损失的准则</span>
<span class="sd">张量：:math:`x1`, :math:`x2`, :math:`x3` 以及一个大于 :math:`0` 的边界值。</span>
<span class="sd">这是用于测量样本之间相对相似度的。一个三元组</span>
<span class="sd">由 `a`、`p` 和 `n` 组成（即 `锚点`、`正例` 和 `负例`）。</span>
<span class="sd">示例分别）。所有输入张量的形状应</span>
<span class="sd"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本翻译为简体中文为：
(N, D).</font></font></font></span>

<span class="sd">《Immersive Translate》中详细描述了距离交换</span>
<span class="sd">基于三元组损失的卷积特征描述符</span>
<span class="sd">V. Balntas, E. Riba 等人</span>

<span class="sd">每个样本在迷你批次的损失函数为：</span>

<span class="sd">    .. math::</span>
<span class="sd">L(a, p, n) = max {d(a_i, p_i) - d(a_i, n_i) + 边界, 0}</span>


<span class="sd">哪里</span>

<span class="sd">    .. math::</span>
<span class="sd">        d(x_i, y_i) = \left\lVert {\bf x}_i - {\bf y}_i \right\rVert_p</span>

<span class="sd">范数是使用指定的 p 值计算的，并添加了一个小的常数 :math:`\varepsilon` 以提高数值稳定性。</span>
<span class="sd">有关更多信息，请参阅 :class:`~torch.nn.TripletMarginWithDistanceLoss`，它计算了</span>

<span class="sd">有关更多信息，请参阅 :class:`~torch.nn.TripletMarginWithDistanceLoss`，它计算了</span>
<span class="sd">使用自定义距离函数对输入张量进行三元组边缘损失。</span>

<span class="sd">    Args:</span>
<span class="sd">边缘（浮点数，可选）：默认：:math:`1`。</span>
<span class="sd">p（整数，可选）：成对距离的范数度。默认：:math:`2`。</span>
<span class="sd">eps（浮点数，可选）：用于数值稳定性的小常数。默认：:math:`1e-6`。</span>
<span class="sd">交换（bool，可选）：距离交换在论文中有详细描述</span>
<span class="sd">《使用三元组损失学习浅层卷积特征描述符》</span>
<span class="sd">由 V. Balntas，E. Riba 等人撰写。默认：``False``。</span>
<span class="sd">size_average（布尔值，可选）：已弃用（参见：attr:`reduction`）。默认情况下，</span>
<span class="sd">批量中的每个损失元素的平均值。注意，对于某些损失，每个样本可能有多个元素。如果将字段 :attr:`size_average` 设置为 ``False``，则损失将改为对每个小批量求和。当 reduce 为 ``False`` 时忽略。默认：``True``</span>
<span class="sd">一些损失函数，每个样本可能有多个元素。如果字段 :attr:`size_average`</span>
<span class="sd">设置为“False”，损失将分别对每个小批量进行求和。忽略</span>
<span class="sd">当 :attr:`reduce` 为 ``False`` 时。默认：``True``</span>
<span class="sd">减少（布尔值，可选）：已弃用（见：attr：`reduction`）。默认情况下，</span>
<span class="sd">损失在每个小批量上的观测值被平均或求和</span>
<span class="sd">在：attr:`size_average`。当：attr:`reduce`为``False``时，返回每个样本的损失</span>
<span class="sd">批量元素而不是，并忽略：attr:`size_average`。默认：``True``</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">``'sum'``：输出将进行求和。注意：:attr:`size_average`</span>
<span class="sd">和 :attr:`reduce` 正在弃用，在此期间，</span>
<span class="sd">指定这两个参数中的任何一个将覆盖 :attr:`reduction`。默认：``'mean'``</span>

<span class="sd">形状：</span>
<span class="sd">输入：:math:`(N, D)` 或 :math:`(D)`，其中 :math:`D` 是向量维度。</span>
<span class="sd">输出：如果 :attr:`reduction` 是 ``'none'``，则形状为 :math:`(N)` 的张量。</span>
<span class="sd">输入形状为 :math:`(N, D)`；否则为标量。</span>

<span class="sd">示例：</span>

<span class="sd">    &gt;&gt;&gt; triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-7)</span>
<span class="sd">    &gt;&gt;&gt; anchor = torch.randn(100, 128, requires_grad=True)</span>
<span class="sd">    &gt;&gt;&gt; positive = torch.randn(100, 128, requires_grad=True)</span>
<span class="sd">    &gt;&gt;&gt; negative = torch.randn(100, 128, requires_grad=True)</span>
<span class="sd">    &gt;&gt;&gt; output = triplet_loss(anchor, positive, negative)</span>
<span class="sd">    &gt;&gt;&gt; output.backward()</span>

<span class="sd">学习使用三元组损失进行浅层卷积特征描述符</span>
<span class="sd">        https://bmva-archive.org.uk/bmvc/2016/papers/paper119/index.html</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">p</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">eps</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">交换</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>
    <span class="n">边距</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span>
    <span class="n">p</span><span class="p">:</span> <span class="nb">浮点数</span>
    <span class="n">eps</span><span class="p">:</span> <span class="nb">浮点数</span>
    <span class="n">交换</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔类型</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">边距</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">p</span><span class="p">:</span> <span class="nb">浮点数</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">浮点数</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">交换</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔类型</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">,</span>
        <span class="n">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span> <span class="o"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">≤</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">提升</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">TripletMarginLoss：期望间隔大于 0，得到</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">而不是</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">边距</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">交换</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">交换</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">锚点</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">正的</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">负的</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">三重边界损失</span><span class="p">(</span>
            <span class="n">锚点</span><span class="p">,</span>
            <span class="n">正的</span><span class="p">,</span>
            <span class="n">负的</span><span class="p">,</span>
            <span class="n">边距</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</span><span class="p">,</span>
            <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span>
            <span class="n">交换</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">交换</span><span class="p">,</span>
            <span class="n">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="TripletMarginWithDistanceLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.TripletMarginWithDistanceLoss.html#torch.nn.TripletMarginWithDistanceLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">三元组距离损失</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">创建一个衡量输入三元组损失的准则</span>
<span class="sd">张量：:math:`a`、:math:`p` 和 :math:`n`（表示锚点）</span>
<span class="sd">正负示例，以及非负示例，分别），</span>
<span class="sd">实值函数（距离函数）用于计算关系</span>
<span class="sd">在锚点和正例（“正距离”）之间</span>
<span class="sd">锚点和负例（"负距离"）。</span>

<span class="sd">未归一化的损失（即，将：attr:`reduction` 设置为 ``'none'``）</span>
<span class="sd">可以描述为：</span>

<span class="sd">    .. math::</span>
<span class="sd">        \ell(a, p, n) = L = \{l_1,\dots,l_N\}^\top, \quad</span>
<span class="sd">        l_i = \max \{d(a_i, p_i) - d(a_i, n_i) + {\rm margin}, 0\}</span>

<span class="sd">其中 :math:`N` 是批大小；:math:`d` 是一个非负的实值函数</span>
<span class="sd">量化两个张量的接近程度，称为：:attr:`距离函数`</span>
<span class="sd">并且 :math:`margin` 是一个非负的边界，表示最小差值</span>
<span class="sd">在正负距离之间，这是损失所需的</span>
<span class="sd">输入张量各有 \(N\) 个元素，可以是任何形状。</span>
<span class="sd">那个距离函数可以处理的。</span>

<span class="sd">如果 :attr:`reduction` 不是 ``'none'``</span>
<span class="sd">（默认 ``'mean'``），则：</span>

<span class="sd">    .. math::</span>
<span class="sd">        \ell(x, y) =</span>
<span class="sd">        \begin{cases}</span>
<span class="sd">\operatorname{mean}(L), &amp;  \text{如果 reduction} = \text{`mean';}\\</span>
<span class="sd">\operatorname{sum}(L)，&amp;  \text{如果} \text{reduction} = \text{`sum'}.</span>
<span class="sd">        \end{cases}</span>

<span class="sd">参见 :class:`~torch.nn.TripletMarginLoss`，它使用 :math:`l_p` 距离作为距离函数来计算输入张量的三元组损失。</span>
<span class="sd">距离函数 (Callable, 可选): 一个非负的、实值函数，用于量化两个张量之间的接近程度。如果未指定，</span>

<span class="sd">    Args:</span>
<span class="sd">距离函数 (Callable, 可选): 一个非负的、实值函数，用于量化两个张量之间的接近程度。如果未指定，</span>
<span class="sd">距离函数 (Callable, 可选): 一个非负的、实值函数，用于量化两个张量之间的接近程度。如果未指定，</span>
<span class="sd">`nn.PairwiseDistance` 将被使用。默认：`None`</span>
<span class="sd">(浮点数，可选)：表示最小差异的非负边距</span>
<span class="sd">在正负距离之间，使得损失为 0。</span>
<span class="sd">边际惩罚那些负例不够远离的情况</span>
<span class="sd">锚点相对于正例。默认值：:math:`1`。</span>
<span class="sd">交换（bool，可选）：是否使用论文中描述的距离交换</span>
<span class="sd">《使用三元组损失学习浅层卷积特征描述符》</span>
<span class="sd">由 V. Balntas, E. Riba 等人所著。如果为 True，并且正例更接近于</span>
<span class="sd">负面示例比锚点更差，交换了正面示例和锚点</span>
<span class="sd">损失计算。默认：``False``。</span>
<span class="sd">reduction (str, 可选): 指定应用于输出的（可选）缩减操作：</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``：输出总和将除以输出元素的数量，</span>
<span class="sd">输出元素，``'sum'``：输出将被求和。默认：``'mean'``。</span>


<span class="sd">形状：</span>
<span class="sd">输入：:math:`(N, *)` 其中 :math:`*` 代表任意数量的额外维度</span>
<span class="sd">支持距离函数。</span>
<span class="sd">输出：如果 :attr:`reduction` 是 ``'none'``，则形状为 :math:`(N)` 的张量，或者是一个标量</span>
<span class="sd">否则。</span>

<span class="sd">示例：</span>

<span class="sd">&gt;&gt;&gt; # 初始化嵌入</span>
<span class="sd">    &gt;&gt;&gt; embedding = nn.Embedding(1000, 128)</span>
<span class="sd">    &gt;&gt;&gt; anchor_ids = torch.randint(0, 1000, (1,))</span>
<span class="sd">    &gt;&gt;&gt; positive_ids = torch.randint(0, 1000, (1,))</span>
<span class="sd">    &gt;&gt;&gt; negative_ids = torch.randint(0, 1000, (1,))</span>
<span class="sd">&gt;&gt;&gt; 锚点 = 嵌入(锚点 ID)</span>
<span class="sd">&gt;&gt;&gt; 正面 = 嵌入(正面 ID)</span>
<span class="sd">&gt;&gt;&gt; 负面 = 嵌入(负面 ID)</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 内置距离函数</span>
<span class="sd">    &gt;&gt;&gt; triplet_loss = \</span>
<span class="sd">    &gt;&gt;&gt;     nn.TripletMarginWithDistanceLoss(distance_function=nn.PairwiseDistance())</span>
<span class="sd">    &gt;&gt;&gt; output = triplet_loss(anchor, positive, negative)</span>
<span class="sd">    &gt;&gt;&gt; output.backward()</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 自定义距离函数</span>
<span class="sd">    &gt;&gt;&gt; def l_infinity(x1, x2):</span>
<span class="sd">    &gt;&gt;&gt;     return torch.max(torch.abs(x1 - x2), dim=1).values</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # xdoctest: +SKIP("FIXME: 两次调用反向传播")</span>
<span class="sd">    &gt;&gt;&gt; triplet_loss = (</span>
<span class="sd">    &gt;&gt;&gt;     nn.TripletMarginWithDistanceLoss(distance_function=l_infinity, margin=1.5))</span>
<span class="sd">    &gt;&gt;&gt; output = triplet_loss(anchor, positive, negative)</span>
<span class="sd">    &gt;&gt;&gt; output.backward()</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 自定义距离函数（Lambda）</span>
<span class="sd">    &gt;&gt;&gt; triplet_loss = (</span>
<span class="sd">    &gt;&gt;&gt;     nn.TripletMarginWithDistanceLoss(</span>
<span class="sd">    &gt;&gt;&gt;         distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)))</span>
<span class="sd">    &gt;&gt;&gt; output = triplet_loss(anchor, positive, negative)</span>
<span class="sd">    &gt;&gt;&gt; output.backward()</span>

<span class="sd">参考文献：</span>
<span class="sd">V. Balntas 等人：使用三元组损失学习浅层卷积特征描述符：</span>
<span class="sd">        https://bmva-archive.org.uk/bmvc/2016/papers/paper119/index.html</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">交换</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>
    <span class="n">边距</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span>
    <span class="n">交换</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔类型</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">距离函数</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可调用</font></font></font></span><span class="p">[[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">]]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">边距</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">浮点数</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">交换</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔类型</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">,</span>
        <span class="n">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减少</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span> <span class="o"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">≤</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">提升</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">TripletMarginWithDistanceLoss：期望间隔大于 0，得到</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</font></font></font></span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">而不是</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">距离函数</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可调用</font></font></font></span><span class="p">[[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">距离函数</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离函数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">否则</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对距</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">边距</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">交换</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">交换</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">锚点</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">正的</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">负的</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">:</span>
        <span class="k">返回</font></font></font></span> <span class="n">F</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">三重边距与距离损失</span><span class="p">(</span>
            <span class="n">锚点</span><span class="p">,</span>
            <span class="n">正的</span><span class="p">,</span>
            <span class="n">负的</span><span class="p">,</span>
            <span class="n">距离函数</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离函数</span><span class="p">,</span>
            <span class="n">边距</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">边距</span><span class="p">,</span>
            <span class="n">交换</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">交换</span><span class="p">,</span>
            <span class="n">缩减</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="CTCLoss"><a class="viewcode-back" href="../../../../generated/torch.nn.CTCLoss.html#torch.nn.CTCLoss">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</span> <span class="nc">CTCLoss</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">“连接主义时序分类损失”</span>

<span class="sd">计算连续（未分割）时间序列与目标序列之间的损失。CTCLoss 对输入到目标的所有可能的对齐概率进行求和，产生一个可微分的损失值。</span>
<span class="sd">对输入到目标的所有可能的对齐概率进行求和，产生一个可微分的损失值。</span>
<span class="sd">针对每个输入节点。输入与目标的对齐假设为“多对一”，</span>
<span class="sd">限制目标序列的长度，使其必须小于等于输入长度。</span>

<span class="sd">    Args:</span>
<span class="sd">空白（int，可选）：空白标签。默认为 0。</span>
<span class="sd">reduction（字符串，可选）：指定应用于输出的缩减</span>
<span class="sd">``'none'``：不应用缩减，``'mean'``：应用平均值缩减，``'sum'``：应用总和缩减</span>
<span class="sd">``'mean'``: 输出的损失将除以目标长度，然后取批次的平均值，</span>
<span class="sd">然后取批次的平均值，``'sum'``：输出损失将求和。</span>
<span class="sd">默认: ``'mean'``</span>
<span class="sd">        zero_infinity (bool, optional):</span>
<span class="sd">是否将无穷大的损失及其关联的梯度置零。</span>
<span class="sd">默认：``False``</span>
<span class="sd">无穷大的损失主要发生在输入太短时。</span>
<span class="sd">与目标对齐。</span>

<span class="sd">形状：</span>
<span class="sd">- 对数概率：大小为 :math:`(T, N, C)` 或 :math:`(T, C)` 的张量，</span>
<span class="sd">其中 :math:`T = \text{输入长度}`，</span>
<span class="sd">math:`N = \text{批大小}`，以及</span>
<span class="sd">math:`C = \text{类别数（包括空白）}`。</span>
<span class="sd">输出对数的概率（例如，使用</span>
<span class="sd">:func:`torch.nn.functional.log_softmax`)</span>
<span class="sd">目标：大小为 :math:`(N, S)` 的张量</span>
<span class="sd">（目标长度之和）</span>
<span class="sd">其中 :math:`N = \text{批大小}` 和</span>
<span class="sd">\(S = \text{max target length, if shape is } (N, S)\)</span>
<span class="sd">它代表目标序列。目标序列中的每个元素是一个类别索引。目标索引不能为空（默认=0）</span>
<span class="sd">在 \((N, S)\) 形式中，目标序列被填充到</span>
<span class="sd">在 \((N, S)\) 形式中，目标序列被填充到</span>
<span class="sd">最长序列的长度，并堆叠。</span>
<span class="sd">在 :math:`(\operatorname{sum}(\text{target\_lengths}))` 形式下，</span>
<span class="sd">假设目标长度未填充，</span>
<span class="sd">在 1 个维度内连接。</span>
<span class="sd">- 输入长度：大小为 :math:`(N)` 或 :math:`()` 的元组或张量</span>
<span class="sd">`其中 :math:`N = \text{批大小}`。它表示长度为`</span>
<span class="sd">输入（必须每个都：数学`≤ T`）。长度已指定</span>
<span class="sd">对于每个序列，在假设序列下实现掩码</span>
<span class="sd">都填充到相同的长度。</span>
<span class="sd">- 目标长度：大小为 :math:`(N)` 或 :math:`()` 的元组或张量，</span>
<span class="sd">其中 :math:`N = \text{批大小}`。它表示目标长度。</span>
<span class="sd">为每个序列指定长度以实现掩码。</span>
<span class="sd">假设序列被填充到相同的长度。如果目标形状是</span>
<span class="sd">math:`(N,S)`，则目标长度实际上是停止索引</span>
<span class="sd">math:`s_n` 对于每个目标序列，使得 ``target_n = targets[n,0:s_n]`` 对于</span>
<span class="sd">批处理中的每个目标。长度必须每个都小于等于 :math:`S`</span>
<span class="sd">如果目标以 1 维张量形式给出，该张量是各个目标的拼接，则目标长度之和必须等于张量的总长度。</span>
<span class="sd">如果目标长度之和等于张量的总长度，则目标以 1 维张量形式给出。</span>
<span class="sd">- 输出：如果：attr:`reduction` 是 ``'mean'``（默认）或 ``'sum'``，则为标量。如果：attr:`reduction` 是 ``'none'``，则为 (N, *) 形状</span>
<span class="sd">如果输入是批处理，则如果 `:attr:`reduction` 是 `'none'`，则为 :math:`(N)`。</span>
<span class="sd">如果输入未分批，则为 :math:`()`，其中 :math:`N` 为批大小。</span>

<span class="sd">示例：</span>

<span class="sd">&gt;&gt;&gt; 目标需要填充</span>
<span class="sd">&gt;&gt;&gt; T = 50      # 输入序列长度</span>
<span class="sd">&gt;&gt;&gt; C = 20      # 类别数量（包括空白）</span>
<span class="sd">&gt;&gt;&gt; N = 16      # 批处理大小</span>
<span class="sd">&gt;&gt;&gt; S = 30      # 批处理中最长目标序列的长度（填充长度）</span>
<span class="sd">&gt;&gt;&gt; S_min = 10  # 最小目标长度，用于演示</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 初始化随机输入向量批次，大小为 (T,N,C)</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 初始化随机目标批次（0 = 空白，1:C = 类别）</span>
<span class="sd">        &gt;&gt;&gt; target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)</span>
<span class="sd">...</span>
<span class="sd">        &gt;&gt;&gt; input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)</span>
<span class="sd">        &gt;&gt;&gt; target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)</span>
<span class="sd">        &gt;&gt;&gt; ctc_loss = nn.CTCLoss()</span>
<span class="sd">        &gt;&gt;&gt; loss = ctc_loss(input, target, input_lengths, target_lengths)</span>
<span class="sd">        &gt;&gt;&gt; loss.backward()</span>
<span class="sd">...</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 目标是取消填充</span>
<span class="sd">&gt;&gt;&gt; T = 50      # 输入序列长度</span>
<span class="sd">&gt;&gt;&gt; C = 20      # 类别数量（包括空白）</span>
<span class="sd">&gt;&gt;&gt; N = 16      # 批处理大小</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 初始化随机输入向量批次，大小为 (T,N,C)</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()</span>
<span class="sd">        &gt;&gt;&gt; input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 初始化随机目标批次（0 = 空白，1:C = 类别）</span>
<span class="sd">        &gt;&gt;&gt; target_lengths = torch.randint(low=1, high=T, size=(N,), dtype=torch.long)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.randint(low=1, high=C, size=(sum(target_lengths),), dtype=torch.long)</span>
<span class="sd">        &gt;&gt;&gt; ctc_loss = nn.CTCLoss()</span>
<span class="sd">        &gt;&gt;&gt; loss = ctc_loss(input, target, input_lengths, target_lengths)</span>
<span class="sd">        &gt;&gt;&gt; loss.backward()</span>
<span class="sd">...</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 目标是取消填充和取消批处理（实际上 N=1）</span>
<span class="sd">&gt;&gt;&gt; T = 50      # 输入序列长度</span>
<span class="sd">&gt;&gt;&gt; C = 20      # 类别数量（包括空白）</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 初始化随机输入向量批次，大小为 *size = (T,C)</span>
<span class="sd">&gt;&gt;&gt; # xdoctest: +SKIP("FIXME: 错误在 doctest 中")</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(T, C).log_softmax(1).detach().requires_grad_()</span>
<span class="sd">        &gt;&gt;&gt; input_lengths = torch.tensor(T, dtype=torch.long)</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 初始化随机目标批次（0 = 空白，1:C = 类别）</span>
<span class="sd">        &gt;&gt;&gt; target_lengths = torch.randint(low=1, high=T, size=(), dtype=torch.long)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.randint(low=1, high=C, size=(target_lengths,), dtype=torch.long)</span>
<span class="sd">        &gt;&gt;&gt; ctc_loss = nn.CTCLoss()</span>
<span class="sd">        &gt;&gt;&gt; loss = ctc_loss(input, target, input_lengths, target_lengths)</span>
<span class="sd">        &gt;&gt;&gt; loss.backward()</span>

<span class="sd">参考文献：</span>
<span class="sd">A. Graves 等人：连接主义时序分类：</span>
<span class="sd">使用循环神经网络对未分割序列数据进行标注：</span>
<span class="sd">        https://www.cs.toronto.edu/~graves/icml_2006.pdf</span>

<span class="sd">注意：</span>
<span class="sd">为了使用 CuDNN，必须满足以下条件：:attr:`targets`必须为</span>
<span class="sd">连接格式，所有:attr:`input_lengths`必须为`T`。:math:`blank=0`，</span>
<span class="sd">attr:`target_lengths` :math:`\leq 256`，整数参数必须是 dtype :attr:`torch.int32`类型。</span>
<span class="sd">的。</span>

<span class="sd">常规实现使用（在 PyTorch 中更常见）的 `torch.long` 数据类型。</span>


<span class="sd">注意：</span>
<span class="sd">在某些情况下，使用 CUDA 后端和 CuDNN 时，此运算符</span>
<span class="sd">可以选择一个非确定性算法来提高性能。如果这</span>
<span class="sd">不可取，您可以尝试将操作设置为确定性（可能</span>
<span class="sd">会有性能成本）通过设置 `torch.backends.cudnn.deterministic =</span>
<span class="sd">True`。</span>
<span class="sd">请参阅：doc:`/notes/randomness` 中的笔记以获取背景信息。</span>
<span class="sd">"源代码"</span>
    <span class="n">常量</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"空白"</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"减少"</span><span class="p">]</span>
    <span class="n">空白</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">整型</span>
    <span class="n">零无穷</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔类型</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">空白</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">整型</font></font></font></span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">平均值</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">零无穷</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔类型</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">假</span>
    <span class="p">):</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缩减</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">空白</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">空白</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">零无穷</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">零无穷</span>

    <span class="k">def</span> <span class="nf">前向</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">log_probs</span><span class="p">:</span> <span class="n">张量</span><span class="p">,</span>
        <span class="n">targets</span><span class="p">:</span> <span class="n">张量</span><span class="p">,</span>
        <span class="n">input_lengths</span><span class="p">:</span> <span class="n">张量</span><span class="p">,</span>
        <span class="n">目标长度</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">张量</span><span class="p">:</span>
        <span class="k">返回</span> <span class="n">F</span><span class="o">.</span><span class="n">ctc_loss</span><span class="p">(</span>
            <span class="n">log_probs</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">input_lengths</span><span class="p">,</span>
            <span class="n">目标长度</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">空白</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">缩减</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">零无穷</span><span class="p">,</span>
        <span class="p">)</span></div>


<span class="c1"># TODO: L1HingeEmbeddingCriterion</span>
<span class="c1"># TODO: 均方误差准则权重</span>
<span class="c1"># TODO: 简单准则类</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>© 版权所有 PyTorch 贡献者。</p>
  </div>
    
      <div>使用 Sphinx 构建，并使用 Read the Docs 提供的主题。</div>
     

</footer>

          </div>
<script>

var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/clipboard.min.js"></script>
         <script src="../../../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script="" type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0">


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>文档</h2>
          <p>查看 PyTorch 的全面开发者文档</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">查看文档</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>教程</h2>
          <p>深入了解初学者和高级开发者的教程</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">查看教程</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>资源</h2>
          <p>查找开发资源，获取您的疑问解答</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">查看资源</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">开始使用</a></li>
            <li><a href="https://pytorch.org/features">功能</a></li>
            <li><a href="https://pytorch.org/ecosystem">生态系统</a></li>
            <li><a href="https://pytorch.org/blog/">博客</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">贡献</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">资源</a></li>
            <li><a href="https://pytorch.org/tutorials">教程</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">文档</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">讨论</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github 问题</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">品牌指南</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">保持更新</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">推特</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">领英</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch 播客</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">苹果</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">谷歌</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">亚马逊</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">条款</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">隐私</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© 版权所有 Linux 基金会。PyTorch 基金会是 Linux 基金会的一个项目。有关 PyTorch 基金会的网站使用条款、商标政策以及其他适用政策，请参阅 www.linuxfoundation.org/policies/。PyTorch 基金会支持 PyTorch 开源项目，该项目已被确立为 LF Projects, LLC 的 PyTorch 项目系列。有关适用于 PyTorch 项目系列 LF Projects, LLC 的政策，请参阅 www.lfprojects.org/policies/。</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">为了分析流量并优化您的体验，我们在本网站上使用 cookies。通过点击或导航，您同意允许我们使用 cookies。作为本网站的当前维护者，适用 Facebook 的 Cookies 政策。了解更多信息，包括关于可用控制的信息：Cookies 政策。</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg" width="16" height="16">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>学习</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">开始使用</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">教程</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">学习基础知识</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch 食谱</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">PyTorch 入门 - YouTube 系列</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>生态系统</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">工具</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">社区</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">论坛</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">开发者资源</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">贡献者奖项 - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>边缘</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">关于 PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch 文档</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>文档</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch 领域</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>博客 &amp; 新闻</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch 博客</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">社区博客</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">视频</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">社区故事</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">活动</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">通讯</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>关于</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch 基金会</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">管理委员会</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">云信用计划</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">技术咨询委员会</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">员工</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">联系我们</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>

</body></html>