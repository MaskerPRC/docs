<!DOCTYPE html>
<html lang="zh_CN">
<head>
  <meta charset="UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.nn.parallel.distributed — PyTorch main documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/nn/parallel/distributed.html">
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css">
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/sphinx-dropdown.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/panels-bootstrap.min.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/css/jit.css" type="text/css">
  <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css">
    <link rel="index" title="Index" href="../../../../genindex.html">
    <link rel="search" title="Search" href="../../../../search.html">

<!--
  Search engines should not index the main version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head><body class="pytorch-body"><div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">学习</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class="dropdown-title">开始使用</span>
                  <p>在本地运行 PyTorch 或快速开始使用支持的云平台之一</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">教程</span><p></p>
                  <p>PyTorch 教程中有什么新内容</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">学习基础知识</span><p></p>
                  <p>熟悉 PyTorch 的概念和模块</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch 食谱</span><p></p>
                  <p>小而全，即用即部署的 PyTorch 代码示例</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">PyTorch 入门 - YouTube 系列教程</span><p></p>
                  <p>通过我们引人入胜的 YouTube 教程系列掌握 PyTorch 基础知识</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">生态系统</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">工具</span><p></p>
                  <p>了解 PyTorch 生态系统中的工具和框架</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">社区</span>
                  <p>加入 PyTorch 开发者社区，贡献、学习并获得问题解答</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">论坛</span>
                  <p>讨论 PyTorch 代码、问题、安装、研究的地方</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">开发者资源</span>
                  <p>查找资源并获得问题解答</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">贡献者奖项 - 2024</span><p></p>
                  <p>本年 PyTorch 会议揭晓获奖者</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">边缘</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">关于 PyTorch Edge</span><p></p>
                  <p>为边缘设备构建创新且注重隐私的 AI 体验</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span><p></p>
                  <p>针对移动和边缘设备实现端到端推理能力的解决方案</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch 文档</span><p></p>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">文档</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span><p></p>
                  <p>查阅文档以获取全面指导，了解如何使用 PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch 领域</span><p></p>
                  <p>阅读 PyTorch 领域文档，了解更多关于特定领域库的信息</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">博客与新闻</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch 博客</span><p></p>
                  <p>跟上最新的技术新闻和动态</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">社区博客</span><p></p>
                  <p>PyTorch 生态系统中的故事</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">视频</span><p></p>
                  <p>了解最新的 PyTorch 教程、新内容等</p>
                </a><a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">社区故事</span><p></p>
                  <p>了解我们的社区如何使用 PyTorch 解决真实、日常的机器学习问题</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">活动</span><p></p>
                  <p>查找活动、网络研讨会和播客</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">通讯</span><p></p>
                  <p>跟踪最新更新</p>
                </a>
            </div>
          </div></li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">关于</a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch 基金会</span><p></p>
                  <p>了解更多关于 PyTorch 基金会的信息</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">管理委员会</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">云信用计划</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">技术顾问委员会</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">员工</span><p></p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">联系我们</span><p></p>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">成为会员</a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>



   

    

    <div class="table-of-contents-link-wrapper">
      <span>目录</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="https://pytorch.org/docs/versions.html">主页 (2.7.0+cpu ) ▼</a>
    </div>
    <div id="searchBox">
    <div class="searchbox" id="googleSearchBox">
      <script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
      <div class="gcse-search"></div>
    </div>
    <div id="sphinxSearchBox" style="display: none;">
      <div role="search">
        <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
          <input type="text" name="q" placeholder="Search Docs">
          <input type="hidden" name="check_keywords" value="yes">
          <input type="hidden" name="area" value="default">
        </form>
      </div>
    </div>
  </div>
  <form id="searchForm">
    <label style="margin-bottom: 1rem">
      <input type="radio" name="searchType" value="google" checked="">Google 搜索</label>
    <label style="margin-bottom: 1rem">
      <input type="radio" name="searchType" value="sphinx">经典搜索</label>
  </form>

  <script>
     document.addEventListener('DOMContentLoaded', function() {
      const searchForm = document.getElementById('searchForm');
      const googleSearchBox = document.getElementById('googleSearchBox');
      const sphinxSearchBox = document.getElementById('sphinxSearchBox');
      // Function to toggle search box visibility
      function toggleSearchBox(searchType) {
        googleSearchBox.style.display = searchType === 'google' ? 'block' : 'none';
        sphinxSearchBox.style.display = searchType === 'sphinx' ? 'block' : 'none';
      }
      // Determine the default search type
      let defaultSearchType;
      const currentUrl = window.location.href;
      if (currentUrl.startsWith('https://pytorch.org/docs/stable')) {
        // For the stable documentation, default to Google
        defaultSearchType = localStorage.getItem('searchType') || 'google';
      } else {
        // For any other version, including docs-preview, default to Sphinx
        defaultSearchType = 'sphinx';
      }
      // Set the default search type
      document.querySelector(`input[name="searchType"][value="${defaultSearchType}"]`).checked = true;
      toggleSearchBox(defaultSearchType);
      // Event listener for changes in search type
      searchForm.addEventListener('change', function(event) {
        const selectedSearchType = event.target.value;
        localStorage.setItem('searchType', selectedSearchType);
        toggleSearchBox(selectedSearchType);
      });
      // Set placeholder text for Google search box
      window.onload = function() {
        var placeholderText = "Search Docs";
        var googleSearchboxText = document.querySelector("#gsc-i-id1");
        if (googleSearchboxText) {
          googleSearchboxText.placeholder = placeholderText;
          googleSearchboxText.style.fontFamily = 'FreightSans';
          googleSearchboxText.style.fontSize = "1.2rem";
          googleSearchboxText.style.color = '#262626';
        }
      };
    });
  </script>

          </div>

          

<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/_modules/torch/nn/parallel/distributed.html">您正在查看不稳定开发者预览文档。请点击此处查看最新稳定版本的文档。</a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">社区</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/build_ci_governance.html">PyTorch 治理 | 构建 + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/contribution_guide.html">PyTorch 贡献指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/design.html">PyTorch 设计哲学</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/governance.html">PyTorch 治理 | 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/persons_of_interest.html">PyTorch 治理 | 维护者</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">开发者笔记</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/amp_examples.html">自动混合精度示例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/autograd.html">Autograd 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/broadcasting.html">广播语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cpu_threading_torchscript_inference.html">CPU 多线程和 TorchScript 推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cuda.html">CUDA 语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/custom_operators.html">PyTorch 自定义算子页面</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/ddp.html">分布式数据并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/extending.html">扩展 PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/extending.func.html">使用 autograd.Function 扩展 torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/faq.html">常见问题解答</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/fsdp.html">FSDP 笔记</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/get_start_xpu.html">在 Intel GPU 上入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/gradcheck.html">Gradcheck 机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/hip.html">HIP (ROCm)语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/large_scale_deployments.html">大规模部署功能</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/libtorch_stable_abi.html">LibTorch 稳定 ABI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/modules.html">模块</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/mps.html">MPS 后端</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/multiprocessing.html">多进程最佳实践</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/numerical_accuracy.html">数值精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/randomness.html">可重复性</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/serialization.html">序列化语义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/windows.html">Windows 常见问题解答</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">语言绑定</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_attributes.html">索引属性</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_view.html">张量视图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../accelerator.html">torch.accelerator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpu.html">torch.cpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_cuda_memory.html">理解 CUDA 内存使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_cuda_memory.html#generating-a-snapshot">生成快照</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_cuda_memory.html#using-the-visualizer">使用可视化工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_cuda_memory.html#snapshot-api-reference">摄像头 API 参考</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mps.html">torch.mps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../xpu.html">torch.xpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mtia.html">torch.mtia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mtia.memory.html">torch.mtia.memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../meta.html">元设备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../export.html">torch.export</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.tensor.html">torch.distributed.tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.fsdp.fully_shard.html">torch.distributed.fsdp.fully_shard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.pipelining.html">torch.distributed.pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.compiler.html">torch.compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../func.html">torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fx.experimental.html">torch.fx.experimental</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../signal.html">torch.signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.attention.html">torch.nn.attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../complex_numbers.html">复数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ddp_comm_hooks.html">DDP 通信钩子</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../quantization.html">量化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rpc.html">分布式 RPC 框架</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../masked.html">torch.masked</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../size.html">torch.Size</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils.html">torch.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deterministic.html">torch.utils.deterministic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../module_tracker.html">torch.utils.module_tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../type_info.html">类型信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../named_tensor.html">命名张量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../name_inference.html">命名张量操作覆盖率</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../future_mod.html">torch.__future__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../logging.html">torch._logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_environment_variables.html">Torch 环境变量</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">库</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">火炬推荐</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/ao">torchao</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        文档 &gt;</li>

        
          <li>模块代码 &gt;</li>
        
          <li><a href="../../../torch.html">torch</a> &gt;</li>
        
      <li>torch.nn.parallel.distributed</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">快捷键</div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>torch.nn.parallel.distributed 的源代码</font></font></font></h1><div class="highlight"><pre><span></span><span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># mypy: 允许未类型化定义</span>
<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">复制</span>
<span class="kn">导入</span> <span class="nn">functools</span>
<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">检查</span>
<span class="kn">导入</span> <span class="nn">itertools</span>
<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">记录日志</span>
<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">操作系统</span>
<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">系统</span>
<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">警告</span>
<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">弱引用</span>
<span class="kn">来自</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">集合</font></font></font></span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">双端队列</span>
<span class="kn">来自</font></font></font></span> <span class="nn">contextlib</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="n">contextmanager</span>
<span class="kn">来自</font></font></font></span> <span class="nn">dataclasses</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">数据类</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字段</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是数据类</span>
<span class="kn">来自</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">枚举</font></font></font></span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">自动</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">枚举</span>
<span class="kn">来自</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">打字</font></font></font></span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">任意</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可调用</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类型检查</span>

<span class="kn">导入</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</span>
<span class="kn">导入</font></font></font></span> <span class="nn">torch.distributed</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">作为</span> <span class="nn">dist</span>
<span class="kn">来自</font></font></font></span> <span class="nn">torch._utils</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="n">_get_device_index</span>
<span class="kn">来自</font></font></font></span> <span class="nn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">torch 自动微分</font></font></font></span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">函数</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">变量</span>
<span class="kn">来自</font></font></font></span> <span class="nn">torch.distributed.algorithms.join</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">加入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可加入的</span><span class="p">,</span> <span class="n">JoinHook</span>
<span class="kn">来自</font></font></font></span> <span class="nn">torch.nn.modules</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span>
<span class="kn">来自</font></font></font></span> <span class="nn">torch.nn.parallel.scatter_gather</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">收集</span><span class="p">,</span> <span class="n">scatter_kwargs</span>
<span class="kn">来自</font></font></font></span> <span class="nn">torch.utils._pytree</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">树扁平化</span><span class="p">,</span> <span class="n">tree_unflatten</span>


<span class="n">RPC 可用</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">假</span>
<span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是否可用</span><span class="p">():</span>
    <span class="kn">来自</font></font></font></span> <span class="nn">torch.distributed.distributed_c10d</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="p">(</span>
        <span class="n">获取默认组</span><span class="p">,</span>
        <span class="n">_rank_not_in_group</span><span class="p">,</span>
        <span class="n">ReduceOp</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="kn">来自</font></font></font></span> <span class="nn">torch.distributed.utils</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="p">(</span>
        <span class="n">_alloc_storage</span><span class="p">,</span>
        <span class="n">_cast_forward_inputs</span><span class="p">,</span>
        <span class="n">_free_storage</span><span class="p">,</span>
        <span class="n">_sync_module_states</span><span class="p">,</span>
        <span class="n">_to_kwargs</span><span class="p">,</span>
        <span class="n">在各个流程中验证参数形状</span><span class="p">,</span>
    <span class="p">)</span>
<span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离</font></font></font></span><span class="o">.</span><span class="n">rpc</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是否可用</span><span class="p">():</span>
    <span class="n">RPC 可用</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
    <span class="kn">来自</font></font></font></span> <span class="nn">torch.distributed.rpc</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="n">RRef</span>

<span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类型检查</span><span class="p">:</span>
    <span class="kn">来自</font></font></font></span> <span class="nn">torch.utils.hooks</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可移除句柄</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">分布式数据并行</span><span class="p">]</span>

<span class="n">日志记录器</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">记录日志</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取日志记录器</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="nd">@dataclass</span>
<span class="k">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度</span><span class="p">:</span>
<span class="w">    </span><span class="sd">""</span>
<span class="sd">配置 DDP 本地混合精度训练。</span>

<span class="sd">属性：</span>
<span class="sd">param_dtype (torch.dtype)：这指定了模型的 dtype</span>
<span class="sd">参数，输入（当“cast_forward_inputs”被设置时）</span>
<span class="sd">``True``)，因此用于计算的 dtype。</span>
<span class="sd">然而，在正向和反向传递之外，参数处于</span>
<span class="sd">全精度。模型检查点总是在全精度下发生</span>
<span class="sd">精度。</span>
<span class="sd">reduce_dtype (torch.dtype)：这指定了梯度的数据类型</span>
<span class="sd">减少值，允许与 ``param_dtype`` 不同。</span>
<span class="sd">buffer_dtype (torch.dtype)：指定缓冲区的数据类型。</span>

<span class="sd">.. 注意:: 此 API 为实验性，可能随时更改。</span>

<span class="sd">.. 注意:: 只有浮点张量会被转换为指定的数据类型。</span>

<span class="sd">.. note:: 将参数和缓冲区完整地保存到 `state_dict` 中</span>
<span class="sd">精度。</span>

<span class="sd">.. 注意:: 每个低精度数据类型必须明确指定。</span>
<span class="sd">示例，`_MixedPrecision(reduce_dtype=torch.float16)` 仅指定</span>
<span class="sd">降低数据类型的精度，DDP 不会进行类型转换</span>
<span class="sd">参数或缓冲区。</span>

<span class="sd">.. note:: 如果未指定 `reduce_dtype`，则梯度缩减</span>
<span class="sd">发生 `param_dtype` 中，如果指定或使用原始参数数据类型</span>
<span class="sd">否则。例如，``_MixedPrecision(param_dtype=torch.float16)``</span>
<span class="sd">将导致通信以 fp16 进行。</span>
<span class="sd">"源代码"</span>

    <span class="n">param_dtype</span><span class="p">:</span> <span class="n">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">数据类型</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
    <span class="n">reduce_dtype</span><span class="p">:</span> <span class="n">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">数据类型</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
    <span class="n">缓冲区数据类型</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">数据类型</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
    <span class="c1"># TODO (rohan-varma): keep_low_precision_grads: bool = False</span>
    <span class="c1"># TODO (rohan-varma): 提供 API 以允许用户运行批归一化和层归一化</span>
    <span class="c1"># 在全精度下。对于 DDP，可以通过不执行以下操作来实现。</span>
    <span class="c1"># 参数类型转换用于 BN 和 LN 单元。</span>


<span class="k">def</span> <span class="nf">_cast_buffers</span><span class="p">(</span><span class="n">混合精度配置</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">根模块</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""将缓冲区转换为指定的 ``buffer_dtype``。"""</span>
    <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">根模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区</span><span class="p">():</span>
        <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_ddp_ignored</font></font></font></span><span class="p">)</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区</span><span class="o">.</span><span class="n">_ddp_ignored</span><span class="p">:</span>
            <span class="k">继续</span>

        <span class="n">缓冲区</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">数据</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">到</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">数据类型</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度配置</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区数据类型</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_setup_mixed_precision_params</span><span class="p">(</span><span class="n">混合精度配置</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">根模块</span><span class="p">):</span>
<span class="w">    </span><span class="sd">创建并释放混合精度参数的存储空间。</span>
    <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">根模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">():</span>
        <span class="c1">不要为 DDP 忽略的参数设置混合精度。</span>
        <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_ddp_忽略</font></font></font></span><span class="p">)</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_ddp_忽略</span><span class="p">:</span>
            <span class="k">继续</span>

        <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_mp 参数</span><span class="p">):</span>
            <span class="n">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_mp 参数</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">与...相同形状的零</span><span class="p">(</span>
                <span class="n">参数</span><span class="p">,</span>
                <span class="n">设备</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">,</span>
                <span class="n">数据类型</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度配置</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数数据类型</span><span class="p">,</span>
                <span class="n">需要梯度</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">需要梯度</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">_空闲存储</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_mp 参数</span><span class="p">)</span>
            <span class="c1"># _fp_param 将指向全精度参数，以便可以切换</span>
            <span class="c1">返回到前后翻页的末尾。</span>
            <span class="n">参数</font></font></font></span><span class="o">.</span><span class="n">_fp_param</span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">数据</span>


<span class="k">def</span> <span class="nf">_tree_flatten_with_rref</span><span class="p">(</span><span class="n">输出</span><span class="p">):</span>
    <span class="n">输出是 rref</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">RPC 可用</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</span><span class="p">,</span> <span class="n">RRef</span><span class="p">)</span>
    <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出是 rref</span><span class="p">:</span>
        <span class="n">输出张量列表</font></font></font></span><span class="p">,</span> <span class="n">treespec</span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">树扁平化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">本地值</span><span class="p">())</span>
    <span class="k">否则</span><span class="p">:</span>
        <span class="n">输出张量列表</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">树木规范</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">树扁平化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</span><span class="p">)</span>
    <span class="c1">需要返回展平的张量，指定如何重新打包它们</span>
    <span class="c1">#就像返回类型实际上是 RRef 的引用来重建一样。</span>
    <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出张量列表</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">树木规范</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出是 rref</span>


<span class="k">def</span> <span class="nf">使用 rref 展开树</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">树规范</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出是 rref</span><span class="p">):</span>
    <span class="n">输出</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">树形展开</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">树规范</span><span class="p">)</span>
    <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出为 rref</span><span class="p">:</span>
        <span class="n">输出</font></font></font></span> <span class="o">=</span> <span class="n">RRef</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</span><span class="p">)</span>
    <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</span>


<span class="k">def</span> <span class="nf">查找张量</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">递归查找指定对象中包含的所有张量。</span>
    <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">RPC 可用</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</span><span class="p">,</span> <span class="n">RRef</span><span class="p">):</span>
        <span class="c1">如果当前节点是 RRef 的所有者，则展开它并尝试</span>
        <span class="c1">查找张量。</span>
        <span class="c1">TODO：扩展到远程 RRef。</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</span><span class="o">.</span><span class="n">is_owner</span><span class="p">():</span>
            <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">查找张量</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">本地值</span><span class="p">())</span>
    <span class="k">如果</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">):</span>
        <span class="k">返回</font></font></font></span> <span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</span><span class="p">]</span>
    <span class="k">如果</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</font></font></font></span><span class="p">,</span> <span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">列表</font></font></font></span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">元组</span><span class="p">)):</span>
        <span class="k">返回</font></font></font></span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">地图</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">查找张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</span><span class="p">))</span>
    <span class="k">如果</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</font></font></font></span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字典</span><span class="p">):</span>
        <span class="k">返回</font></font></font></span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">地图</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">查找张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">值</span><span class="p">()))</span>
    <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是数据类</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</span><span class="p">):</span>
        <span class="k">返回</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span>
            <span class="nb">地图</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">查找张量</font></font></font></span><span class="p">,</span> <span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</font></font></font></span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">名称</font></font></font></span><span class="p">)</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n">f</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字段</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</span><span class="p">)))</span>
        <span class="p">)</span>

    <span class="k">返回</span> <span class="p">[]</span>


<span class="k">def</span> <span class="nf">导出 DDP 相关环境变量</span><span class="p">():</span>
    <span class="n">相关环境变量</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">RANK</span><span class="p">,</span>
        <span class="s2">本地排名</span><span class="p">,</span>
        <span class="s2">WORLD_SIZE</span><span class="p">,</span>
        <span class="s2">"主端口"</span><span class="p">,</span>
        <span class="s2">"主地址"</span><span class="p">,</span>
        <span class="s2">CUDA_VISIBLE_DEVICES</span><span class="p">,</span>
        <span class="s2">"Gloo 套接字接口名称"</span><span class="p">,</span>
        <span class="s2">"Gloo 设备传输"</span><span class="p">,</span>
        <span class="s2">"NCCL SOCKET IFNAME"</span><span class="p">,</span>
        <span class="s2">"TORCH NCCL 阻塞等待"</span><span class="p">,</span>
        <span class="s2">"NCCL 调试"</span><span class="p">,</span>
        <span class="s2">"NCCL 调试子系统"</span><span class="p">,</span>
        <span class="s2">"NCCL_IB_DISABLE"</span><span class="p">,</span>
        <span class="c1"># 更多 NCCL 环境变量：</span>
        <span class="s2">"NCCL_P2P_DISABLE"</span><span class="p">,</span>
        <span class="s2">"NCCL_P2P_LEVEL"</span><span class="p">,</span>
        <span class="s2">"NCCL 禁用共享内存"</span><span class="p">,</span>
        <span class="s2">"NCCL 套接字线程数"</span><span class="p">,</span>
        <span class="s2">"NCCL 每个线程的套接字数"</span><span class="p">,</span>
        <span class="s2">"NCCL 缓冲区大小"</span><span class="p">,</span>
        <span class="s2">"NCCL_NTHREADS"</span><span class="p">,</span>
        <span class="s2">"NCCL_RINGS"</span><span class="p">,</span>
        <span class="s2">"NCCL_MAX_NCHANNELS"</span><span class="p">,</span>
        <span class="s2">"NCCL_MIN_NCHANNELS"</span><span class="p">,</span>
        <span class="s2">"NCCL_CHECKS_DISABLE"</span><span class="p">,</span>
        <span class="s2">"NCCL_CHECK_POINTERS"</span><span class="p">,</span>
        <span class="s2">"NCCL_LAUNCH_MODE"</span><span class="p">,</span>
        <span class="s2">"NCCL_IB_HCA"</span><span class="p">,</span>
        <span class="s2">"NCCL_IB_TIMEOUT"</span><span class="p">,</span>
        <span class="s2">"NCCL_IB_RETRY_CNT"</span><span class="p">,</span>
        <span class="s2">"NCCL_IB_GID_INDEX"</span><span class="p">,</span>
        <span class="s2">"NCCL_IB_SL"</span><span class="p">,</span>
        <span class="s2">"NCCL_IB_TC"</span><span class="p">,</span>
        <span class="s2">"NCCL_IB_AR_THRESHOLD"</span><span class="p">,</span>
        <span class="s2">"NCCL_IB_CUDA 支持"</span><span class="p">,</span>
        <span class="s2">"NCCL_NET_GDR 级别"</span><span class="p">,</span>
        <span class="s2">"NCCL_NET_GDR 读取"</span><span class="p">,</span>
        <span class="s2">NCCL_SINGLE_RING_THRESHOLD</span><span class="p">,</span>
        <span class="s2">"NCCL_LL_THRESHOLD"</span><span class="p">,</span>
        <span class="s2">"NCCL_TREE_THRESHOLD"</span><span class="p">,</span>
        <span class="s2">"NCCL_ALGO"</span><span class="p">,</span>
        <span class="s2">"NCCL_PROTO"</span><span class="p">,</span>
        <span class="s2">"NCCL 忽略 CPU 亲和性"</span><span class="p">,</span>
        <span class="s2">"NCCL 调试文件"</span><span class="p">,</span>
        <span class="s2">"NCCL 启用网络通信"</span><span class="p">,</span>
        <span class="s2">"NCCL 拓扑文件"</span><span class="p">,</span>
        <span class="s2">NCCL 拓扑转储文件</span><span class="p">,</span>
        <span class="s2">PyTorch NCCL 异步错误处理</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="n">格式化输出</font></font></font></span> <span class="o">=</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">请提供需要翻译的文本</span>
    <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">变量</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">相关环境变量</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">操作系统</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">环境</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">变量</font></font></font></span><span class="p">]</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">变量</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">操作系统</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">环境</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">否则</font></font></font></span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无效</span>
        <span class="n">格式化输出</font></font></font></span> <span class="o">+=</span> <span class="sa">f</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">env:</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">变量</font></font></font></span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">值</font></font></font></span><span class="si">}</span><span class="se"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入文本翻译为简体中文为：\n</span><span class="s2">"</span>
    <span class="nb">打印</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">格式化输出</span><span class="p">)</span>


<span class="k">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_缓冲通信钩子位置</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">枚举</span><span class="p">):</span>
    <span class="n">预转发</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">自动</span><span class="p">()</span>
    <span class="n">后转发</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">自动</span><span class="p">()</span>


<span class="nd">@dataclass</span>
<span class="k">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区通信钩子</span><span class="p">:</span>
    <span class="n">缓冲区通信钩子</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可调用</span>
    <span class="n">缓冲区通信钩子状态</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">任何</span>
    <span class="n">缓冲区通信钩子位置</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_缓冲通信钩子位置</span>


<span class="c1"># 添加 DDPSink 以在向后启动时运行各种功能，例如</span>
<span class="c1"># 队列最外层向后/图任务的回调调用，</span>
<span class="c1"># 这有助于在所有梯度计算完成后触发回调</span>
<span class="c1"># 已完成。</span>
<span class="k">类</font></font></font></span> <span class="nc">_DDPSink</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">函数</span><span class="p">):</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">ddp_weakref</span><span class="p">,</span> <span class="o">*</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</span><span class="p">):</span>
        <span class="c1"># 设置 materialize_grads(False) 将确保 None 梯度保持为</span>
        <span class="c1">无效且不为零填充。</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">set_materialize_grads</span><span class="p">(</span><span class="kc">错误</span><span class="p">)</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">ddp_weakref</span> <span class="o">=</span> <span class="n">ddp_weakref</span>
        <span class="n">返回</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</span>
        <span class="k">如果</span> <span class="n">ddp_weakref</span><span class="p">()</span><span class="o">.</span><span class="n">_ddp_sink_clone</span><span class="p">:</span>
            <span class="n">返回</font></font></font></span> <span class="o">=</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">元组</span><span class="p">(</span>
                <span class="n">输入</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">克隆</font></font></font></span><span class="p">()</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">如果</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">)</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">否则</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</span>
            <span class="p">)</span>
        <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">返回</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">反向</font></font></font></span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="o">*</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度输出</span><span class="p">):</span>
        <span class="c1"># 将静态图训练中的所有 reduce 操作延迟入队</span>
        <span class="c1">迭代</span>
        <span class="n">ddp_weakref</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">ddp 弱引用</span><span class="p">()</span>
        <span class="n">减法器</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">ddp 弱引用</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减法器</span>
        <span class="n">静态图</font></font></font></span> <span class="o">=</span> <span class="n">ddp_weakref</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">静态图</span>
        <span class="n">延迟入队</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">静态图</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="n">ddp_weakref</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_静态图延迟_allreduce_enqueued</span>
        <span class="p">)</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">静态图</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="ow">not</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">延迟入队</span><span class="p">:</span>
            <span class="n">变量</font></font></font></span><span class="o">.</span><span class="n">_execution_engine</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">队列回调</span><span class="p">(</span>  <span class="c1"># type: ignore[call-arg,misc]</span>
                <span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_延迟_all_reduce</span>
            <span class="p">)</span>
            <span class="n">ddp_weakref</span><span class="o">.</span><span class="n">_static_graph_delay_allreduce_enqueued</span> <span class="o">=</span> <span class="kc">真实</span>

        <span class="k">返回</font></font></font></span> <span class="p">(</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="o">*</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度输出</span><span class="p">)</span>


<span class="k">类</span> <span class="nc">_DDPJoinHook</span><span class="p">(</span><span class="n">JoinHook</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ddp</span><span class="p">,</span> <span class="n">divide_by_initial_world_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">设置内部使用的配置变量。</span>
        <span class="k">断言</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ddp</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分布式数据并行</span><span class="p">),</span> <span class="p">(</span>
            <span class="s2">DDP 加入钩子需要传递一个 DistributedDataParallel</span>
            <span class="s2">"实例作为状态"</span>
        <span class="p">)</span>
        <span class="k">断言</font></font></font></span> <span class="n">ddp</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">日志记录器</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
        <span class="n">ddp</span><span class="o">.</span><span class="n">记录器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_设置不均匀输入连接</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ddp</span> <span class="o">=</span> <span class="n">ddp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ddp</span><span class="o">.</span><span class="n">根据初始世界大小进行除法</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">根据初始世界大小进行除法</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">主钩子</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">在正向和反向传递中跟踪 DDP 集体通信操作。</span>
        <span class="n">ddp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">深度学习框架</span>
        <span class="c1">训练期间桶只重建一次</span>
        <span class="n">ddp</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重建桶</span><span class="p">()</span>

        <span class="c1">安排广播，如果我们正在同步模块缓冲区</span>
        <span class="c1">前向传递</span>
        <span class="c1">TODO：实现 DDP 不均匀输入上下文管理器支持缓冲区</span>
        <span class="c1">通信钩子（https://github.com/pytorch/pytorch/issues/65436）</span>
        <span class="n">ddp</span><span class="o">.</span><span class="n">_check_and_sync_module_buffers</span><span class="p">()</span>

        <span class="c1"># 需要检查在反向传播中是否需要同步</span>
        <span class="n">应该同步反向</font></font></font></span> <span class="o">=</span> <span class="n">ddp</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_检查全局是否需要反向梯度同步</span><span class="p">(</span>
            <span class="n">是否已连接的 rank</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
        <span class="p">)</span>
        <span class="c1">在下一次迭代中，如果跳过梯度同步，则禁用前向参数同步</span>
        <span class="c1">因此，相应地设置 `require_forward_param_sync`</span>
        <span class="c1">`require_forward_param_sync`</span>
        <span class="n">ddp</span><span class="o">.</span><span class="n">require_forward_param_sync</span> <span class="o">=</span> <span class="n">应该向后同步</span>
        <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">应该向后同步</span><span class="p">:</span>
            <span class="k">返回</span>

        <span class="c1"># 为每个梯度桶安排一次 allreduce 以匹配反向</span>
        <span class="c1"># 执行 allreduce</span>
        <span class="n">ddp</span><span class="o">.</span><span class="n">_match_all_reduce_for_bwd_pass</span><span class="p">()</span>

        <span class="c1"># 检查是否需要本地 allreduce 未使用参数</span>
        <span class="k">如果</span> <span class="n">ddp</span><span class="o">.</span><span class="n">find_unused_parameters</span><span class="p">:</span>
            <span class="n">ddp</span><span class="o">.</span><span class="n">_match_unused_params_allreduce</span><span class="p">()</span>

        <span class="c1">训练期间重建的参数只推送一次</span>
        <span class="n">ddp</span><span class="o">.</span><span class="n">简化器</span><span class="o">.</span><span class="n">_push_all_rebuilt_params</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">后钩</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_last_joiner</span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔</span><span class="p">):</span>
<span class="w">        </span><span class="sd">同步最终模型以确保所有进程中的模型相同</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ddp</span><span class="o">.</span><span class="n">同步最终模型</span><span class="p">(</span><span class="n">is_last_joiner</span><span class="p">)</span>


<div class="viewcode-block" id="DistributedDataParallel"><a class="viewcode-back" href="../../../../generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel">[文档]</font></font></font></a><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</font></font></font></span> <span class="nc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分布式数据并行</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可加入的</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">实现基于 ``torch.distributed`` 的模块级分布式数据并行。</span>

<span class="sd">此容器通过同步梯度提供数据并行性</span>
<span class="sd">在每个模型副本之间。要同步的设备</span>
<span class="sd">指定由输入 `process_group` 指定，即整个世界</span>
<span class="sd">默认情况下。请注意，`DistributedDataParallel` 不分块或</span>
<span class="sd">否则将输入数据分片分配给参与的计算单元；用户是</span>
<span class="sd">负责定义如何做到这一点，例如通过使用</span>
<span class="sd">关于 :class:`DistributedSampler` 的描述。</span>

<span class="sd">参见：:ref:`分布式基础` 和 :ref:`cuda-nn-ddp-instead`。</span>
<span class="sd">与 :class:`torch.nn.DataParallel` 相同的输入约束适用。</span>

<span class="sd">创建此类需要 ``torch.distributed`` 已经存在。</span>
<span class="sd">通过调用 :func:`torch.distributed.init_process_group` 初始化。</span>

<span class="sd">``DistributedDataParallel`` 已被证明在单节点多 GPU 数据并行训练方面比 :class:`torch.nn.DataParallel` 快得多。</span>
<span class="sd">class:`torch.nn.DataParallel` 用于单节点多 GPU 数据并行训练。</span>
<span class="sd">并行训练。</span>

<span class="sd">在具有 N 个 GPU 的主机上使用`DistributedDataParallel`，你应该启动</span>
<span class="sd">启动`N`个进程，确保每个进程仅独立工作于单一</span>
<span class="sd">GPU 从 0 到 N-1。这可以通过设置</span>
<span class="sd">CUDA_VISIBLE_DEVICES 对每个进程或通过调用：</span>

<span class="sd">&gt;&gt;&gt; # xdoctest: +SKIP("未定义变量")</span>
<span class="sd">        &gt;&gt;&gt; torch.cuda.set_device(i)</span>

<span class="sd">where i is from 0 to N-1. In each process, you should refer to the following</span>
<span class="sd">    to construct this module:</span>

<span class="sd">&gt;&gt;&gt; # xdoctest: +SKIP("未定义变量")</span>
<span class="sd">        &gt;&gt;&gt; torch.distributed.init_process_group(</span>
<span class="sd">&gt;&gt;&gt; backend='nccl', world_size=N, init_method='...'</span>
<span class="sd">        &gt;&gt;&gt; )</span>
<span class="sd">        &gt;&gt;&gt; model = DistributedDataParallel(model, device_ids=[i], output_device=i)</span>

<span class="sd">为了在每个节点上启动多个进程，您可以使用 `torch.distributed.launch` 或 `torch.multiprocessing.spawn`。</span>
<span class="sd">``torch.distributed.launch`` 或 ``torch.multiprocessing.spawn``。</span>

<span class="sd">.. 注意::</span>
<span class="sd">请参阅 `PyTorch 分布式概述 `__</span>
<span class="sd">用于了解所有与分布式训练相关的功能简介。</span>

<span class="sd">.. 注意::</span>
<span class="sd">分布式数据并行可用于与</span>
<span class="sd">`:class:`torch.distributed.optim.ZeroRedundancyOptimizer` 用于减少</span>
<span class="sd">每个 rank 的优化器状态内存占用。请参阅</span>
<span class="sd">`ZeroRedundancyOptimizer 配方 `__</span>
<span class="sd">更多详情请查看。</span>

<span class="sd">.. 注意:: ``nccl`` 后端目前是最快且强烈推荐的</span>
<span class="sd">后端，当使用 GPU 时适用。这适用于单节点和多节点</span>
<span class="sd">多节点分布式训练。</span>

<span class="sd">.. 注意:: 此模块还支持混合精度分布式训练。</span>
<span class="sd">这意味着您的模型可以有不同的参数类型，例如</span>
<span class="sd">混合类型的 ``fp16`` 和 ``fp32``，在这些参数上的梯度下降</span>
<span class="sd">混合类型的参数将正常工作。</span>

<span class="sd">.. 注意:: 如果在一个进程中使用 `torch.save` 来保存模块的检查点，</span>
<span class="sd">确保在其它进程中使用 `torch.load` 来恢复它。</span>
<span class="sd">每个进程的 `map_location` 都已正确配置。如果没有</span>
<span class="sd">`map_location`, `torch.load` 将恢复到设备上的模块</span>
<span class="sd">模块被保存的位置。</span>

<span class="sd">.. note:: 当一个模型在 `M` 节点上使用 `batch=N` 进行训练时，</span>
<span class="sd">与相同模型相比，梯度将小 `M` 倍。</span>
<span class="sd">在单个节点上训练，如果损失总和（NOT）</span>
<span class="sd">平均通常)跨批次实例（因为梯度</span>
<span class="sd">不同节点之间的平均值）。您应该取这个平均值</span>
<span class="sd">考虑当你想要获得数学上等效的</span>
<span class="sd">与本地训练的对比，训练过程。但在大多数情况下，你可以将 DistributedDataParallel 包装的模型、DataParallel 包装的模型和单 GPU 上的普通模型视为相同（例如，使用等效批次的相同学习率）。</span>
<span class="sd">在大多数情况下，你可以将 DistributedDataParallel 包装的模型、DataParallel 包装的模型和单 GPU 上的普通模型视为相同（例如，使用等效批次的相同学习率）。</span>
<span class="sd">在大多数情况下，你可以将 DistributedDataParallel 包装的模型、DataParallel 包装的模型和单 GPU 上的普通模型视为相同（例如，使用等效批次的相同学习率）。</span>
<span class="sd">在大多数情况下，你可以将 DistributedDataParallel 包装的模型、DataParallel 包装的模型和单 GPU 上的普通模型视为相同（例如，使用等效批次的相同学习率）。</span>

<span class="sd">.. 注意::</span>
<span class="sd">参数永远不会在进程之间广播。该模块执行</span>
<span class="sd">梯度上的全量减少步骤，并假设它们将被修改</span>
<span class="sd">由优化器以相同方式作用于所有进程。缓冲区</span>
<span class="sd">（例如，BatchNorm 状态）从正在处理的模块中广播出来</span>
<span class="sd">在每次迭代中，都向系统中的所有其他副本发送。</span>

<span class="sd">.. 注意::</span>
<span class="sd">如果您正在与 DistributedDataParallel 一起使用</span>
<span class="sd">ref:`分布式 RPC 框架`，您应该始终使用</span>
<span class="sd">meth:`torch.distributed.autograd.backward` 来计算梯度</span>
<span class="sd">用于优化的 :class:`torch.distributed.optim.DistributedOptimizer`</span>
<span class="sd">参数</span>

<span class="sd">示例::</span>

<span class="sd">&gt;&gt;&gt; # xdoctest: +SKIP("未定义变量")</span>
<span class="sd">            &gt;&gt;&gt; import torch.distributed.autograd as dist_autograd</span>
<span class="sd">&gt;&gt;&gt; 从 torch.nn.parallel 导入 DistributedDataParallel 作为 DDP</span>
<span class="sd">&gt;&gt;&gt; 导入 torch</span>
<span class="sd">&gt;&gt;&gt; 从 torch 导入 optim</span>
<span class="sd">&gt;&gt;&gt; 从 torch.distributed.optim 导入 DistributedOptimizer</span>
<span class="sd">&gt;&gt;&gt; 导入 torch.distributed.rpc 作为 rpc</span>
<span class="sd">&gt;&gt;&gt; 从 torch.distributed.rpc 导入 RRef</span>
<span class="sd">...</span>
<span class="sd">            &gt;&gt;&gt; t1 = torch.rand((3, 3), requires_grad=True)</span>
<span class="sd">            &gt;&gt;&gt; t2 = torch.rand((3, 3), requires_grad=True)</span>
<span class="sd">            &gt;&gt;&gt; rref = rpc.remote("worker1", torch.add, args=(t1, t2))</span>
<span class="sd">            &gt;&gt;&gt; ddp_model = DDP(my_model)</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; # 设置优化器</span>
<span class="sd">            &gt;&gt;&gt; optimizer_params = [rref]</span>
<span class="sd">            &gt;&gt;&gt; for param in ddp_model.parameters():</span>
<span class="sd">            &gt;&gt;&gt;     optimizer_params.append(RRef(param))</span>
<span class="sd">...</span>
<span class="sd">            &gt;&gt;&gt; dist_optim = DistributedOptimizer(</span>
<span class="sd">&gt;&gt;&gt;     优化器.SGD,</span>
<span class="sd">            &gt;&gt;&gt;     optimizer_params,</span>
<span class="sd">            &gt;&gt;&gt;     lr=0.05,</span>
<span class="sd">            &gt;&gt;&gt; )</span>
<span class="sd">...</span>
<span class="sd">&gt;&gt;&gt; 使用 dist_autograd.context() 上下文管理器 as context_id:</span>
<span class="sd">&gt;&gt;&gt; pred = ddp_model(rref.to_here())</span>
<span class="sd">&gt;&gt;&gt; loss = loss_func(pred, target)</span>
<span class="sd">&gt;&gt;&gt; dist_autograd.backward(context_id, [loss])</span>
<span class="sd">&gt;&gt;&gt; dist_optim.step(context_id)</span>

<span class="sd">.. 注意::</span>
<span class="sd">DistributedDataParallel 目前对梯度</span>
<span class="sd">checkpointing 使用:meth:`torch.utils.checkpoint`提供了有限的支持。</span>
<span class="sd">如果使用 use_reentrant=False（推荐）进行 checkpoint，DDP</span>
<span class="sd">将按预期工作，没有任何限制。</span>
<span class="sd">然而，如果使用默认的 use_reentrant=True 进行检查点操作，</span>
<span class="sd">DDP 在没有模型中未使用参数的情况下将按预期工作</span>
<span class="sd">并且每层最多只检查点一次（确保您没有传递）</span>
<span class="sd">`find_unused_parameters=True` 用于 DDP。我们目前不支持</span>
<span class="sd">情况是一个层被多次检查点，或者当有未使用的</span>
<span class="sd">模型检查点中的参数。</span>

<span class="sd">.. 注意::</span>
<span class="sd">要使非 DDP 模型加载 DDP 模型的 state dict</span>
<span class="sd"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">:meth:`~torch.nn.modules.utils.consume_prefix_in_state_dict_if_present` 
翻译为：:meth:`~torch.nn.modules.utils.consume_prefix_in_state_dict_if_present`</font></font></font></span>
<span class="sd">在加载前需要应用去除 DDP 状态字典前缀 "module." 的操作。</span>

<span class="sd">.. 警告::</span>
<span class="sd">构造函数、前向方法和输出（或该模块输出的函数）的微分是分布式同步点。考虑到不同进程可能的情况，请考虑这一点。</span>
<span class="sd">函数的输出（或该模块输出的函数）是分布式同步点。考虑到不同进程可能的情况，请考虑这一点。</span>
<span class="sd">考虑到不同进程可能的情况，请考虑这一点。</span>
<span class="sd">执行不同的代码。</span>

<span class="sd">.. 警告::</span>
<span class="sd">此模块假定所有参数在创建时已注册到模型中。</span>
<span class="sd">时间创建后，不应添加或删除任何参数。</span>
<span class="sd">同样适用于缓冲区。</span>

<span class="sd">.. 警告::</span>
<span class="sd">本模块假定所有参数都已注册在每个模型的模型中</span>
<span class="sd">分布式进程顺序相同。模块本身将</span>
<span class="sd">执行梯度 ``allreduce`` 按照反向顺序</span>
<span class="sd">模型注册的参数。换句话说，它是用户的</span>
<span class="sd">确保每个分布式进程具有相同的模型以及相同的参数注册顺序的责任</span>
<span class="sd">此模块允许具有非行主序连续步长的参数</span>

<span class="sd">.. 警告::</span>
<span class="sd">例如，您的模型可能包含一些参数，这些参数的</span>
<span class="sd">例如，您的模型可能包含一些参数，这些参数的</span>
<span class="sd">`torch.memory_format` 是 `torch.contiguous_format`</span>
<span class="sd">以及其他格式为 `torch.channels_last` 的内容。然而，</span>
<span class="sd">不同进程中的对应参数必须具有相同的步长。</span>
<span class="sd">相同。</span>

<span class="sd">.. 警告::</span>
<span class="sd">此模块不与 :func:`torch.autograd.grad` 兼容（即它将</span>
<span class="sd">仅当梯度要累积在 ``.grad`` 属性中时才工作</span>
<span class="sd">参数)。</span>

<span class="sd">.. 警告::</span>
<span class="sd">如果您计划使用此模块与 ``nccl`` 后端或 ``gloo`` 结合使用</span>
<span class="sd">后端（使用 Infiniband），以及一个使用 DataLoader 的数据加载器</span>
<span class="sd">多个工作者，请将多进程启动方法改为</span>
<span class="sd">`forkserver`（仅限 Python 3）或 `spawn`。遗憾的是</span>
<span class="sd">Gloo（使用 Infiniband）和 NCCL2 不安全，并且你将</span>
<span class="sd">如果不对这个设置进行更改，可能会遇到死锁问题。</span>

<span class="sd">.. 警告::</span>
<span class="sd">您不应该在封装模型后尝试更改模型的参数</span>
<span class="sd">提升您的模型使用 `DistributedDataParallel`。因为，当</span>
<span class="sd">将模型封装为 `DistributedDataParallel`，构造函数</span>
<span class="sd">`DistributedDataParallel` 将注册额外的梯度</span>
<span class="sd">对模型本身的全部参数进行降维函数处理。</span>
<span class="sd">如果之后更改模型的参数，则梯度降维函数将不再匹配正确的集合。</span>
<span class="sd">使用 ``DistributedDataParallel`` 与之结合。</span>
<span class="sd">参数</span>

<span class="sd">.. 警告::</span>
<span class="sd">使用 ``DistributedDataParallel``。</span>
<span class="sd">`:ref:`分布式 RPC 框架`处于实验阶段，可能会发生变化。</span>

<span class="sd">    Args:</span>
<span class="sd">模块（Module）：要并行化的模块</span>
<span class="sd">device_ids（整数列表或 torch.device）：CUDA 设备。</span>
<span class="sd">1) 对于单设备模块，`device_ids`可以</span>
<span class="sd">包含一个设备 ID，该 ID 代表唯一的</span>
<span class="sd">CUDA 设备，其中包含对应此进程的输入模块。</span>
<span class="sd">或者，`device_ids` 也可以为 `None`。</span>
<span class="sd">2) 对于多设备模块和 CPU 模块，</span>
<span class="sd">``device_ids``必须为``None``。</span>

<span class="sd">当两种情况下的``device_ids``均为``None``时，</span>
<span class="sd">前向传递的输入数据和实际模块</span>
<span class="sd">必须放置在正确的设备上。</span>
<span class="sd">（默认：`None`）</span>
<span class="sd">输出设备（int 或 torch.device）：输出位置的设备</span>
<span class="sd">单设备 CUDA 模块。对于多设备模块和</span>
<span class="sd">CPU 模块，它必须为`None`，模块本身</span>
<span class="sd">决定输出位置。（默认：`device_ids[0]`）</span>
<span class="sd">（适用于单设备模块）</span>
<span class="sd">（广播缓冲区）（布尔值）：启用同步（广播）的标志</span>
<span class="sd">模块在 ``forward`` 函数开始时的缓冲区</span>
<span class="sd">（默认：``True``）</span>
<span class="sd">初始化同步（布尔值）：是否在初始化期间同步以验证参数</span>
<span class="sd">形状和广播参数以及缓冲区。</span>
<span class="sd">警告：如果设置为 False，则用户需要</span>
<span class="sd">确保它们自己权重相同</span>
<span class="sd">所有等级。</span>
<span class="sd">（默认：``True``）</span>
<span class="sd">process_group：用于分布式数据的进程组</span>
<span class="sd">all-reduction。如果为 ``None``，则使用默认进程组，</span>
<span class="sd">由 :func:`torch.distributed.init_process_group` 创建，</span>
<span class="sd">将被使用。（默认：``None``）</span>
<span class="sd">bucket_cap_mb: ``DistributedDataParallel`` 将参数分桶到</span>
<span class="sd">多个桶中，以便每个桶的梯度减少</span>
<span class="sd">桶可能与其他反向计算重叠。</span>
<span class="sd">attr:`bucket_cap_mb` 控制桶的大小。</span>
<span class="sd">兆字节（MiB）。如果为 ``None``，则使用默认大小 25 MiB。</span>
<span class="sd">（默认：``None``）。</span>
<span class="sd">find_unused_parameters (bool): 从所有返回值中包含的张量开始遍历 autograd 图。</span>
<span class="sd">                               tensors contained in the return value of the</span>
<span class="sd">                               wrapped module's ``forward`` function. Parameters</span>
<span class="sd">                               that don't receive gradients as part of this</span>
<span class="sd">图被预先标记为已准备好</span>
<span class="sd">将可能被减少。此外，参数</span>
<span class="sd">已被用于包装模块的 `forward`</span>
<span class="sd">函数但不是损失计算的一部分</span>
<span class="sd">因此也不会收到梯度，会被预先标记为准备减少。</span>
<span class="sd">预先标记为准备减少。</span>
<span class="sd">(默认：``False``)</span>
<span class="sd">check_reduction: 此参数已弃用。</span>
<span class="sd">gradient_as_bucket_view (bool): 当设置为 ``True`` 时，梯度将变为视图</span>
<span class="sd">指向 ``allreduce`` 通信的不同偏移量</span>
<span class="sd">桶。这可以减少峰值内存使用，其中</span>
<span class="sd">保存的内存大小将与总梯度相等</span>
<span class="sd">大小。此外，它避免了复制之间的开销。</span>
<span class="sd">梯度与`allreduce`通信桶。当</span>
<span class="sd">梯度是视图，`detach_()` 不能在它们上调用</span>
<span class="sd">如果遇到此类错误，请通过参考 `torch.optim.Optimizer.zero_grad` 函数来解决。</span>
<span class="sd">在 `torch/optim/optimizer.py` 中查找该函数作为解决方案。</span>
<span class="sd">注意，梯度将在第一次迭代后变为视图。</span>
<span class="sd">请注意，梯度将在第一次迭代后变为视图。</span>
<span class="sd">第一次迭代后应检查峰值内存节省情况。</span>
<span class="sd">static_graph (bool): 当设置为 ``True`` 时，DDP 知道训练图是</span>
<span class="sd">静态的。静态图意味着 1) 使用的和未使用的</span>
<span class="sd">参数在整个训练循环中不会改变；在</span>
<span class="sd">在这种情况下，用户是否设置</span>
<span class="sd">``find_unused_parameters = True`` 都无关紧要。2) 图的训练</span>
<span class="sd">在整个训练循环中不会改变（意味着没有</span>
<span class="sd">基于迭代的控制流）。</span>
<span class="sd">当 static_graph 设置为 ``True`` 时，DDP 将支持以下情况</span>
<span class="sd">无法在以前支持：</span>
<span class="sd">1) 可重入回退。</span>
<span class="sd">2) 多次激活检查点。</span>
<span class="sd">3) 当模型有未使用参数时的激活检查点。</span>
<span class="sd">4) 模型参数中存在不在前向函数之外的参数。</span>
<span class="sd">5) 当存在未使用参数时，可能提高性能，</span>
<span class="sd">因为 DDP 不会在每次迭代中搜索图来检测未使用的</span>
<span class="sd">当 static_graph 设置为 True 时的参数。</span>
<span class="sd">要检查是否可以将 static_graph 设置为 True，一种方法是在</span>
<span class="sd">您之前模型训练的结尾检查 ddp 日志数据，</span>
<span class="sd">如果 ddp_logging_data.get("can_set_static_graph") == True，通常情况下，</span>
<span class="sd">也可以将 `static_graph = True` 设置为 True。</span>

<span class="sd">示例::</span>
<span class="sd">&gt;&gt;&gt; # xdoctest: +SKIP("未定义变量")</span>
<span class="sd">                         &gt;&gt;&gt; model_DDP = torch.nn.parallel.DistributedDataParallel(model)</span>
<span class="sd">&gt;&gt;&gt; # 训练循环</span>
<span class="sd">                         &gt;&gt;&gt; ...</span>
<span class="sd">                         &gt;&gt;&gt; ddp_logging_data = model_DDP._get_ddp_logging_data()</span>
<span class="sd">                         &gt;&gt;&gt; static_graph = ddp_logging_data.get("can_set_static_graph")</span>
<span class="sd">        delay_all_reduce_named_params (list of tuple of str and torch.nn.Parameter): a list</span>
<span class="sd">                    of named parameters whose all reduce will be delayed when the gradient of</span>
<span class="sd">指定的 `param_to_hook_all_reduce` 参数已准备好。其他</span>
<span class="sd">DDP 的参数不适用于此参数中指定的命名参数</span>
<span class="sd">这些命名参数将被 DDP reducer 忽略。</span>
<span class="sd">param_to_hook_all_reduce (torch.nn.Parameter)：用于钩子延迟全量减少的参数</span>
<span class="sd">在 `delay_all_reduce_named_params` 中指定的参数。</span>


<span class="sd">属性：</span>
<span class="sd">模块（Module）：要并行化的模块。</span>

<span class="sd">示例::</span>

<span class="sd">&gt;&gt;&gt; # xdoctest: +SKIP("未定义变量")</span>
<span class="sd">        &gt;&gt;&gt; torch.distributed.init_process_group(backend='nccl', world_size=4, init_method='...')</span>
<span class="sd">        &gt;&gt;&gt; net = torch.nn.parallel.DistributedDataParallel(model)</span>
<span class="sd">"源代码"</span>

    <span class="c1">用于跟踪给定线程是否在 ddp forward 中用于 torchdynamo 目的</span>
    <span class="n">_active_ddp_module</span><span class="p">:</span> <span class="n">可选</font></font></font></span><span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分布式数据并行</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>

    <span class="k">def</span> <span class="fm">初始化</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">模块</span><span class="p">,</span>
        <span class="n">设备 ID</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">输出设备</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">暗淡</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">广播缓冲区</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">初始化同步</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">进程组</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">桶容量（MB）</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">查找未使用参数</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">,</span>
        <span class="n">检查缩减</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">,</span>
        <span class="n">渐进式桶视图</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">,</span>
        <span class="n">静态图</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">,</span>
        <span class="n">延迟所有 reduce 命名参数</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">将参数钩子到所有 reduce</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">混合精度</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
        <span class="n">装置网状结构</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</span><span class="p">()</span>
        <span class="n">可加入的</font></font></font></span><span class="o">.</span><span class="fm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">初始化</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">记录器</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">记录器</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
        <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">延迟所有 reduce 命名参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">)</span> <span class="o">!=</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔</span><span class="p">(</span>
            <span class="n">将参数钩子到 all_reduce</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">记录并抛出异常</span><span class="p">(</span>
                <span class="ne">ValueError</span><span class="p">,</span>
                <span class="s2">"delay_all_reduce_named_params 和 param_to_hook_all_reduce 需要同时设置。"</span>
                <span class="s2">"不能同时指定 process_group 和 device_mesh 参数。"</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">流程组</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备网状</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="k">提升</font></font></font></span> <span class="ne"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">运行时错误</span><span class="p">(</span>
                <span class="s2">"无法指定 process_group 和 device_mesh 参数。"</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">流程组</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备网状</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">流程组</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取默认组</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">设备网状</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">流程组</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">流程组</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">装置网状结构</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">维数</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">提升</font></font></font></span> <span class="ne"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">运行时错误</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"仅支持 1D 设备网格，但得到了"</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">装置网状结构</font></font></font></span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">。</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">设备网状</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备网状</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">流程组</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">装置网状结构</font></font></font></span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">网格维度</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="kn">来自</font></font></font></span> <span class="nn">torch.distributed.device_mesh</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="n">_mesh_resources</span>

            <span class="n">根网格</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_网状资源</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取根网格</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">装置网状结构</span><span class="p">)</span>
            <span class="c1"># 如果根网格与 device_mesh 不同，</span>
            <span class="c1"># 从根网格中切出 device_mesh。</span>
            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">根网格</font></font></font></span> <span class="o">!=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">装置网状结构</span><span class="p">:</span>
                <span class="c1"># TODO：这是一个临时解决方案，以启用 DDP + TP。</span>
                <span class="c1"># 我们应该在 DDP 中实现逻辑，以便 2D 实现能够</span>
                <span class="c1"># 声音和 state_dict 能够直接工作。</span>
                <span class="c1">在检查未初始化参数之前必须完成此操作。</span>
                <span class="kn">来自</font></font></font></span> <span class="nn">torch.distributed.tensor.parallel.ddp</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="p">(</span>
                    <span class="n">_pre_dp_module_transform</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="n">_pre_dp_module_transform</span><span class="p">(</span><span class="n">模块</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">全部延迟所有 reduce 参数</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">忽略的_ddp 参数和缓冲区</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">忽略的参数</font></font></font></span> <span class="o">=</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">集合</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">忽略的_ddp 参数和缓冲区</span><span class="p">)</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">忽略的参数</font></font></font></span> <span class="o">=</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">集合</span><span class="p">()</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">延迟所有 reduce 命名参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">名称</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">延迟所有 reduce 命名参数</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">忽略的参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">添加</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">名称</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">全部延迟所有 reduce 参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">追加</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">模块参数</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">p</span>
            <span class="k">为</font></font></font></span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名参数。</span><span class="p">()</span>
            <span class="k">如果</font></font></font></span> <span class="n">n</span> <span class="ow">not</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">忽略的参数</span>
        <span class="p">]</span>
        <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">任何</font></font></font></span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n">p</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块参数</span><span class="p">):</span>
            <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">延迟所有全量 reduce 参数</span><span class="p">):</span>
                <span class="n">记录器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">信息</font></font></font></span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">延迟所有参数的 AllReduce 操作。</span><span class="p">)</span>
            <span class="k">否则</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span>
                    <span class="ne">运行时错误</span><span class="p">,</span>
                    <span class="s2">分布式数据并行在模块 "</span>
                    <span class="s2">"没有需要梯度的参数。"</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span>
                <span class="ne">ValueError</span><span class="p">,</span>
                <span class="s2">"device_ids 只能为 None 或包含单个元素。"</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">是多设备模块</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">长度</font></font></font></span><span class="p">({</span><span class="n">p</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n">p</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块参数</span><span class="p">})</span> <span class="o">&gt;</span> <span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">独特设备类型</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">p</span><span class="o">.</span><span class="n">设备</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类型</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n">p</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块参数</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">如果</font></font></font></span> <span class="n">p</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
        <span class="p">}</span>
        <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">独特设备类型</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">记录并抛出</span><span class="p">(</span>
                <span class="ne">ValueError</span><span class="p">,</span>
                <span class="s2">"DistributedDataParallel 的输入模块必须在"</span>
                <span class="sa">f</span><span class="s2">"同一类型的设备上，但输入模块的参数位于"</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">不同设备类型</span><span class="si">}</span><span class="s2">."</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">设备类型</font></font></font></span> <span class="o">=</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">下一</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">迭代</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">独特设备类型</span><span class="p">))</span>

        <span class="k">如果</span> <span class="p">(</span>
            <span class="n">设备 ID</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
            <span class="ow">或</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</font></font></font></span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 为向后兼容</span>
            <span class="ow">或</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备类型</font></font></font></span> <span class="o">==</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">cpu</span>
            <span class="ow">或</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是否为多设备模块</span>
        <span class="p">):</span>
            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">或</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出设备</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span>
                    <span class="ne">ValueError</span><span class="p">,</span>
                    <span class="s2">"分布式数据并行 device_ids 和 output_device 参数"</span>
                    <span class="s2">"仅与单设备/多设备 GPU 模块或 CPU 模块兼容，"</span>
                    <span class="sa">f</span><span class="s2">"但获取了 device_ids"</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</font></font></font></span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出设备</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出设备</font></font></font></span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">，"</span>
                    <span class="sa">f</span><span class="s2">模块参数</font></font></font></span><span class="si">{</span><span class="p">({</span><span class="n">p</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="w"> </span><span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_模块参数</span><span class="p">})</span><span class="si">}</span><span class="s2">."</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">设备 ID</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">输出设备</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">设备 ID</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取设备索引</font></font></font></span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n">x</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</span><span class="p">]</span>

            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出设备</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
                <span class="n">输出设备</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">输出设备</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取设备索引</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出设备</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">静态图</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">假</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">维度</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">维度</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">模块</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">设备</font></font></font></span> <span class="o">=</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">下一</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">迭代</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块参数</font></font></font></span><span class="p">))</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">广播缓冲区</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">广播缓冲区</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">查找未使用参数</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">查找未使用参数</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">需要反向梯度同步</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">需要正向参数同步</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">渐进式桶视图</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">渐进式桶视图</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">混合精度</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度</span>
        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="n">记录器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">警告</font></font></font></span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"收到混合精度配置"</font></font></font></span><span class="si">%s</span><span class="s2">"</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度</span><span class="p">)</span>

        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">检查缩减</span><span class="p">:</span>
            <span class="c1"># 此参数已不再使用，因为缩减器</span>
            <span class="c1">确保即使某些参数减少也能完成减少</span>
            <span class="c1"># 不接收梯度。</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">警告</span><span class="p">(</span>
                <span class="s2">`DistributedDataParallel`中的`check_reduction`参数</span>
                <span class="s2">模块已弃用。请避免使用。</span><span class="p">,</span>
                <span class="ne">未来警告</span><span class="p">,</span>
                <span class="n">栈级别</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1">检查模块是否未初始化参数</span>
        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_模块参数</span><span class="p">:</span>
            <span class="k">如果</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">未初始化参数</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_记录并抛出</span><span class="p">(</span>
                    <span class="ne">运行时错误</span><span class="p">,</span>
                    <span class="s2">"具有未初始化参数的模块不能与 `DistributedDataParallel` 一起使用。"</span>
                    <span class="s2">运行一个虚拟前向传递以正确初始化模块</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="c1">用于节点内参数同步和节点间同步</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">广播桶大小</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">250</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">)</span>

        <span class="c1">减少桶大小</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶容量（MB）</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="c1"># 默认情况（桶容量为 25 MiB）</span>
            <span class="n">桶容量（MB）</span> <span class="o">=</span> <span class="mi">25</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">桶字节容量默认值</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">桶字节容量默认值</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">假</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">桶字节容量</font></font></font></span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶容量 MB</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">)</span>

        <span class="c1">是否在侧流上执行输入张量 CPU 到 GPU 的复制</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">使用侧边流进行张量复制</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">操作系统</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">环境</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取</font></font></font></span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"使用 PYTORCH_DDP 侧边流"</font></font></font></span><span class="p">,</span> <span class="s2">"1"</span><span class="p">)</span> <span class="o">==</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">1</span>
        <span class="p">)</span>

        <span class="c1">初始化梯度缓冲区并注册所有 reduce 钩子</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_延迟梯度缓冲区</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">延迟梯度视图</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">列表</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">延迟所有 reduce 参数</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">假</span>
        <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">延迟所有 reduce 参数</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">注册延迟所有 reduce 钩子</span><span class="p">(</span>
                <span class="n">桶容量（MB）</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶容量（MB）</span><span class="p">,</span>
                <span class="n">钩子所有 reduce 的参数</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">钩子所有 reduce 的参数</span><span class="p">,</span>
                <span class="n">设备 ID</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_延迟所有 reduce 参数</span><span class="p">:</span>
                <span class="k">返回</span>

        <span class="c1"># 构建 reducer 的参数。</span>
        <span class="n">参数</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">预期稀疏梯度</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_构建 reducer 参数</span><span class="p">()</span>

        <span class="c1">初始化期间所有集体均由此标志控制。</span>
        <span class="k">如果</span> <span class="n">init_sync</span><span class="p">:</span>
            <span class="c1">验证模型等价性。</span>
            <span class="n">_verify_param_shape_across_processes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">进程组</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">)</span>
            <span class="c1">同步参数和缓冲区。确保所有 DDP 模型从相同值开始。</span>
            <span class="n">_同步模块状态</span><span class="p">(</span>
                <span class="n">模块</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">,</span>
                <span class="n">进程组</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程组</span><span class="p">,</span>
                <span class="n">广播桶大小</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">广播桶大小</span><span class="p">,</span>
                <span class="n">源</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">要忽略的参数和缓冲区</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">要忽略的参数</span><span class="p">,</span>
                <span class="n">广播缓冲区</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">广播缓冲区</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># 在调试模式下，构建参数索引 -&gt; 参数的映射。</span>
        <span class="n">参数到名称映射</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">构建调试参数到名称的映射</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">)</span>

        <span class="c1">构建 reducer。</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ddp_init_helper</span><span class="p">(</span>
            <span class="n">参数</span><span class="p">,</span>
            <span class="n">预期稀疏梯度</span><span class="p">,</span>
            <span class="n">参数到名称映射</span><span class="p">,</span>
            <span class="n">静态图</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_通信钩子</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">列表</font></font></font></span><span class="p">[</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">元组</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可调用</font></font></font></span><span class="p">,</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="n">_设置混合精度参数</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度</font></font></font></span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">)</span>
            <span class="n">_转换缓冲区</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度</font></font></font></span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">)</span>
            <span class="c1"># 用于异步低精度复制的流。</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mp_stream</span> <span class="o">=</span> <span class="n">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">流</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_submodule_to_event</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="n">双端队列</span><span class="p">)</span>  <span class="c1"># type: ignore[var-annotated]</span>
            <span class="c1"># 在根模块中添加前向预钩子以启动向低层复制</span>
            <span class="c1"># 提高精度。</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">注册前向钩子</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_root_copy_hook</span><span class="p">,</span> <span class="n">预先添加</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</font></font></font></span><span class="p">,</span> <span class="n">with_kwargs</span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
            <span class="p">)</span>
            <span class="c1"># 在所有子模块中添加前向预钩子以等待复制事件</span>
            <span class="c1"># 在运行计算之前。</span>
            <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">():</span>
                <span class="n">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">注册前向钩子</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_module_wait_for_copy_hook</span><span class="p">,</span>
                    <span class="n">预先添加</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">,</span>
                    <span class="n">with_kwargs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="c1"># 在反向操作中设置回调以提升类型并使用完整精度</span>
            <span class="c1"># params. TODO (rohan-varma): 使其与通用功能组合</span>
            <span class="c1"># comm hooks 和 apply_optimizer_in_backward。将 inline 导入</span>
            <span class="c1"># 避免循环导入问题。</span>
            <span class="kn">来自</font></font></font></span> <span class="nn">torch.distributed.algorithms.ddp_comm_hooks.mixed_precision_hooks</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="p">(</span>
                <span class="n">_AllreduceUpcastHookState</span><span class="p">,</span>
                <span class="n">_reducer_allreduce_and_upcast_hook</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">upcast_hook_state</span> <span class="o">=</span> <span class="n">_AllreduceUpcastHookState</span><span class="p">(</span>
                <span class="n">ddp 弱引用</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">弱引用</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span>
                <span class="n">提升流</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">流</span><span class="p">(),</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">注册通信钩子</span><span class="p">(</span>
                <span class="n">提升钩子状态</span><span class="p">,</span>
                <span class="n">_reducer_allreduce_and_upcast_hook</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># 通知减少精度参数数据类型的正确性给减少器</span>
            <span class="c1">梯度与桶之间的类型检查次数。</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设置混合精度参数数据类型</font></font></font></span><span class="p">(</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 类型: 忽略[attr-defined]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">混合精度</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数数据类型</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_has_rebuilt_buckets</span> <span class="o">=</span> <span class="kc">假</span>

        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">静态图</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_设置静态图</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_懒加载已执行</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">假</span>

        <span class="c1"># 注册 AccumulateGrad 后置钩子，如果 optimize_ddp 为 True</span>
        <span class="c1"># True。如果 compiled_autograd 未启用，则将取消注册钩子。</span>
        <span class="c1">#</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_accum_grad_hooks</span><span class="p">:</span> <span class="nb">列表</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可移除句柄</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">优化分布式数据并行</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">工具</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取优化分布式数据并行模式</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">使用 Python 缩减器</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">优化分布式数据并行</font></font></font></span> <span class="o">==</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">python_reducer</span>
        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">使用 python_reducer</span><span class="p">:</span>
            <span class="n">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">电磁感抗</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">配置</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">合并 DDP 通信</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
            <span class="n">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">电磁感抗</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">配置</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">合并 DDP 桶大小</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶容量（MB）</span>
            <span class="c1">直接将其添加到跟踪规则中将会干扰使用 DDPOptimizer 的用户</span>
            <span class="c1">的用户。</span>
            <span class="n">火炬</font></font></font></span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">跟踪规则</font></font></font></span><span class="o">.</span><span class="n">LEGACY_MOD_INLINELIST</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">添加</span><span class="p">(</span>
                <span class="s2">torch.nn.parallel.distributed</span>
            <span class="p">)</span>
            <span class="n">火炬</font></font></font></span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">跟踪规则</font></font></font></span><span class="o">.</span><span class="n">get_legacy_mod_inlinelist</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">清除缓存</span><span class="p">()</span>
            <span class="c1"># NOTE: 我们应该延迟初始化这些</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_register_accum_grad_hook</span><span class="p">()</span>

        <span class="c1">是否 DDPSink 执行克隆。</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ddp_sink_clone</span> <span class="o">=</span> <span class="kc">真实</span>

    <span class="k">def</span> <span class="nf">_register_accum_grad_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">导入</font></font></font></span> <span class="nn">torch.distributed._functional_collectives</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">作为</span> <span class="nn">fcol</span>

        <span class="k">def</span> <span class="nf">编译累积梯度钩子</span><span class="p">(</span>
            <span class="n">参数</span><span class="p">,</span>
            <span class="o">*</span><span class="p">,</span>
            <span class="n">参数索引</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">需要反向梯度同步</span><span class="p">:</span>
                <span class="k">返回</span>

            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
                <span class="k">返回</span>

            <span class="k">如果</span> <span class="bp">self</span><span class="o">.</span><span class="n">_comm_hooks</span><span class="p">:</span>
                <span class="k">为</font></font></font></span> <span class="n">hook</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">状态</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</span> <span class="bp">self</span><span class="o">.</span><span class="n">_comm_hooks</span><span class="p">:</span>
                    <span class="n">hook</span><span class="p">(</span><span class="n">状态</font></font></font></span><span class="p">,</span> <span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">研究生</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">))</span>
            <span class="k">否则</span><span class="p">:</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="n">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度</font></font></font></span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程组</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">尺寸</span><span class="p">()</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="n">fcol</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">渐变</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"求和"</font></font></font></span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程组</span><span class="p">)</span>
                <span class="n">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">研究生</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">复制_</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">渐变</span><span class="p">)</span>

        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">索引</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">列举</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块参数</span><span class="p">):</span>
            <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">需要梯度</span><span class="p">:</span>
                <span class="k">继续</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">累积梯度钩子</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">追加</span><span class="p">(</span>
                <span class="n">参数</span><span class="o">.</span><span class="n">register_post_accumulate_grad_hook</span><span class="p">(</span>
                    <span class="n">functools</span><span class="o">.</span><span class="n">偏函数</span><span class="p">(</span>
                        <span class="n">编译后的累积梯度钩子</span><span class="p">,</span>
                        <span class="n">参数索引</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">索引</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">延迟_all_reduce 钩子</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">研究生</span><span class="p">):</span>
        <span class="n">世界大小</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取世界大小</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程组</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">延迟梯度缓冲区</font></font></font></span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">世界大小</font></font></font></span><span class="p">)</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 类型：忽略[联合属性]</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">距离</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">延迟梯度缓冲区</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">群组</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程组</font></font></font></span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
        <span class="p">)</span>
        <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度</span>

    <span class="k">def</span> <span class="nf">注册延迟所有 reduce 钩子</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">桶容量（MB）</span><span class="p">,</span>
        <span class="n">将参数钩子到所有 reduce</span><span class="p">,</span>
        <span class="n">设备 ID</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1">创建渐变缓冲区</span>
        <span class="n">设备</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">否则</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">延迟渐变缓冲区</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">零</span><span class="p">(</span>
            <span class="nb">总和</font></font></font></span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">元素数量</font></font></font></span><span class="p">()</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n">p</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_延迟_all_reduce 参数</span><span class="p">),</span>
            <span class="n">设备</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 2. 广播参数</span>
        <span class="n">分离参数</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n">p</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_延迟_all_reduce 参数</span><span class="p">]</span>
        <span class="n">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_广播合并_</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程组</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分离参数</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶容量（MB）</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># 3. 将所有 reduce 钩子连接到指定的参数</span>
        <span class="n">钩子所有 reduce 的参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">注册钩子</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_延迟所有 reduce 钩子</span><span class="p">)</span>

        <span class="c1"># 4. 构建梯度张量视图</span>
        <span class="n">偏移</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</span> <span class="bp">self</span><span class="o">.</span><span class="n">_delay_all_reduce_params</span><span class="p">:</span>
            <span class="n">grad_view</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_delay_grad_buffer</span><span class="p">[</span><span class="n">偏移</font></font></font></span> <span class="p">:</span> <span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">偏移</font></font></font></span> <span class="o">+</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">元素数量</font></font></font></span><span class="p">())]</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">视图</span><span class="p">(</span>
                <span class="n">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">形状</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_延迟梯度视图</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">追加</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度视图</span><span class="p">)</span>
            <span class="n">偏移</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">偏移</font></font></font></span> <span class="o">+</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">元素数量</span><span class="p">()</span>

        <span class="c1"># 5. 检查所有需要梯度的参数的全量梯度是否延迟。</span>
        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块名称</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名模块</span><span class="p">():</span>
            <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">` 的类型为 List[torch.Tensor]</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名参数。</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">递归</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">):</span>
                <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">需要梯度</span><span class="p">:</span>
                    <span class="n">全名</font></font></font></span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块名称</font></font></font></span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">` 的类型为 List[torch.Tensor]</span><span class="si">}</span><span class="s2">"</span>
                    <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">全名</font></font></font></span> <span class="ow">not</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">要忽略的参数</span><span class="p">:</span>
                        <span class="c1"># 至少有一个参数的所有 reduce 不会延迟。</span>
                        <span class="c1"># 在这种情况下，我们不应设置 self._delay_all_reduce_all_params</span>
                        <span class="c1"># to True.</span>
                        <span class="k">返回</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delay_all_reduce_all_params</span> <span class="o">=</span> <span class="kc">真实</span>

    <span class="k">def</span> <span class="nf">_setup_in_backward_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># 检查用户是否已使用 apply_optim_in_backward 来重叠优化器</span>
        <span class="c1"># 步 + DDP 反向. 当前限制：</span>
        <span class="c1"># 1. 目前只支持 allreduce，不支持自定义通信。</span>
        <span class="c1"># 2. 对于 DDP 管理的参数，如果它们的优化器在</span>
        <span class="c1"># 反向中运行，它们的梯度将被设置为 ``None``。如果您的用例</span>
        <span class="c1"># 在 DDP 参数 grad 设置不为 None 之后，请 ping</span>
        <span class="c1"># 后向优化运行中，请 ping</span>
        <span class="c1"># https://github.com/pytorch/pytorch/issues/90052.</span>
        <span class="c1"># 注意：我们使用 self._module_parameters 而不是.parameters()，因为</span>
        <span class="c1">前者排除忽略的（非 DDP 管理的）参数。</span>
        <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">任何</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</font></font></font></span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_in_backward_optimizers</font></font></font></span><span class="p">)</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n">p</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_parameters</span><span class="p">):</span>
            <span class="n">火炬</font></font></font></span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">ddp.optimizer_in_backward</span><span class="p">)</span>
            <span class="c1">移除因为 apply_optim_in_backward 注册的钩子</span>
            <span class="c1">DDP 根据 allreduce 自定义优化器与反向传播的叠加方式</span>
            <span class="c1">的</span>
            <span class="n">param_to_handle_map</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">优化</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在反向传播中应用优化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数到优化钩子句柄映射</span>
            <span class="p">)</span>
            <span class="k">为</font></font></font></span> <span class="n">p</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_模块参数</span><span class="p">:</span>
                <span class="k">为</font></font></font></span> <span class="n">handle</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数到句柄映射</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="p">[]):</span>
                    <span class="n">处理</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">删除</span><span class="p">()</span>

            <span class="c1">需要将 DDP 实例的弱引用传递给 all_reduce（来自 reducer）</span>
            <span class="c1"># 获取管理的 DDP 参数。</span>
            <span class="n">ddp_weakref</span> <span class="o">=</span> <span class="n">弱引用</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="c1"># 注意：在函数中导入，否则这将导致循环</span>
            <span class="c1">导入。</span>
            <span class="kn">来自</font></font></font></span> <span class="nn">torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="p">(</span>
                <span class="n">_apply_optim_in_backward_hook</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">注册通信钩子</span><span class="p">(</span>
                <span class="n">ddp_weakref</span><span class="p">,</span>
                <span class="n">_apply_optim_in_backward_hook</span><span class="p">(</span>
                    <span class="n">gradient_is_bucket_view</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">渐进式桶视图</span>
                <span class="p">),</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在反向过程中设置优化器</font></font></font></span><span class="p">()</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 类型: 忽略[attr-defined]</span>

    <span class="k">def</span> <span class="nf">触发减少器的自动微分钩子</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">索引</font></font></font></span><span class="p">,</span> <span class="o">*</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">未使用</span><span class="p">):</span>
<span class="w">        </span><span class="sd">""</span>
<span class="sd">触发减少器的自动微分钩子以 allreduce Reducer 桶中的参数。</span>

<span class="sd">请注意，这仅在混合精度训练期间使用</span>
<span class="sd">构造时安装的 Reducer 钩子不会在低精度参数设置时被调用</span>
<span class="sd">因为我们在进行低精度参数设置操作。</span>
<span class="sd">"源代码"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n">_autograd_hook</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">索引</font></font></font></span><span class="p">)</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 类型: 忽略[attr-defined]</span>

    <span class="k">def</span> <span class="nf">_root_copy_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">参数</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">任意</font></font></font></span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">任意</font></font></font></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
<span class="w">        </span><span class="sd">""</span>
<span class="sd">对于 DDP 混合精度，将低精度副本放在单独的流上，并创建事件等待它们。</span>

<span class="sd">当使用 DDP 混合精度进行训练时，此根预前向钩子关闭</span>
<span class="sd">在单独的流上关闭低精度副本，并创建相应的事件等待它们。</span>
<span class="sd">的事件等待它们。</span>
<span class="sd">"源代码"</span>
        <span class="c1">清除之前迭代子模块到事件。这是因为我们</span>
        <span class="c1"># 可能为一些最终没有完成的模块填充了一些事件</span>
        <span class="c1"># 已使用。</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_submodule_to_event</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="n">双端队列</span><span class="p">)</span>  <span class="c1"># type: ignore[var-annotated]</span>
        <span class="k">与</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mp_stream</span><span class="p">:</span>
            <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">子模块</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">():</span>
                <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">子模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">递归</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">):</span>
                    <span class="c1">不要将 DDP 忽略的参数进行类型转换。</span>
                    <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_ddp_ignored</font></font></font></span><span class="p">)</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_ddp_忽略</span><span class="p">:</span>
                        <span class="k">继续</span>
                    <span class="n">_分配存储</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n">_mp_param</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">尺寸</span><span class="p">())</span>
                    <span class="c1"># 模拟拷贝()隐式转换为低精度</span>
                    <span class="k">与</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">不梯度</span><span class="p">():</span>
                        <span class="n">参数</font></font></font></span><span class="o">.</span><span class="n">_mp_param</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">复制_</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">数据</span><span class="p">)</span>
                        <span class="c1"># TODO: 当 zero_grad(set_to_none=False)或处于 grad 中</span>
                        <span class="c1"># 累加情况，累加的梯度可以是 fp32</span>
                        <span class="c1"># 运行 DDP 反向传播时可能会因为</span>
                        <span class="c1"># 进入和累积梯度类型不匹配而引发错误。</span>
                        <span class="c1"># 因此我们现在手动将累积梯度向下转换，</span>
                        <span class="c1"># 未来我们可能转向 FSDP 风格的梯度</span>
                        <span class="c1">累积管理，其中累积梯度</span>
                        <span class="c1"># 已保存且 .grad 字段设置为 None，绕过</span>
                        <span class="c1"># 这个问题。</span>
                        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
                            <span class="n">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">研究生</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">数据</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">研究生</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">到</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">混合精度</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数数据类型</font></font></font></span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 类型：忽略[联合属性]</span>
                            <span class="p">)</span>
                    <span class="n">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">数据</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="o">.</span><span class="n">_mp_param</span>
                <span class="n">复制事件</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">活动</span><span class="p">()</span>
                <span class="n">复制事件</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">记录</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_submodule_to_event</span><span class="p">[</span><span class="n">子模块</font></font></font></span><span class="p">]</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">追加</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">复制事件</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_模块等待复制钩子</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">模块</span><span class="p">,</span>
        <span class="o">*</span><span class="n">参数</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">任意</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">任意</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">无</span><span class="p">:</span>
<span class="w">        </span><span class="sd">在执行计算之前，等待适当的事件以确保低精度复制已完成。</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">事件</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_子模块到事件</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">]</span><span class="o">.</span><span class="n">popleft</span><span class="p">()</span>
        <span class="k">除了</font></font></font></span> <span class="ne"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">索引错误</span><span class="p">:</span>
            <span class="c1"># 复制事件已被等待</span>
            <span class="k">返回</span>

        <span class="n">事件</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">等待</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">流</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">加速器</span><span class="o">.</span><span class="n">current_stream</span><span class="p">())</span>
        <span class="k">为</font></font></font></span> <span class="n">p</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">递归</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">):</span>
            <span class="c1">如果参数不需要梯度，则不要注册钩子</span>
            <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">或</font></font></font></span> <span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</font></font></font></span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_ddp_ignored</font></font></font></span><span class="p">)</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</span> <span class="n">p</span><span class="o">.</span><span class="n">_ddp_ignored</span><span class="p">):</span>
                <span class="k">继续</span>
            <span class="c1">我们需要在这里注册自动微分钩子，而不是 DDP 的构造函数中</span>
            <span class="c1">由于我们正在使用低精度参数，请注册它们</span>
            <span class="c1">通过获取梯度累加器</span>
            <span class="n">临时</font></font></font></span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">展开为</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="n">grad_acc</span> <span class="o">=</span> <span class="n">tmp</span><span class="o">.</span><span class="n">grad_fn</span><span class="o">.</span><span class="n">下一个函数</span><span class="p">[</span><span class="mi">0</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]
[</font></font></font></span><span class="mi">0</span><span class="p">]</span>

            <span class="n">钩子</font></font></font></span> <span class="o">=</span> <span class="n">grad_acc</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">注册钩子</span><span class="p">(</span>
                <span class="n">functools</span><span class="o">.</span><span class="n">偏函数</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fire_reducer_autograd_hook</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">_idx</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">p</span><span class="o">.</span><span class="n">_ddp_mp_hook_state</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad_acc</span><span class="p">,</span> <span class="n">hook</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_log_and_throw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">错误类型</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误信息</span><span class="p">):</span>
        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">日志记录器</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">记录器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设置错误并记录</font></font></font></span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误类型</font></font></font></span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误信息</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">提升</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误类型</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误信息</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_ddp 初始化助手</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">参数</span><span class="p">,</span>
        <span class="n">预期稀疏梯度</span><span class="p">,</span>
        <span class="n">参数到名称映射</span><span class="p">,</span>
        <span class="n">静态图</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">""</span>
<span class="sd">DDP 初始化辅助函数，用于管理参数、梯度钩子、日志和同步 BatchNorm。</span>

<span class="sd">初始化辅助函数，执行以下操作：</span>
<span class="sd">（1）对参数进行桶化以进行缩减</span>
<span class="sd">(2) 重置桶化状态</span>
<span class="sd">(3) 注册梯度钩子</span>
<span class="sd">(4) 记录构造时 DDP 的日志数据</span>
<span class="sd">(5) 将 DDP 句柄传递给 SyncBatchNorm 层</span>
<span class="sd">"源代码"</span>
        <span class="c1">注意，参数的顺序并不是它们被使用的顺序，</span>
        <span class="c1">尤其是在有控制流的模型中。</span>
        <span class="c1">#</span>
        <span class="c1">与参数并列的并不是它们在实际执行中的顺序，</span>
        <span class="c1">如果某个模型恰好也</span>
        <span class="c1">#   1) 在其反向图中具有其他集体通信操作的节点。</span>
        <span class="c1">#   2) 在全球子集排名中存在未使用的参数。</span>
        <span class="c1"># 桶化操作可能会过早地在具有未使用参数的排名上插入 ALL-REDUCE 通信操作，</span>
        <span class="c1"># 与其他排名上的其他集体通信操作意外匹配。</span>
        <span class="c1">#</span>
        <span class="c1">为了处理这种特殊情况，当参数不是实际执行顺序时</span>
        <span class="c1">我们不进行桶划分，因此所有梯度之后只插入一个 ALL-REDUCE</span>
        <span class="c1">图中所有节点数都被计算了。</span>
        <span class="c1">#</span>
        <span class="c1">注意，这里我们仅在第 1 次迭代中禁用分桶。</span>
        <span class="c1">第一次迭代后，可以重建桶，</span>
        <span class="c1">因为“桶重建”根据反向图中的实际执行顺序对参数进行桶化。</span>

        <span class="c1">一旦#73732 合并，可以移除这个分支。</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">静态图</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">或</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n">find_unused_parameters</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">:</span>
            <span class="n">桶大小限制</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">系统</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">最大尺寸</span><span class="p">]</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶字节容量默认值</span><span class="p">:</span>
                <span class="n">桶大小限制</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">默认第一个桶的字节数</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">桶字节容量</span><span class="p">,</span>
                <span class="p">]</span>
            <span class="k">否则</span><span class="p">:</span>
                <span class="n">桶大小限制</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶字节上限</span><span class="p">]</span>
        <span class="p">(</span>
            <span class="n">桶索引</span><span class="p">,</span>
            <span class="n">每桶大小限制</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">根据大小计算桶分配</span><span class="p">(</span>
            <span class="n">参数</span><span class="p">,</span>
            <span class="n">桶大小限制</span><span class="p">,</span>
            <span class="n">预期稀疏梯度</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 记录索引以供混合精度使用，因为我们</span>
        <span class="c1"># 需要通过 Python 将索引传递给 Reducer 的 autograd 钩子。</span>
        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="k">为</font></font></font></span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">列举</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">):</span>
                <span class="n">p</span><span class="o">.</span><span class="n">_idx</span> <span class="o">=</span> <span class="n">i</span>

        <span class="c1"># 注意：反转存储桶列表，因为我们想近似</span>
        <span class="c1">生成梯度的顺序，并假设它们</span>
        <span class="c1">按照定义的顺序在正向传播中使用。</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">减法器</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减法器</span><span class="p">(</span>
            <span class="n">参数</span><span class="p">,</span>
            <span class="nb">列表</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">反转</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶索引</span><span class="p">)),</span>
            <span class="nb">列表</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">反转</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">每个桶的大小限制</span><span class="p">)),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">进程组</span><span class="p">,</span>
            <span class="n">期待稀疏梯度</span><span class="p">,</span>
            <span class="c1">桶大小限制在构造函数中指定。</span>
            <span class="c1">此外，我们允许有一个单独的小桶用于参数</span>
            <span class="c1">首先定义的，这样它们的梯度不会溢出</span>
            <span class="c1"># 添加梯度后，增加一个更大的桶，导致不必要的延迟</span>
            <span class="c1"># 计算完成后。实验表明 1MB 是一个合理的值。</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bucket_bytes_cap</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">find_unused_parameters</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gradient_as_bucket_view</span><span class="p">,</span>
            <span class="n">参数到名称映射</span><span class="p">,</span>
            <span class="c1">用户可以将 dist._DEFAULT_FIRST_BUCKET_BYTES 设置为调整 DDP 首个桶的大小</span>
            <span class="c1">桶。</span>
            <span class="p">(</span>
                <span class="n">距离</span><span class="o">.</span><span class="n">_DEFAULT_FIRST_BUCKET_BYTES</span>
                <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶字节容量默认值</span>
                <span class="k">否则</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶字节容量</span>
            <span class="p">),</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">日志记录器</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">记录器</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">简化器</span><span class="p">)</span>
        <span class="c1"># 设置为弱引用以避免日志记录器和减少器之间的引用循环</span>
        <span class="c1"># 日志记录器和减少器</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设置日志记录器</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">记录器</span><span class="p">)</span>

        <span class="n">具有同步 BN</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">假</span>
        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">子模块</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">():</span>
            <span class="k">如果</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">子模块</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">同步批归一化</span><span class="p">):</span>
                <span class="n">具有同步 BN</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
                <span class="k">断开</span>

        <span class="c1">在构造时设置可获取的日志数据。</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">记录器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设置构造数据并记录日志</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">模块</font></font></font></span><span class="o">.</span><span class="vm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
            <span class="p">[]</span> <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">否则</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</span><span class="p">,</span>
            <span class="o">-</span><span class="mi">1</span> <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出设备</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">否则</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出设备</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">广播缓冲区</span><span class="p">,</span>
            <span class="n">具有同步 BN</span><span class="p">,</span>
            <span class="n">静态图</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 将句柄传递给 torch.nn.SyncBatchNorm 层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_传递同步批归一化句柄</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">检查默认组</span><span class="p">()</span>
        <span class="n">attrs</span> <span class="o">=</span> <span class="n">复制</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">复制</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字典</span><span class="p">)</span>
        <span class="k">删除</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">属性</font></font></font></span><span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"进程组"</span><span class="p">]</span>
        <span class="k">删除</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">属性</font></font></font></span><span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">减法器</span><span class="p">]</span>
        <span class="k">删除</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">属性</font></font></font></span><span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">记录器</span><span class="p">]</span>
        <span class="k">返回</span> <span class="n">attrs</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">状态</span><span class="p">):</span>
        <span class="c1">如果可序列化，则进程组应为默认组</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">流程组</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取默认组</span><span class="p">()</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">状态</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">字典</font></font></font></span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">require_forward_param_sync</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">字典</font></font></font></span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">require_backward_grad_sync</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">参数</span><span class="p">,</span> <span class="n">expect_sparse_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_params_for_reducer</span><span class="p">()</span>
        <span class="c1"># 在调试模式下，构建参数索引 -&gt; 参数的映射。</span>
        <span class="n">参数到名称映射</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">构建调试参数到名称的映射</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">)</span>
        <span class="c1">构建 reducer。</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ddp_init_helper</span><span class="p">(</span>
            <span class="n">参数</span><span class="p">,</span>
            <span class="n">预期稀疏梯度</span><span class="p">,</span>
            <span class="n">参数到名称映射</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">静态图</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">静态图</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_设置静态图</span><span class="p">()</span>
            <span class="k">断言</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">日志记录器</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">记录器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_设置静态图</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">构建用于 reducer 的参数</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># 为所有需要梯度的参数构建（模块，参数）元组。</span>
        <span class="n">模块和参数</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">模块</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">)</span>
            <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块名称</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名模块</span><span class="p">()</span>
            <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</span> <span class="p">[</span>
                <span class="n">参数</span>
                <span class="c1">请注意，我们访问 module.named_parameters 而不是</span>
                <span class="c1"># 参数(module). 仅在需要使用模块参数时才需要 parameters(module)</span>
                <span class="c1">单进程多设备案例，其中它访问复制的</span>
                <span class="c1">通过 _former_parameters 参数。</span>
                <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">` 的类型为 List[torch.Tensor]</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名参数。</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">递归</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">)</span>
                <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="o">.</span><span class="n">requires_grad</span>
                <span class="ow">和</font></font></font></span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块名称</font></font></font></span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">` 的类型为 List[torch.Tensor]</font></font></font></span><span class="si">}</span><span class="s2">"</span> <span class="ow">not</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">忽略的参数</span>
            <span class="p">]</span>
        <span class="p">]</span>

        <span class="c1"># 在子模块之间删除任何共享的参数。</span>
        <span class="n">备忘录</font></font></font></span> <span class="o">=</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">集合</span><span class="p">()</span>
        <span class="n">模块和参数</span> <span class="o">=</span> <span class="p">[</span>
            <span class="c1"># "p 不在 memo 中" 是去重检查。</span>
            <span class="c1">"not memo.add(p)" 总是 True，只是为了在需要时执行 "add(p)"。</span>
            <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
            <span class="k">为</font></font></font></span> <span class="n">m</span><span class="p">,</span> <span class="n">p</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块与参数</span>
            <span class="k">如果</font></font></font></span> <span class="n">p</span> <span class="ow">not</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">备忘录</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="ow">not</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">描述</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">添加</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>  <span class="c1"># type: ignore[func-returns-value]</span>
        <span class="p">]</span>

        <span class="c1"># 构建参数列表。</span>
        <span class="n">参数</font></font></font></span> <span class="o">=</span> <span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n">_</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块和参数</span><span class="p">]</span>

        <span class="c1"># 检查一个模块是否会生成稀疏梯度。</span>
        <span class="k">def</span> <span class="nf">生成稀疏梯度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">):</span>
            <span class="k">如果</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="p">,</span> <span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">嵌入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">EmbeddingBag</span><span class="p">)):</span>
                <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">稀疏的</span>
            <span class="k">返回</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">假</span>

        <span class="c1"># 构建一个布尔值列表，表示是否期望稀疏</span>
        <span class="c1"># 对应参数的梯度。</span>
        <span class="n">期待稀疏梯度</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">生成稀疏梯度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="p">)</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="p">,</span> <span class="n">_</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块与参数</span>
        <span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_分配模块缓冲区</span><span class="p">()</span>

        <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">预期稀疏梯度</span>

    <span class="k">def</span> <span class="nf">_分配模块缓冲区</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">""</span>
<span class="sd">将 self.module.named_buffers 分配给 self.modules_buffers。</span>

<span class="sd">将模块缓冲区分配给 self.modules_buffers，然后当 broadcast_buffers=True 时广播到各个进程。注意，这</span>
<span class="sd">些缓冲区将被广播到各个进程。注意，这</span>
<span class="sd">每次需要同步缓冲区时都必须调用，因为缓冲区可能会被用户模块重新分配。</span>
<span class="sd">请参阅 https://github.com/pytorch/pytorch/issues/63916。</span>
<span class="sd">收集模块的缓冲区，过滤掉应该被忽略的缓冲区。</span>
<span class="sd">"源代码"</span>
        <span class="c1"># 收集模块的缓冲区，过滤掉应该被忽略的缓冲区。</span>
        <span class="n">命名模块缓冲区</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">缓冲区</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区名称</span><span class="p">)</span>
            <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区名称</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名缓冲区</span><span class="p">()</span>
            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区名称</font></font></font></span> <span class="ow">not</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">要忽略的参数</span>
        <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">模块缓冲区</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">缓冲区</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区名称</font></font></font></span><span class="p">)</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名模块缓冲区</span>
        <span class="p">]</span>
        <span class="c1">表示未由 DDP 忽略的模块缓冲区的字典[str, tensor]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">命名模块缓冲区</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">缓冲区名称</font></font></font></span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区名称</font></font></font></span><span class="p">)</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名模块缓冲区</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">构建调试参数到名称映射的_build_debug_param_to_name_mapping</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">):</span>
        <span class="n">参数到参数索引</font></font></font></span> <span class="o">=</span> <span class="p">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">[</span><span class="n">i</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]：</font></font></font></span> <span class="n">i</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n">i</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">范围</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">))}</span>
        <span class="n">参数集</font></font></font></span> <span class="o">=</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">集合</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">)</span>
        <span class="n">参数索引到参数全称</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块名称</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名模块</span><span class="p">():</span>
            <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">` 的类型为 List[torch.Tensor]</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名参数。</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">递归</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">):</span>
                <span class="n">完全限定名</font></font></font></span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块名称</font></font></font></span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">` 的类型为 List[torch.Tensor]</span><span class="si">}</span><span class="s2">"</span>
                <span class="c1"># 跳过忽略的参数，因为那些参数不会被 DDP 减少</span>
                <span class="c1"># 首先。</span>
                <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">完全限定名</font></font></font></span> <span class="ow">not</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  "># 要忽略的参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">需要梯度</span><span class="p">:</span>
                    <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow">not</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数集</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span>
                            <span class="ne">ValueError</span><span class="p">,</span>
                            <span class="sa">f</span><span class="s2">"参数名为</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">完全限定名</font></font></font></span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在模块参数中找到，但不在 DDP 参数中。</span>
                            <span class="s2">"这表明 DDP 中存在一个错误，请向 PyTorch 报告问题。"</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="n">参数索引</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数到参数索引</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">]</span>
                    <span class="n">参数索引到参数全称</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数索引</font></font></font></span><span class="p">]</span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">完全限定名</span>

        <span class="c1">确保我们涵盖了所有参数</span>
        <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数集</font></font></font></span><span class="p">)</span> <span class="o">!=</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</span><span class="p">(</span><span class="n">param_index_to_param_fqn</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span>
                <span class="ne">ValueError</span><span class="p">,</span>
                <span class="p">(</span>
                    <span class="s2">预期参数到名称映射应涵盖所有参数，但实际上</span>
                    <span class="sa">f</span><span class="s2">出现了冲突的长度：</font></font></font></span><span class="si">{</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数集</font></font></font></span><span class="p">)</span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">与 " 相比</span>
                    <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb">长度</font></font></font></span><span class="p">(</span><span class="n">param_index_to_param_fqn</span><span class="p">)</span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">这表明 DDP 中存在一个 bug</span>
                    <span class="s2">，请向 PyTorch 报告一个问题。</span>
                <span class="p">),</span>
            <span class="p">)</span>

        <span class="k">返回</span> <span class="n">param_index_to_param_fqn</span>

    <span class="k">def</span> <span class="nf">获取参数</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">递归</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">返回模块参数的生成器。</span>

        <span class="k">def</span> <span class="nf">模型参数</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
            <span class="n">ps</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">m</span><span class="o">.</span><span class="n">_former_parameters</span><span class="o">.</span><span class="n">值</span><span class="p">()</span>
                <span class="k">如果</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</font></font></font></span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_前参数</span><span class="p">)</span>
                <span class="k">否则</font></font></font></span> <span class="n">m</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">递归</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">yield from</span> <span class="n">ps</span>

        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">修饰</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n">m</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="p">()</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">递归</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">否则</font></font></font></span> <span class="p">[</span><span class="n">m</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]：</span>
            <span class="k">yield from</span> <span class="n">模型参数</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_检查默认组</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">不支持 pickle</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">假</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">流程组</font></font></font></span> <span class="o">!=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取默认组</span><span class="p">():</span>
                <span class="n">不支持 pickle</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
        <span class="k">除了</font></font></font></span> <span class="ne"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">运行时错误</span><span class="p">:</span>
            <span class="n">pickle 不支持</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>

        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">pickle 不支持</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span>
                <span class="ne">运行时错误</span><span class="p">,</span>
                <span class="s2">"DDP Pickling/Unpickling 仅支持"</span>
                <span class="s2">"当使用默认进程的 DDP 时"</span>
                <span class="s2">"组。也就是说，当你调用"</span>
                <span class="s2">"init_process_group 并且没有传递"</span>
                <span class="s2">"process_group 参数给 DDP 构造函数"</span><span class="p">,</span>
            <span class="p">)</span>

<div class="viewcode-block" id="DistributedDataParallel.no_sync"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]    @contextmanager
def no_sync(self):
r"""
禁用 DDP 进程间梯度同步的上下文管理器。

在此上下文中，梯度将在模块上累积
变量，稍后将与第一个同步
前向-后向传递退出上下文。

示例：

&gt;&gt;&gt; # xdoctest: +忽略("未定义变量")
&gt;&gt;&gt; ddp = torch.nn.parallel.DistributedDataParallel(model, pg)
&gt;&gt;&gt; with ddp.no_sync():
&gt;&gt;&gt;     for input in inputs:
&gt;&gt;&gt;         ddp(input).backward()  # 无同步，累加梯度
&gt;&gt;&gt; ddp(another_input).backward()  # 同步梯度

.. 警告：
前向传播应包含在上下文管理器内
否则梯度仍然会同步。
"""
old_require_backward_grad_sync = self.require_backward_grad_sync
self.require_backward_grad_sync = False
try:
yield
finally:
self.require_backward_grad_sync = old_require_backward_grad_sync</font></font></font></div>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">获取活动 DDP 模块</font></font></font></span><span class="p">(</span><span class="bp"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</span><span class="p">):</span>
<span class="w">        </span><span class="sd">`TorchDynamo`需要 DDP 的状态和模块以进行协同优化。</span>
        <span class="k">返回</font></font></font></span> <span class="bp"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类</span><span class="o">.</span><span class="n">_active_ddp_module</span>

    <span class="c1"># 注意，此 ctxmgr 函数在 torchdynamo 中被标记为'skip'，因此 dynamo 不会启动</span>
    <span class="c1">'用于“module_to_run”下'</span>
    <span class="c1">'请参阅 torch._dynamo/eval_frame.py 中的 TorchPatcher.patch 以获取更多详细信息'</span>
    <span class="nd">@contextmanager</span>
    <span class="nd">@torch</span><span class="o">.</span><span class="n">_禁用_dynamo</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">递归</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">'_inside_ddp_forward'</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">分布式数据并行</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">'_active_ddp_module'</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">产生</span>
        <span class="k">最后</span><span class="p">:</span>
            <span class="n">分布式数据并行</font></font></font></span><span class="o">.</span><span class="n">_active_ddp_module</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>

    <span class="k">def</span> <span class="nf">_run_ddp_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">输入</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">如果</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_python_reducer</span><span class="p">:</span>
            <span class="k">返回</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="p">(</span><span class="o">*</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">忽略索引</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="k">与</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inside_ddp_forward</span><span class="p">():</span>
                <span class="k">返回</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="p">(</span><span class="o">*</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">忽略索引</span>

    <span class="k">def</span> <span class="nf">清除梯度缓冲区</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># 假设梯度累积是在 autograd 引擎中就地进行的，基于此，在反向传播之前，param.grad 指向的 grad buffers 是</span>
        <span class="c1"># 假设梯度累积是在 autograd 引擎中就地进行的，基于此，在反向传播之前，param.grad 指向的 grad buffers 是</span>
        <span class="c1"># 对于某些边缘情况，如果 autograd 引擎中的梯度累积不是就地进行的，</span>
        <span class="c1"># 然后将 param.grad 和 grad 缓冲区断开连接。</span>
        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_延迟梯度缓冲区</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="c1"># 我们通过重置整个梯度缓冲区来批量执行所有 params 的 zero_grad。</span>
            <span class="c1"># 当所有 params 的梯度设置为 None 时。</span>
            <span class="n">所有参数梯度为空</font></font></font></span> <span class="o">=</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">所有</span><span class="p">(</span>
                <span class="n">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">延迟所有 reduce 参数</span>
            <span class="p">)</span>

            <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">索引</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">列举</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_延迟_all_reduce 参数</span><span class="p">):</span>
                <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
                    <span class="n">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">延迟梯度视图</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">索引</span><span class="p">]</span>
                    <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">所有参数梯度无</span><span class="p">:</span>
                        <span class="n">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">研究生</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">零_</span><span class="p">()</span>

            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">所有参数梯度无</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">延迟梯度缓冲区</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">零_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_lazy_init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># 构造后但延迟初始化的 DDP 初始化</span>
        <span class="c1">在第一次前向传递之前。</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">在反向优化器中设置。</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_懒加载已执行</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>

    <span class="k">def</span> <span class="nf">_pre_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">输入</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">使用 Python 缩减器。</span><span class="p">:</span>
            <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</span><span class="p">,</span> <span class="n">kwargs</span>

        <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_懒加载已执行</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="ow">not</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">编译器</span><span class="o">.</span><span class="n">is_compiling</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_lazy_init</span><span class="p">()</span>

        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">延迟所有 reduce_all_params</span><span class="p">:</span>
            <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</span><span class="p">,</span> <span class="n">kwargs</span>

        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度是否启用</font></font></font></span><span class="p">()</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">需要反向梯度同步</span><span class="p">:</span>
            <span class="k">断言</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">日志记录器</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">记录器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设置运行时统计和日志</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">准备前向</span><span class="p">()</span>

        <span class="c1"># 通知加入上下文，此进程尚未加入</span>
        <span class="c1"># 如果需要</span>
        <span class="n">工作</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">加入</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">通知加入上下文</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">工作</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">简化器</span><span class="o">.</span><span class="n">_set_forward_pass_work_handle</span><span class="p">(</span>
                <span class="n">工作</font></font></font></span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">根据初始世界大小进行除法</span>  <span class="c1"># type: ignore[arg-type]</span>
            <span class="p">)</span>

        <span class="c1"># 在前向计算之前调用 _rebuild_buckets，</span>
        <span class="c1">在释放旧桶之前可能分配新的桶</span>
        <span class="c1">在_rebuild_buckets 中。为了节省峰值内存使用，</span>
        <span class="c1">在峰值内存使用增加之前调用_rebuild_buckets</span>
        <span class="c1">在前向计算期间。</span>
        <span class="c1">在整个训练期间只能调用一次。</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度是否启用</font></font></font></span><span class="p">()</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_重建桶</span><span class="p">():</span>
            <span class="n">记录器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">信息</font></font></font></span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"在本迭代中已重建减少器桶。"</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_has_rebuilt_buckets</span> <span class="o">=</span> <span class="kc">真实</span>

        <span class="c1">根据位置（前向/后向）同步参数（用户）</span>
        <span class="c1"># 指定作为钩子的一部分，如果指定了钩子。</span>
        <span class="k">如果</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_sync_bufs_pre_fwd</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_buffers</span><span class="p">()</span>

        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n">_join_config</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">启用</span><span class="p">:</span>
            <span class="c1"># 通知加入的队列是否应该在反向传递中进行同步。</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">检查全局反向梯度同步需求</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是否已连接的 rank</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">)</span>

        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</span><span class="p">:</span>
            <span class="n">移动的输入</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">移动的关键字参数</span> <span class="o">=</span> <span class="n">_to_kwargs</span><span class="p">(</span>
                <span class="n">输入</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="p">,</span>
                <span class="n">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备类型</font></font></font></span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</font></font></font></span><span class="p">[</span><span class="mi">0</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">)]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">使用侧流进行张量复制</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">参数</font></font></font></span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">移动输入</font></font></font></span><span class="p">[</span><span class="mi">0</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">移动参数</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1">如有必要，将输入转换为低精度。</span>
            <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
                <span class="n">参数</font></font></font></span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_将前向输入转换为低精度</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">混合精度</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数数据类型</span><span class="p">,</span>
                    <span class="o">*</span><span class="n">参数</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">,</span> <span class="n">kwargs</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="c1">如有必要，将输入转换为低精度。</span>
            <span class="c1"># TODO (rohan-varma) 测试此代码路径。</span>
            <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">混合精度</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
                <span class="n">输入</font></font></font></span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_向前传递输入</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">混合精度</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数数据类型</span><span class="p">,</span>
                    <span class="o">*</span><span class="n">输入</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</span><span class="p">,</span> <span class="n">kwargs</span>

    <span class="k">def</span> <span class="nf">_post_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">输出</span><span class="p">):</span>
        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_使用 Python 聚合器</span><span class="p">:</span>
            <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</span>

        <span class="k">如果</span> <span class="bp">self</span><span class="o">.</span><span class="n">_delay_all_reduce_all_params</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_clear_grad_buffer</span><span class="p">()</span>
            <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</span>

        <span class="c1"># 根据位置（前/后 forward）同步参数（用户指定）</span>
        <span class="c1"># 如果指定了 hook，则作为 hook 的一部分指定。</span>
        <span class="k">如果</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_sync_bufs_post_fwd</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_buffers</span><span class="p">()</span>

        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度是否启用</font></font></font></span><span class="p">()</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</span> <span class="bp">self</span><span class="o">.</span><span class="n">require_backward_grad_sync</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">require_forward_param_sync</span> <span class="o">=</span> <span class="kc">真实</span>
            <span class="c1"># 我们将原封不动地返回输出对象，因为它是自由形式的</span>
            <span class="c1"># 因为我们需要找出这个对象中的任何张量，</span>
            <span class="c1"># 因为我们需要确定在这次前向传递中使用了哪些参数，</span>
            <span class="c1"># 以确保我们为任何需要短路减少的情况</span>
            <span class="c1"># 未使用参数。仅在 `find_unused_parameters` 设置时使用。</span>
            <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n">find_unused_parameters</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">静态图</span><span class="p">:</span>
                <span class="c1"># 对于静态图不需要填充此信息。</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">准备反向操作</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">列表</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">查找张量</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</span><span class="p">)))</span>
            <span class="k">否则</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">准备反向操作</span><span class="p">([])</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">require_forward_param_sync</span> <span class="o">=</span> <span class="kc">假</span>

        <span class="c1">DDPSink 目前启用检测未使用参数</span>
        <span class="c1">静态图训练第一次迭代</span>
        <span class="k">如果</font></font></font></span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">查找未使用参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">静态图</font></font></font></span><span class="p">)</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">或</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">静态图</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_静态图延迟_allreduce_enqueued</span>
        <span class="p">):</span>
            <span class="p">(</span>
                <span class="n">输出张量列表</span><span class="p">,</span>
                <span class="n">树规范</span><span class="p">,</span>
                <span class="n">输出为 rref</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">使用_rref 进行树扁平化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</span><span class="p">)</span>
            <span class="n">输出占位符</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">列表</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可选</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span>
                <span class="kc">无</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">为</font></font></font></span> <span class="n">_</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">范围</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出张量列表</span><span class="p">))</span>
            <span class="p">]</span>
            <span class="c1">不要触摸没有 grad_fn 的 tensor，这可能会引发问题</span>
            <span class="c1">例如：https://github.com/pytorch/pytorch/issues/60733</span>
            <span class="k">为</font></font></font></span> <span class="n">i</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">列举</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出张量列表</span><span class="p">):</span>
                <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</font></font></font></span><span class="p">)</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</font></font></font></span><span class="o">.</span><span class="n">grad_fn</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
                    <span class="n">输出占位符</font></font></font></span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</span>

            <span class="c1">当 find_unused_parameters=True 时，生成需要梯度的张量</span>
            <span class="c1"># 通过 DDPSink 反向传播。当不是所有输出都</span>
            <span class="c1"># 用于损失时，这会使相应的张量接收</span>
            <span class="c1">未定义的梯度，然后由 reducer 处理以确保</span>
            <span class="c1">不修改 param.grad 字段，我们也不会出错。</span>
            <span class="n">透传张量列表</font></font></font></span> <span class="o">=</span> <span class="n">_DDPSink</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">应用</span><span class="p">(</span>
                <span class="n">弱引用</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span>
                <span class="o">*</span><span class="n">输出张量列表</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">为</font></font></font></span> <span class="n">i</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">范围</font></font></font></span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出占位符</span><span class="p">)):</span>
                <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出占位符</font></font></font></span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
                    <span class="n">输出占位符</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">passthrough_tensor_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="c1"># 重建输出数据结构。</span>
            <span class="n">输出</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">使用 rref 展开树</span><span class="p">(</span>
                <span class="n">output_placeholders</span><span class="p">,</span> <span class="n">树规范</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出是 rref</span>
            <span class="p">)</span>

        <span class="c1"># 前向传播结束后，重置梯度缓冲区和梯度视图</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">清除梯度缓冲区</span><span class="p">()</span>
        <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</span>

    <span class="k">def</span> <span class="nf">前向</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">与</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">自动微分</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">分析器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">记录功能</font></font></font></span><span class="p">(</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">DistributedDataParallel.forward</span><span class="p">):</span>
            <span class="n">输入</font></font></font></span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pre_forward</span><span class="p">(</span><span class="o">*</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">输出</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">前向</font></font></font></span><span class="p">(</span><span class="o">*</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="k">如果</span> <span class="bp">self</span><span class="o">.</span><span class="n">_delay_all_reduce_all_params</span>
                <span class="k">否则</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_ddp_forward</span><span class="p">(</span><span class="o">*</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">返回</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_forward</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">分散</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</span><span class="p">):</span>
        <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">scatter 参数</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输入</font></font></font></span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">暗淡</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">暗淡</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">输入</font></font></font></span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</span><span class="p">):</span>
        <span class="c1">为向后兼容保留</span>
        <span class="k">返回</span> <span class="n">_to_kwargs</span><span class="p">(</span>
            <span class="n">输入</span><span class="p">,</span>
            <span class="n">kwargs</span><span class="p">,</span>
            <span class="n">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备类型</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备 ID</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">使用侧流进行张量复制</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">收集</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出设备</span><span class="p">):</span>
        <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">收集</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">输出设备</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">暗淡</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">暗淡</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">训练</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模式</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">超级</font></font></font></span><span class="p">()</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">训练</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模式</span><span class="p">)</span>
        <span class="k">返回</span> <span class="bp">self</span>

    <span class="c1">当以连接模式运行时，安排一个 allreduce 来通知已连接的进程</span>
    <span class="c1">是否将在本次迭代运行反向传播同步。</span>
    <span class="k">def</span> <span class="nf">_check_global_requires_backward_grad_sync</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_joined_rank</span><span class="p">):</span>
        <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">已加入排名</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">需要反向梯度同步</span><span class="p">:</span>
            <span class="n">需要同步张量</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">一</font></font></font></span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">)</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="n">需要同步张量</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">零</font></font></font></span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">)</span>

        <span class="n">工作</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span>
            <span class="n">需要同步张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">群组</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程组</font></font></font></span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
        <span class="p">)</span>

        <span class="c1"># (kwen2501) 这个 if 条件是之前内容的直接翻译</span>
        <span class="c1"># behavior，即当`is_joined_rank=False`时，`work.wait()`</span>
        <span class="c1"># 没有被调用，它也不关心结果。我在猜测</span>
        <span class="c1">它只想触发一个匹配的全量减少操作，而不想</span>
        <span class="c1">主流等待。</span>
        <span class="k">如果</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">is_joined_rank
是已加入排名</font></font></font></span><span class="p">:</span>
            <span class="n">工作</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">等待</span><span class="p">()</span>
            <span class="n">应该向后同步</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">需要同步张量</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">项目</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span>
            <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">应该向后同步</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="k">返回</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span>  <span class="c1"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">返回值不应/不应该被使用。</span>

    <span class="c1">当以连接模式运行时，如果模型有在正向传播中应该同步的缓冲区，则检查并执行模块缓冲区的同步。</span>
    <span class="c1"># 在正向传播中应该同步的缓冲区。</span>
    <span class="k">def</span> <span class="nf">_check_and_sync_module_buffers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">如果</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_sync_bufs_pre_fwd</span><span class="p">():</span>
            <span class="n">权威排名</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_common_rank</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distributed_rank</span><span class="p">,</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_module_buffers</span><span class="p">(</span><span class="n">权威排名</span><span class="p">)</span>

    <span class="c1"># 当在联合模式下运行时，就共同排名和广播模式达成一致</span>
    <span class="c1"># 将参数广播到所有其他排名</span>
    <span class="k">def</span> <span class="nf">_sync_final_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_last_joiner</span><span class="p">):</span>
        <span class="c1">达成一致，确定将作为权威模型副本的过程。</span>
        <span class="c1">当前排名是权威副本的候选者，如果</span>
        <span class="c1">is_last_joiner=True。我们通过选择较大的排名来打破平局。</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">权威排名</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">查找共同排名</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">分布式排名</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是否为最后一个加入者</span>
        <span class="p">)</span>
        <span class="n">同步模块状态</span><span class="p">(</span>
            <span class="n">模块</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">,</span>
            <span class="n">进程组</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程组</span><span class="p">,</span>
            <span class="n">广播桶大小</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">广播桶大小</span><span class="p">,</span>
            <span class="n">源</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">权威排名</span><span class="p">,</span>
            <span class="n">要忽略的参数和缓冲区</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">要忽略的参数</span><span class="p">,</span>
            <span class="n">广播缓冲区</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">广播缓冲区</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1">将通信操作调度与在 reducer 的逆向调度中安排的调度相匹配</span>
    <span class="c1">通过。</span>
    <span class="k">def</span> <span class="nf">_match_all_reduce_for_bwd_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">通信工作</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1">以与 Reducer 安排相同的顺序调度通信，即</span>
        <span class="c1">从 reducer 中检索桶的顺序</span>
        <span class="c1">确保在连接模式下保持相同的顺序，例如在动态重建顺序时</span>
        <span class="c1"># 顺序</span>

        <span class="c1">返回按顺序排列的 grad_buckets，但用实际的张量替换了</span>
        <span class="c1">同形状的零张量</span>
        <span class="n">梯度桶</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">简化器</span><span class="o">.</span><span class="n">_get_zeros_like_grad_buckets</span><span class="p">()</span>
        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">梯度桶</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">grad_buckets
梯度桶</font></font></font></span><span class="p">:</span>
            <span class="c1">进程加入不贡献梯度。在情况下</span>
            <span class="c1"># divide_by_initial_world_size=True, 我们将梯度除以初始世界大小</span>
            <span class="c1">世界大小，如果没有，则除数减少</span>
            <span class="c1">参与进程的数量。</span>
            <span class="n">工作</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">运行通信钩子。</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">累加桶。</span><span class="p">)</span>
            <span class="n">通信工作。</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">追加</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">工作</span><span class="p">)</span>
        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">工作</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</span> <span class="n">comm_work</span><span class="p">:</span>
            <span class="n">工作</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">等待</span><span class="p">()</span>

    <span class="c1">所有进程都减少了跨 rank 使用的参数映射。</span>
    <span class="k">def</span> <span class="nf">_match_unused_params_allreduce</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">本地使用的参数映射</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取本地已用地图</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">进程组</font></font></font></span><span class="o">.</span><span class="n">allreduce</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">本地已用参数地图</span><span class="p">)</span>

<div class="viewcode-block" id="DistributedDataParallel.join"><a class="viewcode-back" href="../../../../generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.join">[文档]</font></font></font></a>    <span class="k">def</span> <span class="nf"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">加入</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">除以初始世界大小</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔类型</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">启用</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔类型</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">抛出早期终止</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔类型</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">""</span>
<span class="sd">DDP 中处理进程间输入不均匀的上下文管理器。</span>

<span class="sd">此上下文管理器将跟踪已加入的 DDP 进程，</span>
<span class="sd">并通过插入集体通信操作来“阴影”前向和反向传递，以匹配非加入进程创建的操作。</span>
<span class="sd">这样可以确保每个集体调用都有一个相应的操作。</span>
<span class="sd">这将确保每个集体调用都有一个相应的操作。</span>
<span class="sd">通过已连接的 DDP 进程调用，防止因进程间输入不均匀而导致的挂起或错误</span>
<span class="sd">在训练过程中，否则可能会发生此类错误</span>
<span class="sd">如果将标志`throw_on_early_termination`指定为`True`，一旦有一个 rank</span>
<span class="sd">抛出错误，所有训练器都将抛出错误</span>
<span class="sd">输入用尽，允许捕获和处理这些错误</span>
<span class="sd">根据应用逻辑。</span>

<span class="sd">一旦所有 DDP 进程都已加入，上下文管理器将广播</span>
<span class="sd">模型对应于最后加入的所有进程</span>
<span class="sd">确保所有进程中的模型相同</span>
<span class="sd">（由 DDP 保证）。</span>

<span class="sd">要使用此方法启用进程间输入不均匀的训练，</span>
<span class="sd">简单地将此上下文管理器包装在您的训练循环中。无需进一步</span>
<span class="sd">模型或数据加载需要修改。</span>

<span class="sd">.. 警告::</span>
<span class="sd">如果该上下文管理器包装的模型或训练循环</span>
<span class="sd">具有额外的分布式集体操作，例如</span>
<span class="sd">模型前向传播中的 `SyncBatchNorm`，然后设置标志</span>
<span class="sd">必须启用 `throw_on_early_termination`。这是因为这</span>
<span class="sd">上下文管理器不了解非 DDP 集体通信。</span>
<span class="sd">此标志将导致所有等级在任何一个等级抛出异常</span>
<span class="sd">耗尽输入，允许捕获并恢复这些错误</span>
<span class="sd">来自所有等级。</span>

<span class="sd">        Args:</span>
<span class="sd">divide_by_initial_world_size (bool): 如果 ``True``，将根据初始 ``world_size`` 分割梯度。DDP 训练是以该 ``world_size`` 启动的。如果 ``False``，将计算有效世界大小。</span>
<span class="sd">梯度将根据初始 ``world_size`` 进行分割。DDP 训练是以该 ``world_size`` 启动的。</span>
<span class="sd">如果 ``False``，将计算有效世界大小。</span>
<span class="sd">（尚未耗尽输入的排名数量）和</span>
<span class="sd">将梯度在整个 allreduce 过程中除以那个值。设置</span>
<span class="sd"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">将输入的文本翻译为简体中文如下：

``按初始世界大小除=True`` 以确保每个输入</font></font></font></span>
<span class="sd">样本中不均匀的输入在权重上相等</span>
<span class="sd">他们对全球梯度贡献了多少。这是</span>
<span class="sd">通过始终将梯度除以初始值来实现的</span>
<span class="sd">即使遇到不均匀的输入，也会这样做。如果您将其设置为“False”，则将梯度除以剩余的</span>
<span class="sd">这将导致梯度被除以剩余的值</span>
<span class="sd">节点数量。这确保了与较小数据集训练的均衡性。</span>
<span class="sd">``world_size`` 虽然这也意味着不均匀的输入会更多地影响全局梯度。</span>
<span class="sd">通常情况下，您希望将此设置为 ``True``，以便在最后几个样本对全局梯度影响更大的情况下。</span>
<span class="sd">您可能希望将其设置为 ``True``，以应对此类情况。</span>
<span class="sd">您的训练作业输入不均匀。在极端情况下，当输入数量差异很大时，将其设置为 ``False`` 可能会提供更好的结果。</span>
<span class="sd">启用（布尔值）：是否启用不均匀输入检测。传递</span>
<span class="sd">该参数为 ``False`` 时，将关闭不均匀输入检测。</span>
<span class="sd">enable（布尔值）：是否启用不均匀输入检测。</span>
<span class="sd">在 ``enable=False`` 中禁用，在你知道的情况下</span>
<span class="sd">输入在参与进程中均匀分布。默认为</span>
<span class="sd">``True``，则进行交换。</span>
<span class="sd">抛出早期终止错误（布尔值）：是否抛出错误</span>
<span class="sd">或至少有一个等级耗尽时继续训练</span>
<span class="sd">输入。如果为 ``True``，则在第一个排名到达数据末尾时抛出异常</span>
<span class="sd">。如果为 ``False``，则使用更小的有效世界大小继续训练，直到所有排名都加入</span>
<span class="sd">。注意，如果指定了此标志，则该标志</span>
<span class="sd">...</span>
<span class="sd">``divide_by_initial_world_size`` 将被忽略。默认</span>
<span class="sd">是 ``False``。</span>


<span class="sd">示例::</span>

<span class="sd">&gt;&gt;&gt; # xdoctest: +SKIP("分布式")</span>
<span class="sd">&gt;&gt;&gt; 导入 torch</span>
<span class="sd">&gt;&gt;&gt; 导入 torch.distributed 作为 dist</span>
<span class="sd">&gt;&gt;&gt; 导入 os</span>
<span class="sd">&gt;&gt;&gt; 导入 torch.multiprocessing 模块</span>
<span class="sd">&gt;&gt;&gt; 从 torch.nn 导入 nn</span>
<span class="sd">&gt;&gt;&gt; # 在每个创建的进程中</span>
<span class="sd">            &gt;&gt;&gt; def worker(rank):</span>
<span class="sd">            &gt;&gt;&gt;     dist.init_process_group("nccl", rank=rank, world_size=2)</span>
<span class="sd">            &gt;&gt;&gt;     torch.cuda.set_device(rank)</span>
<span class="sd">            &gt;&gt;&gt;     model = nn.Linear(1, 1, bias=False).to(rank)</span>
<span class="sd">            &gt;&gt;&gt;     model = torch.nn.parallel.DistributedDataParallel(</span>
<span class="sd">            &gt;&gt;&gt;         model, device_ids=[rank], output_device=rank</span>
<span class="sd">            &gt;&gt;&gt;     )</span>
<span class="sd">&gt;&gt;&gt;     # 排名 1 比排名 0 多一个输入。</span>
<span class="sd">            &gt;&gt;&gt;     inputs = [torch.tensor([1]).float() for _ in range(10 + rank)]</span>
<span class="sd">            &gt;&gt;&gt;     with model.join():</span>
<span class="sd">            &gt;&gt;&gt;         for _ in range(5):</span>
<span class="sd">            &gt;&gt;&gt;             for inp in inputs:</span>
<span class="sd">&gt;&gt;&gt;                 损失 = 模型(inp).sum()</span>
<span class="sd">&gt;&gt;&gt;                 损失.backward()</span>
<span class="sd">&gt;&gt;&gt;     # 没有使用 join() API，下面的同步将会挂起</span>
<span class="sd">&gt;&gt;&gt;     # 等待 rank 1 的 allreduce 完成。</span>
<span class="sd">            &gt;&gt;&gt;     torch.cuda.synchronize(device=rank)</span>
<span class="sd">"源代码"</span>
        <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">加入</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="p">]</span>
            <span class="n">启用</span><span class="p">,</span>
            <span class="n">抛出早期终止</span><span class="p">,</span>
            <span class="n">divide_by_initial_world_size</span><span class="o">=</span><span class="n">divide_by_initial_world_size</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DistributedDataParallel.join_hook"><font class=" " lang="zh-CN"><br hidden=""><font class="    "><font class="  ">[文档]    def join_hook(
self,
**kwargs,
    ):
r"""
DDP 加入钩子通过在正向和反向传递中镜像通信，使训练能够在不均匀的输入上进行。

参数：
kwargs (dict): 一个包含任何关键字段的 :class:`dict`
修改运行时连接钩子的行为；所有
:类:`Joinable` 实例共享相同的连接上下文
管理者将相同的值转发给 `kwargs`。

钩子支持以下关键字参数：
divide_by_initial_world_size (bool, 可选):
如果为 ``True``，则梯度将除以 DDP 启动时的初始世界大小。
如果为 ``False``，则梯度将除以有效世界大小。
如果为 ``False``，则梯度将除以有效世界大小。
大小（即非连接进程的数量），意味着
不均匀的输入对全局梯度贡献更大。
通常，如果程度为“True”
不均匀性很小，但在极端情况下可以设置为 ``False``
可能获得更好结果的案例。
默认为 ``True``。
"""
divide_by_initial_world_size = kwargs.get("divide_by_initial_world_size", True)
return _DDPJoinHook(
self, divide_by_initial_world_size=divide_by_initial_world_size
        )</font></font></font></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">连接设备</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">返回</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">加入处理组</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">返回</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">流程组</span>

    <span class="k">def</span> <span class="nf">_register_buffer_comm_hook</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">状态</span><span class="p">,</span>
        <span class="n">hook</span><span class="p">:</span> <span class="n">可调用</span><span class="p">,</span>
        <span class="n">沉浸式翻译位置</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_缓冲通信钩子位置</span><span class="o">.</span><span class="n">POST_FORWARD</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">""</span>
<span class="sd">允许自定义注册钩子，该钩子定义了如何在各个进程间同步缓冲区。</span>

<span class="sd">钩子接收一个可选的状态，并以 Dict[str, Tensor] 的形式传递。</span>
<span class="sd">对应缓冲区名称和缓冲区，可以运行任意 reductions</span>
<span class="sd">相比于 DDP 的默认从 rank 0 广播，这在以下情况下很有用：</span>
<span class="sd">例如，如果计数器需要在每次迭代中跨 rank 求和或平均。</span>

<span class="sd">        Args:</span>
<span class="sd">状态（Any）：传递给钩子的可选状态。</span>
<span class="sd">hook (Callable): 具有以下签名的可调用对象：</span>
<span class="sd">                         ``hook(state: object, bucket: dist.GradBucket) -&gt; torch.futures.Future[torch.Tensor]``</span>
<span class="sd">comm_hook_location (_BufferCommHookLocation): 表示运行钩子位置的枚举值。</span>
<span class="sd">                            where to run the hook.</span>
<span class="sd">`_BufferCommHookLocation.PRE_FORWARD` 表示在转发之前执行钩子，</span>
<span class="sd">钩子将在转发之前运行，并且</span>
<span class="sd">`_BufferCommHookLocation.POST_FORWARD` 表示在转发之后执行钩子，</span>
<span class="sd">钩子将在转发之后运行。</span>

<span class="sd">注意：为了最大化性能，用户可以返回</span>
<span class="sd">从他们的钩子中获取 List[torch.futures.Future]，并且 DDP 将</span>
<span class="sd">安装并适当在末尾等待这些钩子</span>
<span class="sd">反向传播。这将确保所有缓冲区都</span>
<span class="sd">同步至反向遍历结束。如果此</span>
<span class="sd">设置被使用时，建议传递</span>
<span class="sd">comm_hook_location = _BufferCommHookLocation.POST_FORWARD,</span>
<span class="sd">这将触发前向传递后的钩子。</span>
<span class="sd">如果使用 _BufferCommHookLocation.PRE_FORWARD，用户必须</span>
<span class="sd">确保在正向传递中操作 GPU 缓冲区时的适当同步。</span>
<span class="sd">在正向传递中操作 GPU 缓冲区时。</span>
<span class="sd">"源代码"</span>
        <span class="k">断言</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可调用</span><span class="p">(</span><span class="n">hook</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">缓冲区钩子</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区通信钩子</span><span class="p">(</span>
            <span class="n">缓冲区通信钩子</span><span class="o">=</span><span class="n">hook</span><span class="p">,</span>
            <span class="n">缓冲区通信钩子状态</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">状态</span><span class="p">,</span>
            <span class="n">缓冲区通信钩子位置</span><span class="o">=</span><span class="n">comm_hook_location</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="DistributedDataParallel.register_comm_hook"><a class="viewcode-back" href="../../../../generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.register_comm_hook">[文档]</font></font></font></a>    <span class="k">def</span> <span class="nf"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">注册通信钩子</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">状态</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">对象</font></font></font></span><span class="p">,</span> <span class="n">hook</span><span class="p">:</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可调用</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">""</span>
<span class="sd">注册用户定义的跨多个工作进程的 DDP 梯度聚合的通信钩子。这将非常有用，研究人员可以借此尝试新想法。例如，此钩子可以用来实现诸如 GossipGrad 等算法。</span>

<span class="sd">此钩子对于研究人员尝试新想法非常有用。例如，此钩子可以用来实现诸如 GossipGrad 等算法。</span>
<span class="sd">此钩子可以用来实现诸如 GossipGrad 等算法。</span>
<span class="sd">并且涉及不同的通信策略的梯度压缩，</span>
<span class="sd">在运行分布式数据并行训练时的参数同步。</span>

<span class="sd">        Args:</span>
<span class="sd">状态（对象）：传递给钩子以在训练过程中维护任何状态信息。</span>
<span class="sd">例如，在梯度压缩中的错误反馈等。</span>
<span class="sd">在 GossipGrad 中与下一个通信的节点等。</span>

<span class="sd">每个工作节点本地存储</span>
<span class="sd">并由工作节点上的所有梯度张量共享。</span>
<span class="sd">hook（可调用函数）：具有以下签名的可调用函数：</span>
<span class="sd">``hook(state: 对象, bucket: dist.GradBucket) -&gt; torch.futures.Future[torch.Tensor]``：</span>

<span class="sd">此函数在桶准备好后被调用。该</span>
<span class="sd">hook 可以执行所需的任何处理并返回</span>
<span class="sd">一个表示任何异步工作（例如：allreduce）完成的未来</span>
<span class="sd">如果钩子不执行任何通信，它仍然</span>
<span class="sd">必须返回一个完成的 Future。Future 应包含</span>
<span class="sd">新的 grad bucket 张量的值。一旦桶准备好，</span>
<span class="sd">c10d reducer 会调用此钩子并使用返回的张量</span>
<span class="sd">通过 Future 并将梯度复制到各个参数中。</span>
<span class="sd">注意，Future 的返回类型必须是一个单独的张量。</span>

<span class="sd">我们还提供了一个名为 ``get_future`` 的 API 来检索一个</span>
<span class="sd">与`c10d.ProcessGroup.Work`完成相关的未来。</span>
<span class="sd">`get_future`目前支持 NCCL，也支持 GLOO 和 MPI 上的大多数操作。</span>
<span class="sd">除了点对点操作（发送/接收）之外。</span>

<span class="sd">..警告::</span>
<span class="sd">Grad bucket 的 tensor 不会由 world_size 预先划分。用户负责。</span>
<span class="sd">在进行 allreduce 等操作时，需要除以 world_size。</span>

<span class="sd">..警告::</span>
<span class="sd">DDP 通信钩子只能注册一次，并且应该在调用 backward 之前注册。</span>
<span class="sd">钩子返回的 Future 对象应包含单个张量。</span>

<span class="sd">..警告::</span>
<span class="sd">钩子返回的 Future 对象应包含单个张量。</span>
<span class="sd">与 grad bucket 内部的张量具有相同形状。</span>

<span class="sd">..警告::</span>
<span class="sd">``get_future`` API 支持 NCCL，部分支持 GLOO 和 MPI 后端（不支持像 send/recv 这样的对等操作）并将返回一个``torch.futures.Future``。</span>
<span class="sd">下面是一个返回相同张量的空操作 hook 示例。</span>

<span class="sd">示例::</span>
<span class="sd">以下是一个返回相同张量的空操作 hook 示例。</span>

<span class="sd">            &gt;&gt;&gt; # xdoctest: +SKIP('undefined name')</span>
<span class="sd">&gt;&gt;&gt; def 无操作(state: object, 桶: dist.GradBucket) -&gt; torch.futures.Future[torch.Tensor]:</span>
<span class="sd">            &gt;&gt;&gt;     fut = torch.futures.Future()</span>
<span class="sd">&gt;&gt;&gt;     fut.set_result(桶.buffer())</span>
<span class="sd">&gt;&gt;&gt; 返回 fut</span>
<span class="sd">            &gt;&gt;&gt; ddp.register_comm_hook(state=None, hook=noop)</span>

<span class="sd">示例::</span>
<span class="sd">下面是一个并行 SGD 算法的示例，其中梯度在 allreduce 之前进行编码，然后在 allreduce 之后进行解码。</span>
<span class="sd">所有梯度在 allreduce 之前进行编码，然后在 allreduce 之后进行解码。</span>

<span class="sd">            &gt;&gt;&gt; # xdoctest: +SKIP('undefined name')</span>
<span class="sd">&gt;&gt;&gt; 定义 encode_and_decode 函数，参数为 state 对象和 bucket 类型的 GradBucket，返回 torch.futures.Future[torch.Tensor] 类型的 Future 对象</span>
<span class="sd">&gt;&gt;&gt;     对 bucket.buffer() 编码后的梯度进行编码</span>
<span class="sd">            &gt;&gt;&gt;     fut = torch.distributed.all_reduce(encoded_tensor).get_future()</span>
<span class="sd">&gt;&gt;&gt;     # 定义解码的回调函数。</span>
<span class="sd">            &gt;&gt;&gt;     def decode(fut):</span>
<span class="sd">&gt;&gt;&gt;         decoded_tensor = decode(fut.value()[0])  # 解码梯度</span>
<span class="sd">            &gt;&gt;&gt;         return decoded_tensor</span>
<span class="sd">&gt;&gt;&gt; 返回 fut.then(decode)</span>
<span class="sd">            &gt;&gt;&gt; ddp.register_comm_hook(state=None, hook=encode_and_decode)</span>
<span class="sd">"源代码"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_comm_hook</span><span class="p">(</span><span class="n">hook</span><span class="p">)</span>
        <span class="k">断言</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">日志记录器</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">记录器</span><span class="o">.</span><span class="n">_set_comm_hook_name</span><span class="p">(</span><span class="n">hook</span><span class="o">.</span><span class="vm">__qualname__</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_comm_hooks</span><span class="o">.</span><span class="n">追加</font></font></font></span><span class="p">((</span><span class="n">hook</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">状态</span><span class="p">))</span>
        <span class="n">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">注册通信钩子</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">简化器</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">状态</span><span class="p">,</span> <span class="n">hook</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">注册内置通信钩子</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">comm_hook_type</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">""</span>
<span class="sd">注册一个内置的通信钩子，该钩子指定了 DDP 如何在多个工作者之间聚合梯度。</span>

<span class="sd">内置钩子的目的是提供某些钩子的高效 C++实现。</span>
<span class="sd">如果使用 Python 通信钩子实现，可能不会那么高效。</span>

<span class="sd">        Args:</span>
<span class="sd">comm_hook_type (dist.BuiltinCommHookType)：通信钩子类型，例如 ALLREDUCE、FP16_COMPRESS 等。</span>

<span class="sd">..警告::</span>
<span class="sd">DDP 通信钩子只能注册一次，应该在调用 backward 之前注册。</span>
<span class="sd">在调用 backward 之前。</span>

<span class="sd">示例::</span>
<span class="sd">以下是 FP16 压缩的一个示例，其中梯度是</span>
<span class="sd">压缩为 16 位浮点数后再进行 allreduce 操作，并</span>
<span class="sd">然后在对所有 reduce 操作完成后进行解压缩。</span>

<span class="sd">&gt;&gt;&gt; # xdoctest: +SKIP('未定义的名称')</span>
<span class="sd">            &gt;&gt;&gt; ddp._register_builtin_comm_hook(dist.BuiltinCommHookType.FP16_COMPRESS)</span>

<span class="sd">"源代码"</span>
        <span class="k">断言</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">日志记录器</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">记录器</font></font></font></span><span class="o">.</span><span class="n">_set_comm_hook_name</span><span class="p">(</span><span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">字符串</span><span class="p">(</span><span class="n">comm_hook_type</span><span class="p">))</span>
        <span class="n">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">注册内置通信钩子</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">简化器</span><span class="p">,</span> <span class="n">comm_hook_type</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">注册融合优化器</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">优化</font></font></font></span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">类型</font></font></font></span><span class="p">,</span> <span class="o">*</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">优化器参数</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">""</span>
<span class="sd">在 DDP 中注册一个优化器，以便在梯度缩减后立即优化参数。</span>

<span class="sd">将优化器与 DDP 注册，以便对</span>
<span class="sd">参数将在该参数的梯度运行立即</span>
<span class="sd">完成缩减，而不是等待所有参数</span>
<span class="sd">梯度完成缩减。这可能导致训练速度加快</span>
<span class="sd">根据您的工作负载，因为优化器可以在梯度计算时运行</span>
<span class="sd">其他参数的优化仍在进行中。此外，它还有潜力在训练期间降低峰值内存消耗，因为它只需要一次性加载单个参数的优化器状态，而不是加载所有参数的优化器状态。</span>
<span class="sd">这样可以降低训练过程中的峰值内存消耗，因为它只需要一次性加载单个参数的优化器状态，而不是加载所有参数的优化器状态。</span>
<span class="sd">只需一次性加载单个参数的优化器状态，而不是加载所有参数的优化器状态，因此具有降低峰值内存消耗的潜力。</span>
<span class="sd">只需一次性加载单个参数的优化器状态，而不是加载所有参数的优化器状态，从而降低了训练过程中的峰值内存消耗。</span>
<span class="sd">同时翻译多个状态。</span>

<span class="sd">        Args:</span>
<span class="sd">optim（类型）：一个用于注册的 ``torch.optim.Optimizer`` 类。</span>
<span class="sd">作为融合优化器。</span>
<span class="sd">*args（序列[任何类型]）：传递给 `optim` 的参数。</span>
<span class="sd">optim_params (Optional[Iterable[torch.Tensor]]): 需要优化的参数集合，类似于传统 `torch.optim` 的 `params` 参数</span>
<span class="sd">要优化的，类似于传统 `torch.optim` 的 `params` 参数</span>
<span class="sd">优化器。如果省略，则所有 DDP 模型参数将被</span>
<span class="sd">优化。</span>
<span class="sd">**kwargs: (字典[str, 任意]): 将关键字参数传递给 `optim`。</span>

<span class="sd">..警告::</span>
<span class="sd">_register_fused_optim 应仅在 DDP 实例上调用一次</span>
<span class="sd">注册多个针对同一 DDP 模型的融合优化器</span>
<span class="sd">当前不支持。请 ping</span>
<span class="sd">https://github.com/pytorch/pytorch/issues/71595 如果这是必要的</span>
<span class="sd">适用于您的用例。</span>

<span class="sd">..警告::</span>
<span class="sd">_register_fused_optim 和 register_comm_hook 目前无法</span>
<span class="sd">组合在一起，这意味着自定义 DDP 通信钩子</span>
<span class="sd">不支持重叠优化器。请提醒</span>
<span class="sd">如果这是必要的，请访问 https://github.com/pytorch/pytorch/issues/71595</span>
<span class="sd">以满足您的用例。</span>

<span class="sd">..警告::</span>
<span class="sd">目前不支持梯度累积和 DDP 的`no_sync`</span>
<span class="sd">与重叠的优化器一起。请 ping</span>
<span class="sd">如果这是必要的，请访问 https://github.com/pytorch/pytorch/issues/71595</span>
<span class="sd">以满足您的用例。</span>

<span class="sd">示例::</span>

<span class="sd">&gt;&gt;&gt; # xdoctest: +SKIP("没有 rendezvous 处理器")</span>
<span class="sd">            &gt;&gt;&gt; torch.distributed.init_process_group(backend='nccl', world_size=4, init_method='...')</span>
<span class="sd">            &gt;&gt;&gt; net = torch.nn.parallel.DistributedDataParallel(model, pg)</span>
<span class="sd">            &gt;&gt;&gt; lr = 1e-2</span>
<span class="sd">            &gt;&gt;&gt; betas = (0.9, 0.99)</span>
<span class="sd">            &gt;&gt;&gt; eps = 1e-6</span>
<span class="sd">&gt;&gt;&gt; net._register_fused_optim(torch.optim.Adam, lr, betas=beta, eps=eps)</span>
<span class="sd">&gt;&gt;&gt; # 示例使用参数子集</span>
<span class="sd">            &gt;&gt;&gt; params_to_opt = [list(net.parameters())[0]]</span>
<span class="sd">            &gt;&gt;&gt; net._register_fused_optim(</span>
<span class="sd">            ...   torch.optim.Adam, lr, optim_params=params_to_opt,  betas=betas, eps=eps</span>
<span class="sd">            ... )</span>
<span class="sd">"源代码"</span>
        <span class="c1"># 注意：在函数中导入，否则这将会导致循环引用</span>
        <span class="c1"># 导入作为优化器重叠模块需要导入 DistributedDataParallel。</span>
        <span class="kn">来自</font></font></font></span> <span class="nn">torch.distributed.algorithms._optimizer_overlap</span> <span class="kn"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">导入</span> <span class="n">_as_overlapped_optim</span>

        <span class="n">overlapped_optim</span> <span class="o">=</span> <span class="n">_重叠优化</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">优化</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">优化参数</font></font></font></span><span class="p">,</span> <span class="o">*</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">重叠优化</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">注册分布式数据并行</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">除了</font></font></font></span> <span class="ne"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">未实现异常</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">作为</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">提升</font></font></font></span> <span class="ne"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">运行时错误</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">优化</font></font></font></span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">不支持重叠的 DDP。请向 PyTorch 或相应所有者提交问题。</font></font></font></span><span class="si">{</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">优化</font></font></font></span><span class="si">}</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">。</span>
            <span class="p">)</span> <span class="kn">来自</span> <span class="nn">e</span>

    <span class="k">def</span> <span class="nf">_分布式广播合并</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">权威性 rank</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">):</span>
        <span class="n">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_广播合并_</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">进程组</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">权威排名</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_检查同步缓冲区后转发</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">返回</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">将同步模块缓冲区</span><span class="p">()</span>
            <span class="ow">和</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区钩子</span><span class="p">)</span>
            <span class="ow">和</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区钩子</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区通信钩子位置</span>
            <span class="o">==</span> <span class="n">_缓冲通信钩子位置</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">后转发</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_sync_bufs_pre_fwd</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">返回</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">将同步模块缓冲区</font></font></font></span><span class="p">()</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">有属性</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区钩子</span><span class="p">)</span>
            <span class="ow">或</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区钩子</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区通信钩子位置</span>
            <span class="o">==</span> <span class="n">_缓冲通信钩子位置</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">预转发</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">将同步模块缓冲区</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">返回</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">require_forward_param_sync</span>
            <span class="ow">和</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">广播缓冲区</span>
            <span class="ow">和</font></font></font></span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">长度</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modules_buffers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_find_common_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_rank</span><span class="p">,</span> <span class="n">排名条件</span><span class="p">):</span>
        <span class="c1"># -1 表示此排名不在考虑范围内</span>
        <span class="c1"># 常见排名</span>
        <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">rank_to_use
排名使用</font></font></font></span> <span class="o">=</span> <span class="n">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">(</span>
            <span class="p">[</span><span class="n">输入排名</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">排名条件</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">否则</font></font></font></span> <span class="o">-</span><span class="mi">1</span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]</span>
            <span class="n">设备</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">距离</font></font></font></span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">使用的排名</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">操作</font></font></font></span><span class="o">=</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">MAX</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">群组</font></font></font></span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程组</span><span class="p">)</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">使用排名</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">项目</span><span class="p">()</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span>
                <span class="ne">ValueError</span><span class="p">,</span>
                <span class="s2">"BUG！期望至少有一个进程的 rank_cond 为 true。"</span>
                <span class="s2">"这表明 PyTorch 中存在一个 bug，请报告问题。"</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">使用排名</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">项目</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">同步缓冲区</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">与</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">不梯度</span><span class="p">():</span>
            <span class="c1"># 模块缓冲同步</span>
            <span class="c1"># 在进程间同步缓冲区。</span>
            <span class="c1"># 如果我们在使用 DDP 与 join manager，我们必须同意</span>
            <span class="c1"># 从哪个 rank 同步模块缓冲区，因为 rank 0 可能</span>
            <span class="c1">已连接并具有过时的模块缓冲区。</span>
            <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n">_join_config</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">启用</span><span class="p">:</span>
                <span class="n">权威排名</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_common_rank</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">分布式排名</font></font></font></span><span class="p">,</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
                <span class="p">)</span>
            <span class="k">否则</span><span class="p">:</span>
                <span class="c1"># 排名 0 的过程被认为是权威副本。</span>
                <span class="n">权威排名</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># 更新 self.modules_buffers，以防有任何缓冲区被</span>
            <span class="c1">#重新分配。</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_分配模块缓冲区</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_同步模块缓冲区</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">权威排名</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">同步模块缓冲区</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">权威排名</span><span class="p">):</span>
        <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区钩子</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">默认广播合并</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">权威排名</font></font></font></span><span class="o">=</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">权威排名</span><span class="p">)</span>
        <span class="k">否则</span><span class="p">:</span>
            <span class="n">钩子</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区钩子</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区通信钩子</span>
            <span class="n">状态</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区钩子</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区通信钩子状态</span>
            <span class="n">期货</font></font></font></span> <span class="o">=</span> <span class="n">hook</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">状态</font></font></font></span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名模块缓冲区</span><span class="p">)</span>
            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">期货</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">安装后向未来</span><span class="p">(</span><span class="n">futs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_default_broadcast_coalesced</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">缓冲区</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶大小</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">,</span> <span class="n">authoritative_rank</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">""</span>
<span class="sd">从 rank 0 广播缓冲区到其他工作进程。</span>

<span class="sd">如果 bufs、bucket_size 为 None，则使用默认值 self.modules_buffers</span>
<span class="sd">和 self.broadcast_bucket_size 代替。</span>
<span class="sd">"源代码"</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="n">缓冲区</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules_buffers</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶大小</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span><span class="p">:</span>
            <span class="n">桶大小</font></font></font></span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">广播桶大小</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_分布式广播合并</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶大小</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">权威排名</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_传递同步批归一化处理</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">):</span>
        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">层</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</span><span class="p">():</span>
            <span class="k">如果</font></font></font></span> <span class="nb">isinstance</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">层</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">同步批量归一化</span><span class="p">):</span>
                <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设备类型</span> <span class="o">==</span> <span class="s2">"cpu"</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span>
                        <span class="ne">ValueError</span><span class="p">,</span>
                        <span class="s2">"同步批量归一化层仅与 GPU 模块一起工作"</span><span class="p">,</span>
                    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_comm_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>
        <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">可调用</span><span class="p">(</span><span class="n">hook</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span><span class="ne">类型错误</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"通信钩子必须可调用。"</span><span class="p">)</span>

        <span class="n">sig</span> <span class="o">=</span> <span class="n">检查</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">签名</span><span class="p">(</span><span class="n">hook</span><span class="p">)</span>
        <span class="k">如果</span> <span class="p">(</span>
            <span class="n">签名</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶</font></font></font></span><span class="p">]</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">注释</font></font></font></span> <span class="o">!=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">检查</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_空_</span>
            <span class="ow">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">签名</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">桶</font></font></font></span><span class="p">]</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">注释</font></font></font></span> <span class="o">!=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">毕业桶</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span>
                <span class="ne">ValueError</span><span class="p">,</span>
                <span class="s2">"通信钩子：桶注释应为 dist.GradBucket。"</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">如果</span> <span class="p">(</span>
            <span class="n">签名</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">返回注解</font></font></font></span> <span class="o">!=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">检查</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">空</span>
            <span class="ow">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">签名</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">返回注解</font></font></font></span> <span class="o">!=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">期货</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">未来</font></font></font></span><span class="p">[</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">张量</span><span class="p">]</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span>
                <span class="ne">ValueError</span><span class="p">,</span>
                <span class="s2">通信钩子：返回注释应为 torch.futures.Future[torch.Tensor]。</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">如果</font></font></font></span> <span class="n">hook</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="p">[</span><span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"bf16 压缩钩子"</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">"bf16 压缩包装钩子"</font></font></font></span><span class="p"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">]：</span>
            <span class="n">支持 CUDA</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">版本</font></font></font></span><span class="o">.</span><span class="n">cuda</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
            <span class="p">)</span> <span class="ow">或</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">版本</font></font></font></span><span class="o">.</span><span class="n">hip</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
            <span class="n">支持 NCCL</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是否可用</span><span class="p">()</span>
                <span class="ow">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">检查 NCCL 是否可用</span><span class="p">()</span>
                <span class="ow">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">nccl</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">版本</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">xpu_xccl 支持</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是否可用</span><span class="p">()</span>
                <span class="ow">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是否支持 xccl</span><span class="p">()</span>
                <span class="ow">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">火炬</font></font></font></span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是否可用</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="p">((</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">支持 CUDA</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">和</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">支持 NCCL</font></font></font></span><span class="p">)</span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">或</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">支持 XPU 和 XCCL</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span>
                    <span class="ne">类型错误</span><span class="p">,</span>
                    <span class="s2">需要 BF16 all reduce 通信钩子，要求 CUDA 11+和 NCCL 2.10+或 XPU 和 XCCL</span><span class="p">,</span>
                <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">分布式排名</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">返回</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">距离</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">获取排名</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">进程组</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">获取数据并行参数</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名参数</font></font></font></span><span class="o">=</span><span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">错误</span><span class="p">):</span>
<span class="w">        </span><span class="sd">返回由给定 DDP 单元管理的参数生成器。</span>
        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</span> <span class="p">(</span>
            <span class="n">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">()</span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">如果</font></font></font></span> <span class="ow">not</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名参数</font></font></font></span> <span class="k"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">否则</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名参数。</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">有属性</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span><span class="p">,</span> <span class="s2"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_ddp_ignored</span><span class="p">):</span>
                <span class="k">产生</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_设置模型忽略的参数和缓冲区</span><span class="p">(</span>
        <span class="n">模块</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">忽略的参数和缓冲区</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">""</span>
<span class="sd">设置要由 DDP 忽略的参数和缓冲区。</span>

<span class="sd">参数的预期格式为完全限定名：{module_name}.{param_name}，并且</span>
<span class="sd">类似地，{module_name}.{buffer_name}用于缓冲区。例如：</span>
<span class="sd">        params_to_ignore = []</span>
<span class="sd"># NB: 模型此处为纯 PyTorch 模块，尚未使用 DDP 进行封装。</span>
<span class="sd">        for module_name, module in model.named_modules():</span>
<span class="sd">            for param_name, param in module.named_parameters(recurse=False):</span>
<span class="sd">                if should_ignore(param):</span>
<span class="sd">创建预期格式</span>
<span class="sd">                    fqn = f"{module_name}.{param_name}"</span>
<span class="sd">                    params_to_ignore.append(fqn)</span>
<span class="sd">        torch.nn.parallel.DistributedDataParallel._set_params_and_buffers_to_ignore_for_model(</span>
<span class="sd">模型,</span>
<span class="sd">忽略的参数</span>
<span class="sd">        )</span>
<span class="sd">"源代码"</span>
        <span class="c1">这是一个绕过方法，用于设置 DDP 应忽略的参数和缓冲区</span>
        <span class="c1">在同步期间。当 API 最终确定后，它将被删除</span>
        <span class="c1">作为解决 https://github.com/pytorch/pytorch/issues/43690 的一部分</span>
        <span class="n">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">忽略的_ddp 参数和缓冲区</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">忽略的参数和缓冲区</span>
        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">名称</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">参数</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名参数。</span><span class="p">():</span>
            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">名称</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">要忽略的参数和缓冲区</span><span class="p">:</span>
                <span class="n">参数</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_ddp_忽略的</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
        <span class="k">为</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">名称</font></font></font></span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">缓冲区</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">模块</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">命名缓冲区</span><span class="p">():</span>
            <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">名称</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">在</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">要忽略的参数和缓冲区</span><span class="p">:</span>
                <span class="n">缓冲区</font></font></font></span><span class="o">.</span><span class="n">_ddp_ignored</span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>

    <span class="k">def</span> <span class="nf">_get_ddp_logging_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">""</span>
<span class="sd">返回用于调试和分析的日志数据字典。</span>

<span class="sd">在调用 DistributedDataParallel() 之后，可以调用此接口。</span>
<span class="sd">构造函数返回一个日志数据字典。这有助于</span>
<span class="sd">调试和分析。日志数据包括 DistributedDataParallel</span>
<span class="sd">构造函数的输入参数，DistributedDataParallel 的一些内部状态</span>
<span class="sd">以及性能指标。简单打印字典，看看</span>
<span class="sd">这些指标是。</span>
<span class="sd">这是一个原型界面，未来可能会有所变化。</span>
<span class="sd">"源代码"</span>
        <span class="k">断言</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">日志记录器</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
        <span class="n">ddp_logging_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">记录器</span><span class="o">.</span><span class="n">_get_ddp_logging_data</span><span class="p">()</span>
        <span class="k">返回</font></font></font></span> <span class="p">{</span><span class="o">**</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">ddp 日志数据</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">strs 映射</font></font></font></span><span class="p">,</span> <span class="o">**</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">ddp 日志数据</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">ints 映射</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">设置 DDP 运行时日志采样率</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">采样率</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">""</span>
<span class="sd">设置收集运行时统计信息的采样率。</span>

<span class="sd">此接口允许用户设置收集采样率。</span>
<span class="sd">运行时统计信息。运行时统计信息将在前 10 次迭代中记录，</span>
<span class="sd">之后每 10 次迭代记录一次。默认情况下，运行时统计信息将记录前 10 次迭代，</span>
<span class="sd">每"sample_rate"次训练迭代记录一次。在默认情况下，</span>
<span class="sd">运行时统计信息将记录前 10 次迭代，</span>
<span class="sd">经过 10 次迭代后，运行时统计信息每进行一次记录。</span>
<span class="sd">"kDDPRuntimeLoggingSampleRate=100" 训练迭代次数。</span>
<span class="sd">这是一个原型界面，未来可能会有所变化。</span>
<span class="sd">"源代码"</span>
        <span class="k">如果</font></font></font></span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">采样率</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_and_throw</span><span class="p">(</span>
                <span class="ne">ValueError</span><span class="p">,</span>
                <span class="s2">DDP 运行时日志采样率应等于或大于 1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设置 DDP 运行时日志采样率</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">采样率</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_设置静态图</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">""</span>
<span class="sd">为 DDP 设置静态图。</span>

<span class="sd">建议在 DDP 构造函数中设置静态图，</span>
<span class="sd">在内部调用此私有 API。</span>
<span class="sd">"源代码"</span>
        <span class="c1">如果已设置 self.static_graph，则无需再次设置。</span>
        <span class="k">如果</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">静态图</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">警告</span><span class="p">(</span>
                <span class="s2">您已将 static_graph 设置为 True，无需再次设置。</span>
            <span class="p">)</span>
            <span class="k">返回</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">静态图</font></font></font></span> <span class="o">=</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">真实</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_static_graph_delay_allreduce_enqueued</span> <span class="o">=</span> <span class="kc">假</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_设置静态图</span><span class="p">()</span>
        <span class="k">断言</font></font></font></span> <span class="bp">self</span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">日志记录器</font></font></font></span> <span class="ow"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">是</font></font></font></span> <span class="ow">not</span> <span class="kc"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">无</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">记录器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_设置静态图</span><span class="p">()</span>
        <span class="k">如果</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_unused_parameters</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">警告</span><span class="p">(</span>
                <span class="s2">您已将 find_unused_parameters=true 传递给 DistributedDataParallel。</span>
                <span class="s2">"`_set_static_graph` 将自动检测未使用的参数，因此 "</span>
                <span class="s2">"您不需要设置 find_unused_parameters=true，只需确保这些 "</span>
                <span class="s2">"未使用的参数在调用 `_set_static_graph` 的训练循环期间不会改变 "</span>
                <span class="s2">"`_set_static_graph`。"</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">移除自动求导钩子</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"移除由 reducer 注册到模型参数上的 autograd 钩子。"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">_移除 autograd 钩子</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_检查 reducer 是否已最终化</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">""</span>
<span class="sd">检查 reducer 是否已处理所有桶并适当地最终化反向操作。</span>

<span class="sd">在训练循环中调用 .backward() 方法之后调用此方法是有用的</span>
<span class="sd">以避免由于 reducer 未最终化而导致的后续难以调试的错误</span>
<span class="sd">在未来的路上</span>
<span class="sd">"源代码"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">简化器</span><span class="o">.</span><span class="n">_check_reducer_finalized</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">设置稀疏元数据</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">全局唯一标识符</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">设置稀疏元数据</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">全局唯一标识符</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">更新进程组</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">新进程组</span><span class="p">):</span>
<span class="w">        </span><span class="sd">""</span>
<span class="sd">动态更新 DDP 的过程组，以便我们可以缩小/扩展 DDP</span>
<span class="sd">无需重新初始化 DDP 的全局大小</span>

<span class="sd">注意：如果您正在使用通过 register_comm_hook 注册的自定义通信钩子，</span>
<span class="sd">您需要分别更新那些钩子的进程组。</span>
<span class="sd">"源代码"</span>
        <span class="c1">强制重建新进程组的存储桶。这确保了所有进程的编号</span>
        <span class="c1"># 在重建桶的时间上保持同步</span>
        <span class="c1"># 重新评估基于世界大小可能产生的桶的先前假设</span>
        <span class="c1"># 已更改。</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_has_rebuilt_buckets</span> <span class="o">=</span> <span class="kc">假</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">重置状态</span><span class="p">()</span>

        <span class="k">如果</font></font></font></span> <span class="ow">not</span> <span class="n">_rank_not_in_group</span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">新建进程组</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">流程组</font></font></font></span> <span class="o">=</span> <span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">新建进程组</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">简化器</font></font></font></span><span class="o">.</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">更新进程组</font></font></font></span><span class="p">(</span><span class="n"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">新进程组</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_设置 ddp_sink_clone</font></font></font></span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="nb"><font class=" " lang="zh-CN"><br hidden=""><font class="   "><font class="  ">布尔</span><span class="p">):</span>
<span class="w">        </span><span class="sd">""</span>
<span class="sd">设置 DDPSink 是否应该克隆输出张量。</span>
<span class="sd">默认为 True，因为如果损失在原地修改，我们运行</span>
<span class="sd">视图中的修改是在原地发生的错误。</span>

<span class="sd">尽管克隆张量可以增加显著的内存和</span>
<span class="sd">性能下降，如果张量的数量和大小很大。</span>
<span class="sd">结果，这可以设置为 False，如果您不是在原地修改</span>
<span class="sd">损失。</span>
<span class="sd">"源代码"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ddp_sink_clone</span> <span class="o">=</span> <span class="n">val</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>© 版权所有 PyTorch 贡献者。</p>
  </div>
    
      <div>使用 Sphinx 构建，并使用 Read the Docs 提供的主题。</div>
     

</footer>

          </div>
<script>

var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/clipboard.min.js"></script>
         <script src="../../../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script="" type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0">


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>文档</h2>
          <p>查看 PyTorch 的全面开发者文档</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">查看文档</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>教程</h2>
          <p>深入了解初学者和高级开发者的教程</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">查看教程</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>资源</h2>
          <p>查找开发资源，获取您的疑问解答</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">查看资源</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">开始使用</a></li>
            <li><a href="https://pytorch.org/features">功能</a></li>
            <li><a href="https://pytorch.org/ecosystem">生态系统</a></li>
            <li><a href="https://pytorch.org/blog/">博客</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">贡献</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">资源</a></li>
            <li><a href="https://pytorch.org/tutorials">教程</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">文档</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">讨论</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github 问题</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">品牌指南</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">保持更新</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">推特</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">领英</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch 播客</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">苹果</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">谷歌</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">亚马逊</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">条款</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">隐私</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© 版权所有 Linux 基金会。PyTorch 基金会是 Linux 基金会的一个项目。有关 PyTorch 基金会的网站使用条款、商标政策以及其他适用政策，请参阅 www.linuxfoundation.org/policies/。PyTorch 基金会支持 PyTorch 开源项目，该项目已被确立为 LF Projects, LLC 的 PyTorch 项目系列。有关适用于 PyTorch 项目系列 LF Projects, LLC 的政策，请参阅 www.lfprojects.org/policies/。</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">为了分析流量并优化您的体验，我们在本网站上使用 cookies。通过点击或导航，您同意允许我们使用 cookies。作为本网站的当前维护者，适用 Facebook 的 Cookies 政策。了解更多信息，包括关于可用控制的信息：Cookies 政策。</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg" width="16" height="16">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>学习</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">开始使用</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">教程</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">学习基础知识</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch 食谱</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">PyTorch 入门 - YouTube 系列</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>生态系统</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">工具</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">社区</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">论坛</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">开发者资源</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">贡献者奖项 - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>边缘</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">关于 PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch 文档</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>文档</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch 领域</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>博客 &amp; 新闻</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch 博客</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">社区博客</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">视频</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">社区故事</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">活动</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">通讯</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>关于</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch 基金会</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">管理委员会</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">云信用计划</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">技术咨询委员会</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">员工</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">联系我们</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>

</body></html>